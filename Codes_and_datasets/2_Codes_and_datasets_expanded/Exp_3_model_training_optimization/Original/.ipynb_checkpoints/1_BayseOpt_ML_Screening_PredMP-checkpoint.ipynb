{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315d707c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, GroupKFold, cross_val_predict\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import lightgbm as lgb\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt import BayesSearchCV\n",
    "import shap\n",
    "import pickle\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60228007",
   "metadata": {},
   "source": [
    "# Data For"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84fe525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for = '_PredMP'\n",
    "\n",
    "#data_for = '_ExpMP'\n",
    "\n",
    "#data_for = '_NoMP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02d36e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "black = '#515265'\n",
    "red = '#DD706E'\n",
    "yellow = '#FAAF3A'\n",
    "blue = '#3A93C2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc9077dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../Exp_2_Dataset_feature_engineering/Summary_and_dataset/refined_dataset' + data_for + '.csv'\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "train = data[data['Type'] == 'Train']\n",
    "test = data[data['Type'] == 'Test']\n",
    "lab = data[data['Type'] == 'Lab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "103a9b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlapping_values = set(train['Drug-solvent system']).intersection(test['Drug-solvent system'])\n",
    "overlapping_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4538b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing (dataset):\n",
    "\n",
    "    X = dataset.drop(['Type', 'Drug', 'Solvent_1', 'Solvent_2', 'Drug-solvent system', 'LogS', 'Class', 'Solubility (g/100g)'], axis = 1)\n",
    "    Y = dataset['LogS']\n",
    "    G = dataset['Drug-solvent system']\n",
    "\n",
    "    return X, Y, G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1b7be59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, G_train = data_processing(train)\n",
    "X_test, Y_test, G_test = data_processing(test)\n",
    "X_lab, Y_lab, G_lab = data_processing(lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6375ae6f",
   "metadata": {},
   "source": [
    "# Hyperparameter screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc239067",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces = {\n",
    "    \"DT\": {\n",
    "        \"max_depth\": Integer(3, 20),\n",
    "        \"splitter\":Categorical(['best', 'random']),\n",
    "        \"min_samples_split\": Real(0.01, 0.1),\n",
    "        \"min_samples_leaf\": Integer(1, 20),\n",
    "        \"max_features\": Categorical(['auto', 'sqrt', 'log2']),\n",
    "    },\n",
    "    \"RF\": {\n",
    "        \"n_estimators\": Integer(10, 400),\n",
    "        \"max_depth\": Integer(3, 20),\n",
    "        \"min_samples_split\": Real(0.01, 0.1),\n",
    "        \"min_samples_leaf\": Integer(1, 20),\n",
    "        \"max_features\": Categorical(['auto', 'sqrt', 'log2']),\n",
    "        \"bootstrap\": Categorical([True, False]),\n",
    "    },\n",
    "    \"XGB\": {\n",
    "        \"n_estimators\": Integer(10, 400),\n",
    "        \"learning_rate\": Real(0.01, 0.3, prior=\"log-uniform\"),\n",
    "        \"max_depth\": Integer(3, 20),\n",
    "        \"subsample\": Real(0.5, 1.0),\n",
    "        \"colsample_bytree\": Real(0.5, 1.0),\n",
    "        \"gamma\": Real(0, 5),\n",
    "    },\n",
    "    \"NN\": {\n",
    "        \"hidden_layer_sizes\": Integer(2, 64),\n",
    "        \"alpha\": Real(0.0001, 0.1, prior=\"log-uniform\"),\n",
    "        \"learning_rate_init\": Real(0.001, 0.1, prior=\"log-uniform\"),\n",
    "        \"activation\": Categorical(['relu', 'tanh', 'logistic']),\n",
    "},\n",
    "\n",
    "    \"LightGBM\": {\n",
    "        \"num_leaves\": Integer(10, 400),\n",
    "        \"max_depth\": Integer(3, 20),\n",
    "        \"learning_rate\": Real(0.01, 0.3, prior=\"log-uniform\"),\n",
    "        \"n_estimators\": Integer(100, 1000),\n",
    "        \"bagging_fraction\": Real(0.5, 1),\n",
    "        \"feature_fraction\": Real(0.5, 1),\n",
    "        \"min_child_samples\": Integer(5, 100),\n",
    "    },\n",
    "    \"MLR\": {\n",
    "        'fit_intercept':Categorical([True, False]),\n",
    "        'positive':Categorical([True, False])\n",
    "    },\n",
    "    \"Lasso\": {\n",
    "        \"alpha\": Real(0.0001, 1, prior=\"log-uniform\"),\n",
    "        \"selection\": Categorical(['cyclic', 'random']),\n",
    "    },\n",
    "    \"kNN\": {'n_neighbors':Integer(2, 50),\n",
    "            'weights': Categorical([\"uniform\", 'distance']),\n",
    "            'algorithm': Categorical(['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
    "            'leaf_size': Integer(10, 100),\n",
    "            'p':Integer(1, 2),\n",
    "    },\n",
    "    \"PLS\": {'n_components':Integer(2, 6),\n",
    "            'max_iter': Integer(250, 1000)\n",
    "    }\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4fb4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces_df = pd.DataFrame([(model, params) for model, params in search_spaces.items()], columns=['Model', 'Hyperparameters'])\n",
    "\n",
    "search_spaces_df.to_excel('Table_SI_search_space.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29b880f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"DT\": DecisionTreeRegressor(random_state=0),\n",
    "    \"RF\": RandomForestRegressor(random_state=0, n_jobs=6),\n",
    "    \"XGB\": XGBRegressor(random_state=0, n_jobs=6),\n",
    "    \"NN\": MLPRegressor(random_state=0),\n",
    "    \"LightGBM\": lgb.LGBMRegressor(random_state=0, n_jobs=6),\n",
    "    \"MLR\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"PLS\": PLSRegression(),\n",
    "    \"kNN\": KNeighborsRegressor(n_jobs=6)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1bda48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_hp_screening(model_name, X_train, Y_train, G_train, n_iter):\n",
    "\n",
    "    \n",
    "    model = models[model_name]\n",
    "    search_space = search_spaces[model_name]\n",
    "    \n",
    "    \n",
    "    cv = GroupKFold(n_splits=10)\n",
    "\n",
    "    \n",
    "    bscv = BayesSearchCV(\n",
    "        estimator=model,\n",
    "        search_spaces=search_space,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=cv,\n",
    "        n_iter=n_iter,\n",
    "        n_jobs=6,\n",
    "        verbose=0,\n",
    "        random_state = 0\n",
    "    )\n",
    "\n",
    "    \n",
    "    bscv.fit(X_train, Y_train, groups=G_train)\n",
    "    optimization_history = bscv.cv_results_\n",
    "\n",
    "\n",
    "    \n",
    "    return bscv.best_estimator_, bscv.best_params_, bscv.best_score_, optimization_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f54dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"DT\", \"RF\", \"XGB\",  \"NN\", \"LightGBM\", \"MLR\", \"Lasso\", \"PLS\", \"kNN\"]\n",
    "results = {}\n",
    "\n",
    "n_iter = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "433db137",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "The objective has been evaluated at this point before.\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "The objective has been evaluated at this point before.\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "The objective has been evaluated at this point before.\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The objective has been evaluated at this point before.\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "The objective has been evaluated at this point before.\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "The objective has been evaluated at this point before.\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The objective has been evaluated at this point before.\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "The objective has been evaluated at this point before.\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "The objective has been evaluated at this point before.\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The objective has been evaluated at this point before.\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "The objective has been evaluated at this point before.\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "The objective has been evaluated at this point before.\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "The objective has been evaluated at this point before.\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "The objective has been evaluated at this point before.\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DT :   -0.467\n",
      "3.3 min\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "The objective has been evaluated at this point before.\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RF :   -0.419\n",
      "79.4 min\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGB :   -0.314\n",
      "301.1 min\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "The objective has been evaluated at this point before.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NN :   -0.356\n",
      "44.2 min\n",
      "\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8380397544384568, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380397544384568\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7654820824760737, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7654820824760737\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8380397544384568, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380397544384568\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7654820824760737, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7654820824760737\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9894518292131809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9894518292131809\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.629185830986374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.629185830986374\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9894518292131809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9894518292131809\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.629185830986374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.629185830986374\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5289489218467651, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5289489218467651\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7643458710377254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7643458710377254\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5289489218467651, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5289489218467651\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7643458710377254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7643458710377254\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8916331353364969, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8916331353364969\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5737099059755859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5737099059755859\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6216679677341995, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6216679677341995\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6162570141151325, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6162570141151325\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6216679677341995, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6216679677341995\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6162570141151325, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6162570141151325\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9956120269464492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9956120269464492\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9190831912766004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9190831912766004\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9956120269464492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9956120269464492\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9190831912766004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9190831912766004\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8782764530210248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8782764530210248\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9835656124421499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9835656124421499\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8782764530210248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8782764530210248\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9835656124421499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9835656124421499\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7634895156575092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7634895156575092\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7552445232092422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7552445232092422\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7634895156575092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7634895156575092\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7552445232092422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7552445232092422\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9480863089293394, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9480863089293394\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.546027248452608, subsample=1.0 will be ignored. Current value: bagging_fraction=0.546027248452608\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9480863089293394, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9480863089293394\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.546027248452608, subsample=1.0 will be ignored. Current value: bagging_fraction=0.546027248452608\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7200918168694508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7200918168694508\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6847684887002612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6847684887002612\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7200918168694508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7200918168694508\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6847684887002612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6847684887002612\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5494369771275383, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5494369771275383\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7702157793924279, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7702157793924279\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5494369771275383, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5494369771275383\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7702157793924279, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7702157793924279\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5581635896410128, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5581635896410128\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5581635896410128, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5581635896410128\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5918273078858426, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5918273078858426\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5918273078858426, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5918273078858426\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.608887766563851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.608887766563851\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5978395437331077, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5978395437331077\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.695388745250626, subsample=1.0 will be ignored. Current value: bagging_fraction=0.695388745250626\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5978395437331077, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5978395437331077\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.695388745250626, subsample=1.0 will be ignored. Current value: bagging_fraction=0.695388745250626\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6040001789618271, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6040001789618271\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6010607512842553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6010607512842553\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6040001789618271, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6040001789618271\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6010607512842553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6010607512842553\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8224983929326299, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8224983929326299\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8109525010758685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8109525010758685\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8224983929326299, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8224983929326299\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8109525010758685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8109525010758685\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5413766773266244, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5413766773266244\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5413766773266244, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5413766773266244\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7319015248142358, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319015248142358\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9687211934001123, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9687211934001123\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7319015248142358, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319015248142358\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9687211934001123, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9687211934001123\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9701911127551537, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9701911127551537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988240732519352, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988240732519352\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9701911127551537, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9701911127551537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988240732519352, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988240732519352\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7043591453544604, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7043591453544604\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7043591453544604, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7043591453544604\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8284635523142878, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8284635523142878\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8284635523142878, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8284635523142878\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5007232322168101, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5007232322168101\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5233668230146984, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5233668230146984\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9495968117006099, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9495968117006099\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9642100459094738, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9642100459094738\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9495968117006099, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9495968117006099\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9642100459094738, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9642100459094738\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5263814497514758, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5263814497514758\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6624357179010059, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6624357179010059\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5263814497514758, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5263814497514758\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6624357179010059, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6624357179010059\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5694413101740193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5694413101740193\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5051280271051379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5051280271051379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5694413101740193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5694413101740193\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5051280271051379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5051280271051379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.723226860434972, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.723226860434972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8380397544384568, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380397544384568\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7654820824760737, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7654820824760737\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8380397544384568, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380397544384568\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7654820824760737, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7654820824760737\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9894518292131809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9894518292131809\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.629185830986374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.629185830986374\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5289489218467651, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5289489218467651\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7643458710377254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7643458710377254\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5289489218467651, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5289489218467651\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7643458710377254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7643458710377254\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8916331353364969, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8916331353364969\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5737099059755859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5737099059755859\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8916331353364969, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8916331353364969\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5737099059755859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5737099059755859\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6216679677341995, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6216679677341995\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6162570141151325, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6162570141151325\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6216679677341995, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6216679677341995\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6162570141151325, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6162570141151325\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9956120269464492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9956120269464492\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9190831912766004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9190831912766004\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8782764530210248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8782764530210248\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9835656124421499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9835656124421499\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8782764530210248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8782764530210248\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9835656124421499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9835656124421499\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7634895156575092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7634895156575092\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7552445232092422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7552445232092422\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7634895156575092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7634895156575092\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7552445232092422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7552445232092422\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9480863089293394, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9480863089293394\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.546027248452608, subsample=1.0 will be ignored. Current value: bagging_fraction=0.546027248452608\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9480863089293394, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9480863089293394\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.546027248452608, subsample=1.0 will be ignored. Current value: bagging_fraction=0.546027248452608\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7200918168694508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7200918168694508\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6847684887002612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6847684887002612\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5494369771275383, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5494369771275383\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7702157793924279, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7702157793924279\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5581635896410128, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5581635896410128\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5581635896410128, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5581635896410128\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5918273078858426, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5918273078858426\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5918273078858426, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5918273078858426\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.608887766563851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.608887766563851\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.608887766563851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.608887766563851\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5978395437331077, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5978395437331077\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.695388745250626, subsample=1.0 will be ignored. Current value: bagging_fraction=0.695388745250626\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6040001789618271, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6040001789618271\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6010607512842553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6010607512842553\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6040001789618271, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6040001789618271\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6010607512842553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6010607512842553\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8224983929326299, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8224983929326299\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8109525010758685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8109525010758685\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8224983929326299, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8224983929326299\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8109525010758685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8109525010758685\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5413766773266244, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5413766773266244\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5413766773266244, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5413766773266244\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7319015248142358, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319015248142358\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9687211934001123, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9687211934001123\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7319015248142358, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319015248142358\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9687211934001123, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9687211934001123\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9701911127551537, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9701911127551537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988240732519352, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988240732519352\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9701911127551537, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9701911127551537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988240732519352, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988240732519352\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7043591453544604, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7043591453544604\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7043591453544604, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7043591453544604\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8284635523142878, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8284635523142878\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8284635523142878, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8284635523142878\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5007232322168101, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5007232322168101\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5233668230146984, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5233668230146984\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5007232322168101, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5007232322168101\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5233668230146984, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5233668230146984\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9495968117006099, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9495968117006099\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9642100459094738, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9642100459094738\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9495968117006099, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9495968117006099\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9642100459094738, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9642100459094738\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5263814497514758, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5263814497514758\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6624357179010059, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6624357179010059\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5694413101740193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5694413101740193\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5051280271051379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5051280271051379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5694413101740193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5694413101740193\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5051280271051379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5051280271051379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.723226860434972, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.723226860434972\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7954806102031173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7954806102031173\n",
      "[LightGBM] [Warning] feature_fraction is set=0.723226860434972, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.723226860434972\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7954806102031173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7954806102031173\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6697010314498838, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6697010314498838\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8489173577194873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8489173577194873\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.991501942286271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.991501942286271\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8380397544384568, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380397544384568\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7654820824760737, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7654820824760737\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9894518292131809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9894518292131809\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.629185830986374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.629185830986374\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9894518292131809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9894518292131809\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.629185830986374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.629185830986374\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5289489218467651, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5289489218467651\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7643458710377254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7643458710377254\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5289489218467651, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5289489218467651\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7643458710377254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7643458710377254\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8916331353364969, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8916331353364969\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5737099059755859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5737099059755859\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8916331353364969, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8916331353364969\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5737099059755859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5737099059755859\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6216679677341995, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6216679677341995\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6162570141151325, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6162570141151325\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6216679677341995, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6216679677341995\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6162570141151325, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6162570141151325\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9956120269464492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9956120269464492\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9190831912766004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9190831912766004\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9956120269464492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9956120269464492\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9190831912766004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9190831912766004\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8782764530210248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8782764530210248\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9835656124421499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9835656124421499\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8782764530210248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8782764530210248\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9835656124421499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9835656124421499\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7634895156575092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7634895156575092\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7552445232092422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7552445232092422\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7634895156575092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7634895156575092\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7552445232092422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7552445232092422\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9480863089293394, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9480863089293394\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.546027248452608, subsample=1.0 will be ignored. Current value: bagging_fraction=0.546027248452608\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9480863089293394, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9480863089293394\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.546027248452608, subsample=1.0 will be ignored. Current value: bagging_fraction=0.546027248452608\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7200918168694508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7200918168694508\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6847684887002612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6847684887002612\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7200918168694508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7200918168694508\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6847684887002612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6847684887002612\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5494369771275383, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5494369771275383\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7702157793924279, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7702157793924279\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5581635896410128, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5581635896410128\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5918273078858426, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5918273078858426\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.608887766563851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.608887766563851\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.608887766563851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.608887766563851\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5978395437331077, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5978395437331077\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.695388745250626, subsample=1.0 will be ignored. Current value: bagging_fraction=0.695388745250626\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5978395437331077, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5978395437331077\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.695388745250626, subsample=1.0 will be ignored. Current value: bagging_fraction=0.695388745250626\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6040001789618271, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6040001789618271\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6010607512842553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6010607512842553\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6040001789618271, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6040001789618271\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6010607512842553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6010607512842553\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8224983929326299, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8224983929326299\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8109525010758685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8109525010758685\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5413766773266244, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5413766773266244\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7319015248142358, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319015248142358\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9687211934001123, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9687211934001123\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7319015248142358, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319015248142358\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9687211934001123, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9687211934001123\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9701911127551537, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9701911127551537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988240732519352, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988240732519352\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9701911127551537, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9701911127551537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988240732519352, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988240732519352\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7043591453544604, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7043591453544604\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8284635523142878, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8284635523142878\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5007232322168101, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5007232322168101\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5233668230146984, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5233668230146984\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5007232322168101, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5007232322168101\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5233668230146984, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5233668230146984\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9495968117006099, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9495968117006099\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9642100459094738, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9642100459094738\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9495968117006099, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9495968117006099\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9642100459094738, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9642100459094738\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5263814497514758, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5263814497514758\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6624357179010059, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6624357179010059\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5263814497514758, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5263814497514758\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6624357179010059, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6624357179010059\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5694413101740193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5694413101740193\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5051280271051379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5051280271051379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5694413101740193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5694413101740193\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5051280271051379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5051280271051379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.723226860434972, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.723226860434972\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7954806102031173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7954806102031173\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6697010314498838, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6697010314498838\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8489173577194873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8489173577194873\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.991501942286271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.991501942286271\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.991501942286271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.991501942286271\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8399968249028467, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8399968249028467\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6249500138684704, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6249500138684704\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8399968249028467, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8399968249028467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8380397544384568, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380397544384568\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7654820824760737, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7654820824760737\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8380397544384568, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380397544384568\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7654820824760737, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7654820824760737\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9894518292131809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9894518292131809\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.629185830986374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.629185830986374\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5289489218467651, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5289489218467651\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7643458710377254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7643458710377254\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8916331353364969, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8916331353364969\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5737099059755859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5737099059755859\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8916331353364969, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8916331353364969\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5737099059755859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5737099059755859\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6216679677341995, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6216679677341995\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6162570141151325, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6162570141151325\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6216679677341995, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6216679677341995\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6162570141151325, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6162570141151325\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9956120269464492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9956120269464492\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9190831912766004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9190831912766004\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9956120269464492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9956120269464492\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9190831912766004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9190831912766004\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8782764530210248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8782764530210248\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9835656124421499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9835656124421499\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7634895156575092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7634895156575092\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7552445232092422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7552445232092422\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7634895156575092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7634895156575092\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7552445232092422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7552445232092422\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9480863089293394, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9480863089293394\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.546027248452608, subsample=1.0 will be ignored. Current value: bagging_fraction=0.546027248452608\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7200918168694508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7200918168694508\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6847684887002612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6847684887002612\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7200918168694508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7200918168694508\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6847684887002612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6847684887002612\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5494369771275383, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5494369771275383\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7702157793924279, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7702157793924279\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5494369771275383, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5494369771275383\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7702157793924279, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7702157793924279\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5581635896410128, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5581635896410128\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5581635896410128, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5581635896410128\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5918273078858426, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5918273078858426\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5918273078858426, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5918273078858426\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.608887766563851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.608887766563851\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.608887766563851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.608887766563851\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5978395437331077, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5978395437331077\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.695388745250626, subsample=1.0 will be ignored. Current value: bagging_fraction=0.695388745250626\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6040001789618271, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6040001789618271\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6010607512842553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6010607512842553\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8224983929326299, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8224983929326299\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8109525010758685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8109525010758685\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8224983929326299, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8224983929326299\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8109525010758685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8109525010758685\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5413766773266244, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5413766773266244\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5413766773266244, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5413766773266244\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7319015248142358, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319015248142358\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9687211934001123, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9687211934001123\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7319015248142358, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319015248142358\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9687211934001123, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9687211934001123\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9701911127551537, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9701911127551537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988240732519352, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988240732519352\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7043591453544604, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7043591453544604\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8284635523142878, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8284635523142878\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8284635523142878, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8284635523142878\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5007232322168101, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5007232322168101\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5233668230146984, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5233668230146984\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5007232322168101, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5007232322168101\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5233668230146984, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5233668230146984\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9495968117006099, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9495968117006099\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9642100459094738, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9642100459094738\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5263814497514758, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5263814497514758\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6624357179010059, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6624357179010059\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5263814497514758, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5263814497514758\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6624357179010059, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6624357179010059\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5694413101740193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5694413101740193\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5051280271051379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5051280271051379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.723226860434972, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.723226860434972\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7954806102031173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7954806102031173\n",
      "[LightGBM] [Warning] feature_fraction is set=0.723226860434972, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.723226860434972\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7954806102031173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7954806102031173\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6697010314498838, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6697010314498838\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8489173577194873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8489173577194873\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6697010314498838, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6697010314498838\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8489173577194873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8489173577194873\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.991501942286271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.991501942286271\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.991501942286271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.991501942286271\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8399968249028467, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8399968249028467\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6249500138684704, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6249500138684704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8380397544384568, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380397544384568\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7654820824760737, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7654820824760737\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9894518292131809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9894518292131809\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.629185830986374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.629185830986374\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9894518292131809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9894518292131809\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.629185830986374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.629185830986374\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5289489218467651, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5289489218467651\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7643458710377254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7643458710377254\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8916331353364969, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8916331353364969\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5737099059755859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5737099059755859\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6216679677341995, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6216679677341995\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6162570141151325, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6162570141151325\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9956120269464492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9956120269464492\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9190831912766004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9190831912766004\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9956120269464492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9956120269464492\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9190831912766004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9190831912766004\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8782764530210248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8782764530210248\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9835656124421499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9835656124421499\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8782764530210248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8782764530210248\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9835656124421499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9835656124421499\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7634895156575092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7634895156575092\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7552445232092422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7552445232092422\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9480863089293394, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9480863089293394\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.546027248452608, subsample=1.0 will be ignored. Current value: bagging_fraction=0.546027248452608\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9480863089293394, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9480863089293394\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.546027248452608, subsample=1.0 will be ignored. Current value: bagging_fraction=0.546027248452608\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7200918168694508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7200918168694508\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6847684887002612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6847684887002612\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5494369771275383, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5494369771275383\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7702157793924279, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7702157793924279\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5494369771275383, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5494369771275383\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7702157793924279, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7702157793924279\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5581635896410128, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5581635896410128\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5918273078858426, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5918273078858426\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5918273078858426, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5918273078858426\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.608887766563851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.608887766563851\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.608887766563851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.608887766563851\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5978395437331077, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5978395437331077\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.695388745250626, subsample=1.0 will be ignored. Current value: bagging_fraction=0.695388745250626\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5978395437331077, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5978395437331077\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.695388745250626, subsample=1.0 will be ignored. Current value: bagging_fraction=0.695388745250626\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6040001789618271, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6040001789618271\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6010607512842553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6010607512842553\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8224983929326299, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8224983929326299\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8109525010758685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8109525010758685\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5413766773266244, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5413766773266244\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7319015248142358, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319015248142358\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9687211934001123, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9687211934001123\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9701911127551537, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9701911127551537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988240732519352, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988240732519352\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9701911127551537, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9701911127551537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988240732519352, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988240732519352\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7043591453544604, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7043591453544604\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7043591453544604, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7043591453544604\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8284635523142878, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8284635523142878\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8284635523142878, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8284635523142878\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5007232322168101, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5007232322168101\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5233668230146984, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5233668230146984\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9495968117006099, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9495968117006099\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9642100459094738, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9642100459094738\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5263814497514758, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5263814497514758\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6624357179010059, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6624357179010059\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5263814497514758, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5263814497514758\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6624357179010059, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6624357179010059\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5694413101740193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5694413101740193\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5051280271051379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5051280271051379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5694413101740193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5694413101740193\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5051280271051379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5051280271051379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.723226860434972, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.723226860434972\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7954806102031173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7954806102031173\n",
      "[LightGBM] [Warning] feature_fraction is set=0.723226860434972, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.723226860434972\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7954806102031173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7954806102031173\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6697010314498838, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6697010314498838\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8489173577194873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8489173577194873\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6697010314498838, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6697010314498838\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8489173577194873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8489173577194873\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.991501942286271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.991501942286271\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8399968249028467, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8399968249028467\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6249500138684704, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6249500138684704\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8399968249028467, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8399968249028467\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6249500138684704, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6249500138684704\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9091900732331768, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9091900732331768\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9091900732331768, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9091900732331768\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7199533731256063, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7199533731256063\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7199533731256063, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7199533731256063\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728216607363545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728216607363545\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6437844134547452, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6437844134547452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8380397544384568, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380397544384568\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7654820824760737, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7654820824760737\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8380397544384568, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8380397544384568\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7654820824760737, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7654820824760737\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9894518292131809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9894518292131809\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.629185830986374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.629185830986374\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9894518292131809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9894518292131809\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.629185830986374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.629185830986374\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5289489218467651, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5289489218467651\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7643458710377254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7643458710377254\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5289489218467651, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5289489218467651\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7643458710377254, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7643458710377254\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8916331353364969, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8916331353364969\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5737099059755859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5737099059755859\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8916331353364969, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8916331353364969\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5737099059755859, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5737099059755859\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6216679677341995, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6216679677341995\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6162570141151325, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6162570141151325\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9956120269464492, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9956120269464492\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9190831912766004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9190831912766004\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8782764530210248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8782764530210248\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9835656124421499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9835656124421499\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7634895156575092, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7634895156575092\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7552445232092422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7552445232092422\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9480863089293394, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9480863089293394\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.546027248452608, subsample=1.0 will be ignored. Current value: bagging_fraction=0.546027248452608\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7200918168694508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7200918168694508\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6847684887002612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6847684887002612\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7200918168694508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7200918168694508\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6847684887002612, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6847684887002612\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5494369771275383, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5494369771275383\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7702157793924279, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7702157793924279\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5494369771275383, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5494369771275383\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7702157793924279, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7702157793924279\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5581635896410128, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5581635896410128\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5581635896410128, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5581635896410128\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5918273078858426, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5918273078858426\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.608887766563851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.608887766563851\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5978395437331077, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5978395437331077\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.695388745250626, subsample=1.0 will be ignored. Current value: bagging_fraction=0.695388745250626\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5978395437331077, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5978395437331077\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.695388745250626, subsample=1.0 will be ignored. Current value: bagging_fraction=0.695388745250626\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6040001789618271, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6040001789618271\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6010607512842553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6010607512842553\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6040001789618271, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6040001789618271\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6010607512842553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6010607512842553\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8224983929326299, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8224983929326299\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8109525010758685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8109525010758685\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8224983929326299, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8224983929326299\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8109525010758685, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8109525010758685\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5413766773266244, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5413766773266244\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5413766773266244, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5413766773266244\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7319015248142358, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7319015248142358\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9687211934001123, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9687211934001123\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9701911127551537, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9701911127551537\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7988240732519352, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7988240732519352\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7043591453544604, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7043591453544604\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7043591453544604, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7043591453544604\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8284635523142878, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8284635523142878\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5007232322168101, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5007232322168101\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5233668230146984, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5233668230146984\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5007232322168101, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5007232322168101\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5233668230146984, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5233668230146984\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9495968117006099, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9495968117006099\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9642100459094738, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9642100459094738\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9495968117006099, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9495968117006099\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9642100459094738, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9642100459094738\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5263814497514758, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5263814497514758\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6624357179010059, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6624357179010059\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5694413101740193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5694413101740193\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5051280271051379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5051280271051379\n",
      "[LightGBM] [Warning] feature_fraction is set=0.723226860434972, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.723226860434972\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7954806102031173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7954806102031173\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6697010314498838, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6697010314498838\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8489173577194873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8489173577194873\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6697010314498838, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6697010314498838\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8489173577194873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8489173577194873\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.991501942286271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.991501942286271\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8399968249028467, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8399968249028467\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6249500138684704, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6249500138684704\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9091900732331768, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9091900732331768\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7199533731256063, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7199533731256063\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728216607363545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728216607363545\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6437844134547452, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6437844134547452\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5899544838425143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5899544838425143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.7954806102031173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7954806102031173\n",
      "[LightGBM] [Warning] feature_fraction is set=0.723226860434972, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.723226860434972\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7954806102031173, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7954806102031173\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6697010314498838, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6697010314498838\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8489173577194873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8489173577194873\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6697010314498838, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6697010314498838\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8489173577194873, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8489173577194873\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.991501942286271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.991501942286271\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.991501942286271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.991501942286271\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8399968249028467, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8399968249028467\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6249500138684704, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6249500138684704\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8399968249028467, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8399968249028467\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6249500138684704, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6249500138684704\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9091900732331768, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9091900732331768\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9091900732331768, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9091900732331768\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7199533731256063, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7199533731256063\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7199533731256063, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7199533731256063\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728216607363545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728216607363545\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728216607363545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728216607363545\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6437844134547452, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6437844134547452\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6437844134547452, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6437844134547452\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5899544838425143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5899544838425143\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5899544838425143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5899544838425143\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7276147634418255, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7276147634418255\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7276147634418255, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7276147634418255\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7382668290280634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7382668290280634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7382668290280634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7382668290280634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9398644747208972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9398644747208972\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5345692040165404, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5345692040165404\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5345692040165404, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5345692040165404\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9698399160129514, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9698399160129514\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9856124647994302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9856124647994302\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9856124647994302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9856124647994302\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6389064676271512, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6389064676271512\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6389064676271512, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6389064676271512\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118929555283037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118929555283037\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118929555283037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118929555283037\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7082843226968932, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7082843226968932\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7082843226968932, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7082843226968932\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9426618146192435, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9426618146192435\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7065451482709622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7065451482709622\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9426618146192435, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9426618146192435\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7065451482709622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7065451482709622\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7388928029926499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7388928029926499\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7388928029926499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7388928029926499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.6249500138684704, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6249500138684704\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9091900732331768, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9091900732331768\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9091900732331768, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9091900732331768\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7199533731256063, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7199533731256063\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7199533731256063, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7199533731256063\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728216607363545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728216607363545\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728216607363545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728216607363545\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6437844134547452, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6437844134547452\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6437844134547452, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6437844134547452\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5899544838425143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5899544838425143\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5899544838425143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5899544838425143\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7276147634418255, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7276147634418255\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7276147634418255, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7276147634418255\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7382668290280634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7382668290280634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7382668290280634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7382668290280634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9398644747208972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9398644747208972\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9398644747208972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9398644747208972\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5345692040165404, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5345692040165404\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5345692040165404, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5345692040165404\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9698399160129514, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9698399160129514\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9856124647994302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9856124647994302\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6389064676271512, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6389064676271512\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118929555283037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118929555283037\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7082843226968932, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7082843226968932\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9426618146192435, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9426618146192435\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7065451482709622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7065451482709622\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7388928029926499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7388928029926499\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7388928029926499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7388928029926499\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5276954526883374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5276954526883374\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5276954526883374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5276954526883374\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6189633097648055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6189633097648055\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6189633097648055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6189633097648055\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7327978832817351, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7327978832817351\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8778014457239963, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8778014457239963\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7327978832817351, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7327978832817351\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8778014457239963, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8778014457239963\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9756908253050366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9756908253050366\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9756908253050366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9756908253050366\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7272057454468276, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272057454468276\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5602471751326271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5602471751326271\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7272057454468276, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272057454468276\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5602471751326271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5602471751326271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9091900732331768, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9091900732331768\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7199533731256063, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7199533731256063\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728216607363545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728216607363545\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728216607363545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728216607363545\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6437844134547452, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6437844134547452\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5899544838425143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5899544838425143\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5899544838425143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5899544838425143\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7276147634418255, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7276147634418255\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7382668290280634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7382668290280634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9398644747208972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9398644747208972\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9398644747208972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9398644747208972\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5345692040165404, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5345692040165404\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5345692040165404, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5345692040165404\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9698399160129514, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9698399160129514\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9698399160129514, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9698399160129514\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9856124647994302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9856124647994302\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9856124647994302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9856124647994302\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6389064676271512, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6389064676271512\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118929555283037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118929555283037\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118929555283037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118929555283037\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7082843226968932, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7082843226968932\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7082843226968932, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7082843226968932\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9426618146192435, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9426618146192435\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7065451482709622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7065451482709622\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9426618146192435, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9426618146192435\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7065451482709622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7065451482709622\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7388928029926499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7388928029926499\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5276954526883374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5276954526883374\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6189633097648055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6189633097648055\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6189633097648055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6189633097648055\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7327978832817351, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7327978832817351\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8778014457239963, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8778014457239963\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7327978832817351, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7327978832817351\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8778014457239963, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8778014457239963\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9756908253050366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9756908253050366\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7272057454468276, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272057454468276\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5602471751326271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5602471751326271\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7272057454468276, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272057454468276\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5602471751326271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5602471751326271\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829546076664571, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829546076664571\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829546076664571, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829546076664571\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.991501942286271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.991501942286271\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8399968249028467, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8399968249028467\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6249500138684704, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6249500138684704\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8399968249028467, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8399968249028467\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6249500138684704, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6249500138684704\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9091900732331768, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9091900732331768\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9091900732331768, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9091900732331768\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7199533731256063, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7199533731256063\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7199533731256063, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7199533731256063\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728216607363545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728216607363545\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728216607363545, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728216607363545\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6437844134547452, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6437844134547452\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6437844134547452, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6437844134547452\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5899544838425143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5899544838425143\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7276147634418255, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7276147634418255\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7276147634418255, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7276147634418255\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7382668290280634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7382668290280634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7382668290280634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7382668290280634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9398644747208972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9398644747208972\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9398644747208972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9398644747208972\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5345692040165404, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5345692040165404\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5345692040165404, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5345692040165404\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9698399160129514, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9698399160129514\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9698399160129514, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9698399160129514\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9856124647994302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9856124647994302\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9856124647994302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9856124647994302\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6389064676271512, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6389064676271512\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6389064676271512, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6389064676271512\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118929555283037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118929555283037\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118929555283037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118929555283037\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7082843226968932, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7082843226968932\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9426618146192435, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9426618146192435\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7065451482709622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7065451482709622\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7388928029926499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7388928029926499\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7388928029926499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7388928029926499\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5276954526883374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5276954526883374\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6189633097648055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6189633097648055\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7327978832817351, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7327978832817351\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8778014457239963, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8778014457239963\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7327978832817351, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7327978832817351\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8778014457239963, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8778014457239963\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9756908253050366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9756908253050366\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9756908253050366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9756908253050366\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6437844134547452, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6437844134547452\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5899544838425143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5899544838425143\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5899544838425143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5899544838425143\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7276147634418255, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7276147634418255\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7276147634418255, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7276147634418255\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7382668290280634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7382668290280634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7382668290280634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7382668290280634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9398644747208972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9398644747208972\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5345692040165404, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5345692040165404\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9698399160129514, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9698399160129514\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9698399160129514, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9698399160129514\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9856124647994302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9856124647994302\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9856124647994302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9856124647994302\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6389064676271512, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6389064676271512\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6389064676271512, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6389064676271512\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118929555283037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118929555283037\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7082843226968932, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7082843226968932\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7082843226968932, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7082843226968932\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9426618146192435, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9426618146192435\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7065451482709622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7065451482709622\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9426618146192435, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9426618146192435\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7065451482709622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7065451482709622\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7388928029926499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7388928029926499\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7388928029926499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7388928029926499\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5276954526883374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5276954526883374\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5276954526883374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5276954526883374\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6189633097648055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6189633097648055\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6189633097648055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6189633097648055\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7327978832817351, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7327978832817351\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8778014457239963, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8778014457239963\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9756908253050366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9756908253050366\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9756908253050366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9756908253050366\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7272057454468276, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272057454468276\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5602471751326271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5602471751326271\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829546076664571, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829546076664571\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.722172192797577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.722172192797577\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9457936447726392, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9457936447726392\n",
      "[LightGBM] [Warning] feature_fraction is set=0.722172192797577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.722172192797577\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9457936447726392, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9457936447726392\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5251181027794909, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5251181027794909\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5251181027794909, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5251181027794909\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7467555456720641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7467555456720641\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7213088905100546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213088905100546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "\n",
      "LightGBM :   -0.305\n",
      "164.7 min\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLR :   -15803796307.459\n",
      "11.4 min\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.208e+01, tolerance: 1.840e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e+01, tolerance: 1.942e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.137e+01, tolerance: 1.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+01, tolerance: 1.835e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.310e+01, tolerance: 1.896e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.515e+01, tolerance: 1.937e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.442e+01, tolerance: 1.914e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.584e+01, tolerance: 1.918e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.953e+01, tolerance: 1.877e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.417e+01, tolerance: 1.936e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.087e+02, tolerance: 1.840e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.303e+01, tolerance: 1.942e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.090e+01, tolerance: 1.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.717e+01, tolerance: 1.835e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.630e+02, tolerance: 1.937e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.034e+01, tolerance: 1.896e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e+02, tolerance: 1.918e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.221e+01, tolerance: 1.914e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.690e+01, tolerance: 1.936e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.915e+01, tolerance: 1.877e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e+01, tolerance: 1.840e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.451e+01, tolerance: 1.942e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.476e+01, tolerance: 1.937e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.467e+01, tolerance: 1.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.012e+01, tolerance: 1.896e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.952e+01, tolerance: 1.835e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.351e+01, tolerance: 1.914e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.407e+01, tolerance: 1.877e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.631e+01, tolerance: 1.936e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.452e+01, tolerance: 1.918e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.362e+02, tolerance: 1.942e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.519e+02, tolerance: 1.896e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.862e+02, tolerance: 1.937e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.712e+02, tolerance: 1.840e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+02, tolerance: 1.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.398e+02, tolerance: 1.835e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.325e+02, tolerance: 1.936e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.433e+02, tolerance: 1.877e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.509e+01, tolerance: 1.914e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.671e+02, tolerance: 1.918e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.943e+02, tolerance: 1.937e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.544e+02, tolerance: 1.840e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.025e+02, tolerance: 1.942e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.720e+02, tolerance: 1.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.322e+02, tolerance: 1.835e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.640e+02, tolerance: 1.896e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.152e+02, tolerance: 1.914e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.615e+02, tolerance: 1.918e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.772e+02, tolerance: 1.877e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.955e+02, tolerance: 1.936e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.526e+00, tolerance: 1.937e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.983e+00, tolerance: 1.840e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.129e+00, tolerance: 1.835e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.480e+00, tolerance: 1.896e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.702e+00, tolerance: 1.942e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.156e+00, tolerance: 1.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.411e+00, tolerance: 1.914e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.580e+00, tolerance: 1.936e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.256e+01, tolerance: 1.877e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.593e+00, tolerance: 1.918e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.489e+02, tolerance: 1.937e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e+02, tolerance: 1.840e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.108e+02, tolerance: 1.942e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.452e+02, tolerance: 1.896e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.173e+02, tolerance: 1.835e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.135e+02, tolerance: 1.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.052e+02, tolerance: 1.914e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.964e+02, tolerance: 1.877e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+02, tolerance: 1.918e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.862e+02, tolerance: 1.936e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e+02, tolerance: 1.942e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.727e+01, tolerance: 1.840e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.864e+01, tolerance: 1.937e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.176e+01, tolerance: 1.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.381e+01, tolerance: 1.896e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.279e+01, tolerance: 1.835e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.592e+01, tolerance: 1.877e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.377e+01, tolerance: 1.914e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.372e+01, tolerance: 1.936e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.141e+01, tolerance: 1.918e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.113e+00, tolerance: 1.896e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.390e+00, tolerance: 1.937e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.562e+00, tolerance: 1.942e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.058e+00, tolerance: 1.840e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.044e+00, tolerance: 1.835e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.927e+00, tolerance: 1.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.341e+00, tolerance: 1.914e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.816e+00, tolerance: 1.877e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.681e+00, tolerance: 1.936e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.067e+00, tolerance: 1.918e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.842e+02, tolerance: 1.840e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.097e+01, tolerance: 1.896e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.193e+02, tolerance: 1.835e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.801e+02, tolerance: 1.942e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.935e+02, tolerance: 1.937e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.295e+02, tolerance: 1.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.110e+02, tolerance: 1.918e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.494e+02, tolerance: 1.914e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.571e+02, tolerance: 1.936e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.861e+02, tolerance: 1.877e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.902e+00, tolerance: 1.937e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.587e+02, tolerance: 1.942e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.943e+01, tolerance: 1.840e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.216e+01, tolerance: 1.835e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.555e+01, tolerance: 1.896e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.633e+01, tolerance: 1.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.040e+01, tolerance: 1.937e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.511e+01, tolerance: 1.918e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.401e+01, tolerance: 1.914e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.117e+01, tolerance: 1.877e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+01, tolerance: 1.936e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.940e+01, tolerance: 1.840e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.080e+02, tolerance: 1.942e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.309e+02, tolerance: 1.896e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.028e+01, tolerance: 1.835e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.038e+01, tolerance: 1.937e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e+02, tolerance: 1.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.131e+02, tolerance: 1.918e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.036e+02, tolerance: 1.914e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.462e+01, tolerance: 1.877e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.095e+02, tolerance: 1.936e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.038e+02, tolerance: 1.942e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.687e+02, tolerance: 1.937e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.434e+02, tolerance: 1.840e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.520e+02, tolerance: 1.896e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.954e+02, tolerance: 1.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.121e+02, tolerance: 1.835e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.387e+02, tolerance: 1.918e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.225e+02, tolerance: 1.914e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.385e+02, tolerance: 1.936e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.474e+02, tolerance: 1.877e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.578e+00, tolerance: 1.937e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.597e+00, tolerance: 1.835e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.855e+00, tolerance: 1.840e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.017e+00, tolerance: 1.942e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.102e+01, tolerance: 1.896e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.034e+01, tolerance: 1.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.846e+00, tolerance: 1.936e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.729e+01, tolerance: 1.877e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.028e+00, tolerance: 1.914e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.265e+01, tolerance: 1.918e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.379e+01, tolerance: 1.942e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.369e+01, tolerance: 1.896e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.119e+01, tolerance: 1.937e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.642e+00, tolerance: 1.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.345e+00, tolerance: 1.840e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.550e+01, tolerance: 1.835e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.502e+00, tolerance: 1.914e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.704e+00, tolerance: 1.936e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.264e+01, tolerance: 1.918e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.515e+01, tolerance: 1.877e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.351e+00, tolerance: 1.840e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso :   -0.421\n",
      "11.6 min\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PLS :   -0.517\n",
      "2.9 min\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "kNN :   -0.373\n",
      "32.8 min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_names:\n",
    "    \n",
    "    start = time.time()\n",
    "    search_space = search_spaces[model_name]\n",
    "    best_model, best_params, best_score, history = perform_hp_screening(model_name, X_train, Y_train, G_train, n_iter)\n",
    "    end = time.time()\n",
    "    \n",
    "    print()\n",
    "    print(model_name, ':  ', round(best_score,3))\n",
    "    print(round((end-start)/60, 1), 'min')\n",
    "    print()\n",
    "    \n",
    "    # Storing the results in a dictionary\n",
    "    results[model_name] = {\n",
    "        'best_estimator': best_model,\n",
    "        'best_params': best_params,\n",
    "        'best_score': best_score,\n",
    "        'optimization_history': history\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72c9f6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_path = 'Results/BSCV_results' + data_for + '.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1901ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(pickle_file_path, 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfb61834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DT': {'best_estimator': DecisionTreeRegressor(max_depth=18, max_features='auto', min_samples_leaf=11,\n",
       "                        min_samples_split=0.01, random_state=0,\n",
       "                        splitter='random'),\n",
       "  'best_params': OrderedDict([('max_depth', 18),\n",
       "               ('max_features', 'auto'),\n",
       "               ('min_samples_leaf', 11),\n",
       "               ('min_samples_split', 0.01),\n",
       "               ('splitter', 'random')]),\n",
       "  'best_score': -0.4665007735070127,\n",
       "  'optimization_history': {'mean_fit_time': array([0.06444557, 0.05993116, 0.35278938, 0.05164249, 0.30139582,\n",
       "          0.05754099, 0.05863295, 0.04998333, 0.05091996, 0.04465866,\n",
       "          0.24865863, 0.24407685, 0.0404382 , 0.3282182 , 0.40103009,\n",
       "          0.40326896, 0.27934649, 0.04913116, 0.11029584, 0.17482154,\n",
       "          0.2515063 , 0.29328344, 0.26692834, 0.06014693, 0.06114199,\n",
       "          0.39405904, 0.4072279 , 0.18547277, 0.21863885, 0.30702975,\n",
       "          0.04858654, 0.20396349, 0.30914176, 0.43438749, 0.43934023,\n",
       "          0.4147933 , 0.2961808 , 0.44013569, 0.41896222, 0.41922343,\n",
       "          0.29106612, 0.29894636, 0.31079252, 0.06372745, 0.41271064,\n",
       "          0.40264022, 0.39617658, 0.37166371, 0.40166242, 0.0605125 ,\n",
       "          0.30740809, 0.39926381, 0.39950614, 0.04509392, 0.37034783,\n",
       "          0.40610733, 0.40160272, 0.39554293, 0.05267971, 0.38985138,\n",
       "          0.3992069 , 0.38523669, 0.4006351 , 0.29005671, 0.38967388,\n",
       "          0.27830663, 0.32278509, 0.26870456, 0.41525209, 0.28524311,\n",
       "          0.40469143, 0.29092996, 0.29496732, 0.27307594, 0.31978669,\n",
       "          0.39625437, 0.29032323, 0.3937324 , 0.28704524, 0.2892391 ,\n",
       "          0.05341897, 0.10813532, 0.28486359, 0.0486661 , 0.37410221,\n",
       "          0.29097316, 0.28967667, 0.0612669 , 0.28770714, 0.05175271,\n",
       "          0.06205027, 0.29535322, 0.28464098, 0.06145344, 0.28307228,\n",
       "          0.29339445, 0.28642747, 0.2833811 , 0.05188341, 0.28712103]),\n",
       "   'std_fit_time': array([0.01756044, 0.01234368, 0.03118226, 0.00934264, 0.02268489,\n",
       "          0.00700962, 0.00641193, 0.00650039, 0.00619714, 0.00640292,\n",
       "          0.01853608, 0.02220011, 0.0032465 , 0.03360643, 0.04041129,\n",
       "          0.02731873, 0.02804098, 0.00623617, 0.00598612, 0.01634001,\n",
       "          0.02584583, 0.04330277, 0.02359281, 0.00517999, 0.00643615,\n",
       "          0.0437531 , 0.0329514 , 0.02395602, 0.03114972, 0.04461717,\n",
       "          0.00561649, 0.03417023, 0.05636994, 0.05176088, 0.04720267,\n",
       "          0.04129034, 0.04096924, 0.05532343, 0.05070279, 0.04723489,\n",
       "          0.03522222, 0.03272277, 0.04213239, 0.00605109, 0.0435789 ,\n",
       "          0.03344025, 0.03619653, 0.03987597, 0.03743899, 0.00372035,\n",
       "          0.03041086, 0.03797851, 0.03734693, 0.00559614, 0.03038335,\n",
       "          0.04087592, 0.03641339, 0.03557522, 0.00584534, 0.0309536 ,\n",
       "          0.03918194, 0.03378813, 0.03220297, 0.02905787, 0.03223275,\n",
       "          0.02778896, 0.02457024, 0.03080674, 0.0418251 , 0.03206493,\n",
       "          0.04368657, 0.03042152, 0.02878917, 0.03416589, 0.02703282,\n",
       "          0.03264869, 0.0362281 , 0.03869503, 0.0356666 , 0.03533428,\n",
       "          0.00426049, 0.00808002, 0.03152216, 0.00595054, 0.03071674,\n",
       "          0.04259874, 0.03100924, 0.00423557, 0.03023655, 0.00378267,\n",
       "          0.0043636 , 0.03451255, 0.03071332, 0.00590641, 0.03301451,\n",
       "          0.03293791, 0.03272363, 0.03419693, 0.00545556, 0.03311846]),\n",
       "   'mean_score_time': array([0.00451424, 0.00454924, 0.00477366, 0.00545738, 0.00421231,\n",
       "          0.00341823, 0.00409994, 0.00392532, 0.0035578 , 0.00391231,\n",
       "          0.00416405, 0.00404317, 0.00373816, 0.00417945, 0.00403965,\n",
       "          0.00441387, 0.00488391, 0.00402634, 0.00400639, 0.00435307,\n",
       "          0.00364034, 0.00442724, 0.00692484, 0.00478649, 0.00391498,\n",
       "          0.00371654, 0.00500736, 0.00438669, 0.00424123, 0.00444357,\n",
       "          0.0044487 , 0.00453999, 0.00434799, 0.00414386, 0.00387065,\n",
       "          0.0048032 , 0.0041151 , 0.00414612, 0.00408554, 0.00371573,\n",
       "          0.00445788, 0.0042146 , 0.00463939, 0.00442405, 0.00347724,\n",
       "          0.00403118, 0.00428193, 0.00486987, 0.00470326, 0.00414128,\n",
       "          0.00372834, 0.00363021, 0.00405512, 0.00408473, 0.00439842,\n",
       "          0.0034761 , 0.0040338 , 0.00463419, 0.00362184, 0.00396945,\n",
       "          0.00537479, 0.0040591 , 0.0041502 , 0.00356853, 0.00381496,\n",
       "          0.00368361, 0.00376348, 0.00410025, 0.00409265, 0.00453699,\n",
       "          0.00384543, 0.0046556 , 0.00421205, 0.00420682, 0.00380747,\n",
       "          0.00424705, 0.00521522, 0.00375583, 0.00408735, 0.00344625,\n",
       "          0.00382686, 0.00517008, 0.00456324, 0.00395045, 0.00347838,\n",
       "          0.00410929, 0.00455618, 0.00457358, 0.00391243, 0.00447271,\n",
       "          0.00406439, 0.00475082, 0.00405483, 0.00418477, 0.00361607,\n",
       "          0.00477281, 0.00414746, 0.00452752, 0.00381842, 0.00357392]),\n",
       "   'std_score_time': array([0.00070947, 0.00112226, 0.00214391, 0.00215739, 0.00190041,\n",
       "          0.00022578, 0.00110454, 0.00072859, 0.00037426, 0.00084555,\n",
       "          0.00185301, 0.00117884, 0.00044988, 0.00181698, 0.00122751,\n",
       "          0.00136755, 0.00244114, 0.00085474, 0.00180055, 0.0019796 ,\n",
       "          0.00052632, 0.00209619, 0.00377258, 0.00241487, 0.00095759,\n",
       "          0.00094634, 0.0031256 , 0.00144996, 0.00190209, 0.00174414,\n",
       "          0.00131576, 0.00154476, 0.0016584 , 0.00150043, 0.00067447,\n",
       "          0.0027851 , 0.00142876, 0.00155071, 0.00177662, 0.00090063,\n",
       "          0.00201109, 0.00156888, 0.00184188, 0.00141395, 0.00022819,\n",
       "          0.00181646, 0.00198427, 0.00217053, 0.00212764, 0.00136849,\n",
       "          0.00114294, 0.00062849, 0.00179745, 0.00134895, 0.00220829,\n",
       "          0.00036131, 0.00092965, 0.00251397, 0.00072641, 0.00117884,\n",
       "          0.00298688, 0.0011776 , 0.00149079, 0.00035877, 0.00098509,\n",
       "          0.00069159, 0.00112678, 0.00138139, 0.00160055, 0.00193742,\n",
       "          0.00072677, 0.0023072 , 0.00163169, 0.00227883, 0.00114271,\n",
       "          0.00158673, 0.00274867, 0.00114906, 0.00128103, 0.00025345,\n",
       "          0.0010878 , 0.00229167, 0.00200774, 0.00111073, 0.00026678,\n",
       "          0.00158471, 0.00219734, 0.00219377, 0.00118165, 0.00141003,\n",
       "          0.00171092, 0.00235963, 0.00143712, 0.0017849 , 0.00034129,\n",
       "          0.00261369, 0.00160381, 0.00211946, 0.00105853, 0.0003237 ]),\n",
       "   'param_max_depth': masked_array(data=[12, 7, 12, 6, 7, 17, 19, 12, 5, 9, 5, 9, 3, 10, 13, 18,\n",
       "                      19, 20, 3, 3, 20, 15, 20, 20, 20, 14, 20, 3, 20, 14,\n",
       "                      20, 13, 14, 15, 15, 15, 18, 20, 12, 14, 13, 17, 17, 20,\n",
       "                      16, 12, 11, 10, 12, 15, 20, 12, 12, 3, 9, 18, 16, 12,\n",
       "                      20, 11, 19, 10, 18, 18, 12, 14, 7, 11, 15, 15, 11, 17,\n",
       "                      15, 15, 9, 15, 15, 11, 20, 16, 16, 3, 20, 12, 11, 15,\n",
       "                      18, 10, 15, 3, 20, 19, 15, 17, 15, 18, 20, 15, 14, 18],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_features': masked_array(data=['log2', 'sqrt', 'auto', 'sqrt', 'auto', 'sqrt', 'sqrt',\n",
       "                      'log2', 'sqrt', 'log2', 'auto', 'auto', 'sqrt', 'auto',\n",
       "                      'auto', 'auto', 'auto', 'log2', 'auto', 'auto', 'auto',\n",
       "                      'auto', 'auto', 'sqrt', 'sqrt', 'auto', 'auto', 'auto',\n",
       "                      'auto', 'auto', 'log2', 'auto', 'auto', 'auto', 'auto',\n",
       "                      'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                      'auto', 'sqrt', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                      'sqrt', 'auto', 'auto', 'auto', 'log2', 'auto', 'auto',\n",
       "                      'auto', 'auto', 'log2', 'auto', 'auto', 'auto', 'auto',\n",
       "                      'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                      'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                      'auto', 'auto', 'auto', 'log2', 'auto', 'auto', 'sqrt',\n",
       "                      'auto', 'auto', 'auto', 'sqrt', 'auto', 'log2', 'sqrt',\n",
       "                      'auto', 'auto', 'sqrt', 'auto', 'auto', 'auto', 'auto',\n",
       "                      'log2', 'auto'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_min_samples_leaf': masked_array(data=[13, 18, 8, 10, 15, 15, 9, 15, 16, 6, 3, 17, 1, 20, 20,\n",
       "                      20, 1, 1, 14, 14, 2, 1, 20, 20, 18, 20, 20, 7, 4, 1, 1,\n",
       "                      8, 20, 1, 6, 1, 20, 3, 7, 10, 1, 1, 1, 20, 20, 20, 20,\n",
       "                      20, 20, 1, 20, 20, 20, 20, 1, 8, 9, 20, 20, 20, 17, 11,\n",
       "                      1, 1, 20, 5, 20, 20, 12, 8, 1, 6, 6, 6, 1, 20, 6, 16,\n",
       "                      8, 7, 20, 1, 1, 1, 20, 6, 6, 20, 7, 1, 1, 6, 6, 20, 6,\n",
       "                      4, 1, 7, 1, 11],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_min_samples_split': masked_array(data=[0.06820119469644915, 0.06394077902553194,\n",
       "                      0.027231907778595785, 0.050954987496724294,\n",
       "                      0.035698379447037194, 0.053755559059457544,\n",
       "                      0.026585131394449422, 0.012456546518247541,\n",
       "                      0.09400914937055956, 0.08183069151341117,\n",
       "                      0.02830964697195451, 0.01, 0.01, 0.038210833692354146,\n",
       "                      0.01, 0.01, 0.01, 0.01, 0.09380984081274953, 0.01,\n",
       "                      0.029122097557848267, 0.01, 0.1, 0.01, 0.1,\n",
       "                      0.013906606462437597, 0.01, 0.05274240645427632,\n",
       "                      0.06887863406266764, 0.01, 0.1, 0.1, 0.01, 0.01, 0.01,\n",
       "                      0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                      0.01, 0.01, 0.01, 0.016284179772286005, 0.01, 0.01,\n",
       "                      0.05743908025538613, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                      0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                      0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                      0.017194559410837622, 0.04046265688670721, 0.01, 0.01,\n",
       "                      0.01, 0.01, 0.01, 0.01, 0.1, 0.01, 0.1,\n",
       "                      0.017133983728503447, 0.01, 0.01, 0.01, 0.01, 0.1,\n",
       "                      0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                      0.01],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_splitter': masked_array(data=['random', 'best', 'best', 'random', 'best', 'best',\n",
       "                      'best', 'best', 'best', 'best', 'best', 'random',\n",
       "                      'random', 'best', 'best', 'best', 'random', 'random',\n",
       "                      'random', 'best', 'random', 'random', 'best', 'random',\n",
       "                      'best', 'best', 'best', 'best', 'random', 'random',\n",
       "                      'random', 'random', 'random', 'best', 'best', 'best',\n",
       "                      'random', 'best', 'best', 'best', 'random', 'random',\n",
       "                      'random', 'best', 'best', 'best', 'best', 'best',\n",
       "                      'best', 'best', 'best', 'best', 'best', 'random',\n",
       "                      'best', 'best', 'best', 'best', 'best', 'best', 'best',\n",
       "                      'best', 'best', 'random', 'best', 'random', 'best',\n",
       "                      'random', 'best', 'random', 'best', 'random', 'random',\n",
       "                      'random', 'best', 'best', 'random', 'best', 'random',\n",
       "                      'random', 'best', 'random', 'random', 'random', 'best',\n",
       "                      'random', 'random', 'best', 'random', 'random', 'best',\n",
       "                      'random', 'random', 'best', 'random', 'random',\n",
       "                      'random', 'random', 'best', 'random'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [OrderedDict([('max_depth', 12),\n",
       "                 ('max_features', 'log2'),\n",
       "                 ('min_samples_leaf', 13),\n",
       "                 ('min_samples_split', 0.06820119469644915),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 7),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 18),\n",
       "                 ('min_samples_split', 0.06394077902553194),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 12),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 8),\n",
       "                 ('min_samples_split', 0.027231907778595785),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 6),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 10),\n",
       "                 ('min_samples_split', 0.050954987496724294),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 7),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 15),\n",
       "                 ('min_samples_split', 0.035698379447037194),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 17),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 15),\n",
       "                 ('min_samples_split', 0.053755559059457544),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 19),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 9),\n",
       "                 ('min_samples_split', 0.026585131394449422),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 12),\n",
       "                 ('max_features', 'log2'),\n",
       "                 ('min_samples_leaf', 15),\n",
       "                 ('min_samples_split', 0.012456546518247541),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 5),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 16),\n",
       "                 ('min_samples_split', 0.09400914937055956),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 9),\n",
       "                 ('max_features', 'log2'),\n",
       "                 ('min_samples_leaf', 6),\n",
       "                 ('min_samples_split', 0.08183069151341117),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 5),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 3),\n",
       "                 ('min_samples_split', 0.02830964697195451),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 9),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 17),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 3),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 10),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.038210833692354146),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 13),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 18),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 19),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 20),\n",
       "                 ('max_features', 'log2'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 3),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 14),\n",
       "                 ('min_samples_split', 0.09380984081274953),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 3),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 14),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 20),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 2),\n",
       "                 ('min_samples_split', 0.029122097557848267),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 15),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 20),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.1),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 18),\n",
       "                 ('min_samples_split', 0.1),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 14),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.013906606462437597),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 20),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 3),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 7),\n",
       "                 ('min_samples_split', 0.05274240645427632),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 20),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 4),\n",
       "                 ('min_samples_split', 0.06887863406266764),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 14),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 20),\n",
       "                 ('max_features', 'log2'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.1),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 13),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 8),\n",
       "                 ('min_samples_split', 0.1),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 14),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 15),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 15),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 6),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 15),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 18),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 20),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 3),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 12),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 7),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 14),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 10),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 13),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 17),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 17),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 16),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 12),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 11),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 10),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.016284179772286005),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 12),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 15),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 20),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.05743908025538613),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 12),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 12),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 3),\n",
       "                 ('max_features', 'log2'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 9),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 18),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 8),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 16),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 9),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 12),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 20),\n",
       "                 ('max_features', 'log2'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 11),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 19),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 17),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 10),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 11),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 18),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 18),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 12),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 14),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 5),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 7),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 11),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 15),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 12),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 15),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 8),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 11),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 17),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 6),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 15),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 6),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 15),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 6),\n",
       "                 ('min_samples_split', 0.017194559410837622),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 9),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.04046265688670721),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 15),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 15),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 6),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 11),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 16),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 20),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 8),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 16),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 7),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 16),\n",
       "                 ('max_features', 'log2'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 3),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.1),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 20),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 12),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.1),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 11),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.017133983728503447),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 15),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 6),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 18),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 6),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 10),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 15),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 7),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 3),\n",
       "                 ('max_features', 'log2'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.1),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 19),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 6),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 15),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 6),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 17),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 15),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 6),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 18),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 4),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 20),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 15),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 7),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')]),\n",
       "    OrderedDict([('max_depth', 14),\n",
       "                 ('max_features', 'log2'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'best')]),\n",
       "    OrderedDict([('max_depth', 18),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 11),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('splitter', 'random')])],\n",
       "   'split0_test_score': array([-0.73663018, -0.69282576, -0.51342239, -0.69600815, -0.52899385,\n",
       "          -0.65325305, -0.54967379, -0.67077625, -0.66639506, -0.76968493,\n",
       "          -0.6300498 , -0.49668597, -0.83421576, -0.56463553, -0.44034854,\n",
       "          -0.43315902, -0.49270363, -0.53923294, -0.69686597, -0.65527101,\n",
       "          -0.59308545, -0.44152465, -0.65904813, -0.6387988 , -0.67605615,\n",
       "          -0.44765516, -0.43315902, -0.65527101, -0.58799428, -0.46134241,\n",
       "          -0.64944248, -0.6402883 , -0.52492045, -0.44578637, -0.44578637,\n",
       "          -0.44578637, -0.50478515, -0.45466241, -0.4538071 , -0.48713156,\n",
       "          -0.51991305, -0.49270363, -0.49270363, -0.51512791, -0.43315902,\n",
       "          -0.4417181 , -0.4394593 , -0.46129641, -0.4417181 , -0.49800208,\n",
       "          -0.61685999, -0.4417181 , -0.4417181 , -0.83041505, -0.49433759,\n",
       "          -0.45466241, -0.45466241, -0.4417181 , -0.68371612, -0.4394593 ,\n",
       "          -0.43567722, -0.49339208, -0.45466241, -0.49270363, -0.4417181 ,\n",
       "          -0.46134241, -0.44225839, -0.44540205, -0.4389095 , -0.44152465,\n",
       "          -0.46649446, -0.48860117, -0.44152465, -0.48544383, -0.56839757,\n",
       "          -0.43326865, -0.44152465, -0.4491988 , -0.5056273 , -0.50755422,\n",
       "          -0.61380475, -0.69686597, -0.49270363, -0.58075488, -0.45325709,\n",
       "          -0.44152465, -0.5056273 , -0.59837604, -0.44152465, -0.82393688,\n",
       "          -0.58487898, -0.5056273 , -0.44152465, -0.52780916, -0.44152465,\n",
       "          -0.49270363, -0.49270363, -0.44152465, -0.62760071, -0.48554997]),\n",
       "   'split1_test_score': array([-0.68807453, -0.61134798, -0.65232219, -0.6514089 , -0.61798256,\n",
       "          -0.5895403 , -0.54466083, -0.69701551, -0.62892474, -0.68876119,\n",
       "          -0.64082352, -0.5743726 , -0.73049757, -0.63857674, -0.64811333,\n",
       "          -0.64276343, -0.46500869, -0.54603237, -0.71892344, -0.65189651,\n",
       "          -0.59808282, -0.46500869, -0.66697032, -0.51293041, -0.52758302,\n",
       "          -0.63955204, -0.64276343, -0.65189651, -0.51521173, -0.46500869,\n",
       "          -0.62825403, -0.59187896, -0.504522  , -0.65817004, -0.62899706,\n",
       "          -0.65817004, -0.51191534, -0.65817004, -0.65252304, -0.62898638,\n",
       "          -0.50685098, -0.46500869, -0.46500869, -0.63505474, -0.64276343,\n",
       "          -0.62395716, -0.62732292, -0.64176657, -0.62395716, -0.69809544,\n",
       "          -0.69891617, -0.62395716, -0.62395716, -0.67011471, -0.66195978,\n",
       "          -0.62899706, -0.62899706, -0.62395716, -0.58764415, -0.62732292,\n",
       "          -0.64276343, -0.64141579, -0.65817004, -0.46500869, -0.62395716,\n",
       "          -0.46500869, -0.63259106, -0.46742301, -0.63406535, -0.46500869,\n",
       "          -0.64602624, -0.46500869, -0.46500869, -0.52970885, -0.65407881,\n",
       "          -0.64276343, -0.46500869, -0.62732292, -0.46500869, -0.46500869,\n",
       "          -0.73935035, -0.71892344, -0.46500869, -0.61015603, -0.64587052,\n",
       "          -0.46500869, -0.46500869, -0.59096151, -0.46500869, -0.67011471,\n",
       "          -0.63505474, -0.46500869, -0.46500869, -0.55382171, -0.46500869,\n",
       "          -0.46500869, -0.46500869, -0.46500869, -0.51581913, -0.46500869]),\n",
       "   'split2_test_score': array([-0.73929261, -0.68388879, -0.4188009 , -0.73299306, -0.44999784,\n",
       "          -0.62233194, -0.55364335, -0.5350614 , -0.69008138, -0.70788678,\n",
       "          -0.49763494, -0.43205937, -0.70661247, -0.44388233, -0.40977112,\n",
       "          -0.40977112, -0.4393082 , -0.51071044, -0.72956005, -0.65037556,\n",
       "          -0.49833279, -0.3902438 , -0.51469644, -0.72788731, -0.61169007,\n",
       "          -0.40327121, -0.40977112, -0.65484073, -0.54454513, -0.39579317,\n",
       "          -0.72453357, -0.62658344, -0.43961266, -0.40810283, -0.38144046,\n",
       "          -0.40810283, -0.43961266, -0.40810283, -0.37303677, -0.38144046,\n",
       "          -0.43188271, -0.40296746, -0.40296746, -0.51875767, -0.40977112,\n",
       "          -0.39500909, -0.37168575, -0.44117784, -0.39500909, -0.5641982 ,\n",
       "          -0.46683465, -0.39500909, -0.39500909, -0.74647087, -0.41676642,\n",
       "          -0.38144046, -0.38144046, -0.39500909, -0.493486  , -0.37168575,\n",
       "          -0.40977112, -0.41426847, -0.40810283, -0.41274854, -0.39500909,\n",
       "          -0.3715446 , -0.42995036, -0.41261081, -0.38144046, -0.3902438 ,\n",
       "          -0.39636198, -0.40296746, -0.3902438 , -0.44334171, -0.46526505,\n",
       "          -0.40977112, -0.3902438 , -0.37168575, -0.4393082 , -0.40363935,\n",
       "          -0.493486  , -0.72956005, -0.4393082 , -0.67491769, -0.43493997,\n",
       "          -0.3902438 , -0.41274854, -0.58133784, -0.3902438 , -0.6971867 ,\n",
       "          -0.51875767, -0.4393082 , -0.3902438 , -0.51875767, -0.3902438 ,\n",
       "          -0.41274854, -0.4393082 , -0.3902438 , -0.493486  , -0.39039816]),\n",
       "   'split3_test_score': array([-0.58344744, -0.57107147, -0.46728601, -0.61177226, -0.50382743,\n",
       "          -0.5456471 , -0.62008037, -0.64071646, -0.65399616, -0.83089846,\n",
       "          -0.49262237, -0.51880438, -0.75655734, -0.48096938, -0.44552964,\n",
       "          -0.48210465, -0.40085305, -0.58021816, -0.59747279, -0.58871744,\n",
       "          -0.53100509, -0.47955213, -0.49780624, -0.50217264, -0.57690438,\n",
       "          -0.49182371, -0.48210465, -0.58871744, -0.50921021, -0.46090208,\n",
       "          -0.67461078, -0.54848285, -0.45159993, -0.47034468, -0.44372343,\n",
       "          -0.47034468, -0.45159993, -0.47034468, -0.48376105, -0.47332924,\n",
       "          -0.41551537, -0.40085305, -0.40085305, -0.58812061, -0.48210465,\n",
       "          -0.46425127, -0.47849115, -0.4663284 , -0.46425127, -0.63281741,\n",
       "          -0.51567819, -0.46425127, -0.46425127, -0.68734711, -0.47662055,\n",
       "          -0.47332924, -0.47332924, -0.46425127, -0.43404212, -0.47849115,\n",
       "          -0.48220784, -0.45419443, -0.47034468, -0.40085305, -0.46425127,\n",
       "          -0.46090208, -0.47555871, -0.45043742, -0.47550435, -0.47955213,\n",
       "          -0.50763926, -0.40085305, -0.47955213, -0.52837474, -0.49227766,\n",
       "          -0.48210465, -0.47955213, -0.45790542, -0.40085305, -0.49760189,\n",
       "          -0.42785973, -0.59747279, -0.40085305, -0.74171555, -0.45592447,\n",
       "          -0.47955213, -0.40085305, -0.59934577, -0.47955213, -0.7884603 ,\n",
       "          -0.63281741, -0.40085305, -0.47955213, -0.58812061, -0.47955213,\n",
       "          -0.40085305, -0.40085305, -0.47955213, -0.63396776, -0.44120433]),\n",
       "   'split4_test_score': array([-0.60239672, -0.7109858 , -0.52899631, -0.70595166, -0.52436551,\n",
       "          -0.7289616 , -0.70287005, -0.67298542, -0.71368687, -0.65019823,\n",
       "          -0.5025927 , -0.48416049, -0.80765561, -0.52431568, -0.49767638,\n",
       "          -0.48576097, -0.48673227, -0.5668047 , -0.80569336, -0.64277926,\n",
       "          -0.5818454 , -0.44557684, -0.56664782, -0.57160862, -0.74656573,\n",
       "          -0.51626044, -0.48576097, -0.64277926, -0.5755099 , -0.48956479,\n",
       "          -0.86256428, -0.69915348, -0.52829984, -0.48138845, -0.495339  ,\n",
       "          -0.48138845, -0.63823324, -0.48138845, -0.49321383, -0.51440702,\n",
       "          -0.50917081, -0.47289475, -0.47289475, -0.65497561, -0.48576097,\n",
       "          -0.50195356, -0.50422918, -0.52684964, -0.50195356, -0.51382087,\n",
       "          -0.50348388, -0.50195356, -0.50195356, -0.76991423, -0.53288401,\n",
       "          -0.495339  , -0.49550944, -0.50195356, -0.70116146, -0.50422918,\n",
       "          -0.49887685, -0.52106783, -0.48138845, -0.48673227, -0.50195356,\n",
       "          -0.48956479, -0.53122412, -0.59990979, -0.51168395, -0.44207522,\n",
       "          -0.44424007, -0.46794945, -0.44207522, -0.48982643, -0.53574146,\n",
       "          -0.48576097, -0.44207522, -0.50773024, -0.46794945, -0.44018888,\n",
       "          -0.70116146, -0.80569336, -0.48673227, -0.77590929, -0.52063716,\n",
       "          -0.44207522, -0.46794945, -0.59573661, -0.44207522, -0.76991423,\n",
       "          -0.70083567, -0.46794945, -0.44207522, -0.65497561, -0.44207522,\n",
       "          -0.48673227, -0.48673227, -0.44207522, -0.64937819, -0.40078399]),\n",
       "   'split5_test_score': array([-0.83749838, -0.69110243, -0.46674803, -0.7580337 , -0.5070697 ,\n",
       "          -0.61337115, -0.50302541, -0.50308874, -0.59584072, -0.65389155,\n",
       "          -0.6071311 , -0.4948003 , -0.91905973, -0.49044737, -0.40954447,\n",
       "          -0.40326194, -0.40949748, -0.82560932, -0.82753307, -0.71591256,\n",
       "          -0.59287781, -0.43824022, -0.63065911, -0.56490127, -0.68817193,\n",
       "          -0.44547731, -0.40326194, -0.71981326, -0.54590629, -0.40900742,\n",
       "          -0.77313377, -0.66840306, -0.47645542, -0.40977516, -0.41232271,\n",
       "          -0.40977516, -0.47645542, -0.40977516, -0.40325736, -0.41232271,\n",
       "          -0.41302675, -0.42396836, -0.42396836, -0.52777798, -0.40326194,\n",
       "          -0.39356563, -0.40179083, -0.43095971, -0.39356563, -0.68540086,\n",
       "          -0.51421812, -0.39356563, -0.39356563, -0.8904824 , -0.41043357,\n",
       "          -0.41232271, -0.41232271, -0.39356563, -0.61885838, -0.40179083,\n",
       "          -0.40326194, -0.42188612, -0.40977516, -0.47437137, -0.39356563,\n",
       "          -0.40900742, -0.44559033, -0.48688904, -0.40326194, -0.46532577,\n",
       "          -0.39119684, -0.42396836, -0.46532577, -0.50503734, -0.49848014,\n",
       "          -0.40326194, -0.46532577, -0.40179083, -0.40178442, -0.43676779,\n",
       "          -0.61885838, -0.82753307, -0.40949748, -0.6871441 , -0.4146446 ,\n",
       "          -0.46532577, -0.4303231 , -0.54380737, -0.46532577, -0.89728202,\n",
       "          -0.68371975, -0.40178442, -0.46532577, -0.52777798, -0.46532577,\n",
       "          -0.47437137, -0.40949748, -0.46532577, -0.45199279, -0.44744365]),\n",
       "   'split6_test_score': array([-0.78681965, -0.73811647, -0.61493418, -0.80502178, -0.63872681,\n",
       "          -0.70708127, -0.56775913, -0.61453573, -0.75307624, -0.59479346,\n",
       "          -0.71429446, -0.77574912, -0.67413331, -0.64126749, -0.5904851 ,\n",
       "          -0.59089844, -0.66630627, -0.58980527, -0.61843004, -0.63255474,\n",
       "          -0.61178704, -0.66630627, -0.72003348, -0.62035198, -0.79112607,\n",
       "          -0.54976659, -0.59089844, -0.64496169, -0.73326578, -0.65856736,\n",
       "          -0.81065397, -0.70490048, -0.65774685, -0.65061658, -0.64296129,\n",
       "          -0.65061658, -0.66630627, -0.65061658, -0.64753212, -0.64296129,\n",
       "          -0.62569573, -0.66630627, -0.66630627, -0.60424132, -0.59089844,\n",
       "          -0.59782587, -0.57483874, -0.57175896, -0.59782587, -0.68482726,\n",
       "          -0.65579561, -0.59782587, -0.59782587, -0.67677304, -0.62134972,\n",
       "          -0.64296129, -0.64296129, -0.59782587, -0.60127367, -0.57483874,\n",
       "          -0.63728861, -0.62662229, -0.65061658, -0.66630627, -0.59782587,\n",
       "          -0.65856736, -0.6347418 , -0.78183563, -0.64296129, -0.66630627,\n",
       "          -0.6269204 , -0.66630627, -0.66630627, -0.70264335, -0.64872659,\n",
       "          -0.59089844, -0.66630627, -0.62449658, -0.66630627, -0.66630627,\n",
       "          -0.60127367, -0.61843004, -0.66630627, -0.67722486, -0.56872129,\n",
       "          -0.66630627, -0.66630627, -0.81827724, -0.66630627, -0.67677304,\n",
       "          -0.68482726, -0.66630627, -0.66630627, -0.60424132, -0.66630627,\n",
       "          -0.66630627, -0.66630627, -0.66630627, -0.67029593, -0.66630627]),\n",
       "   'split7_test_score': array([-0.64917098, -0.54316495, -0.6085901 , -0.64901242, -0.58506127,\n",
       "          -0.59870488, -0.44413118, -0.47799441, -0.58416845, -0.68482248,\n",
       "          -0.60375666, -0.5541212 , -0.79237577, -0.58824976, -0.57714645,\n",
       "          -0.57714645, -0.48792754, -0.6684498 , -0.67006315, -0.61450232,\n",
       "          -0.5558965 , -0.47954899, -0.57083839, -0.63653224, -0.60906802,\n",
       "          -0.57562056, -0.57714645, -0.61703341, -0.59331007, -0.49023977,\n",
       "          -0.71504262, -0.60332033, -0.44308085, -0.58577751, -0.55889525,\n",
       "          -0.58577751, -0.43341231, -0.58577751, -0.57606559, -0.57187617,\n",
       "          -0.49295348, -0.48792754, -0.48792754, -0.49303382, -0.57714645,\n",
       "          -0.56852988, -0.55931502, -0.57602163, -0.56852988, -0.47117333,\n",
       "          -0.60240964, -0.56852988, -0.56852988, -0.67101858, -0.57200441,\n",
       "          -0.55889525, -0.60294219, -0.56852988, -0.54259973, -0.55931502,\n",
       "          -0.57714645, -0.58080841, -0.58577751, -0.48792754, -0.56852988,\n",
       "          -0.49023977, -0.57915885, -0.47337665, -0.56428127, -0.47954899,\n",
       "          -0.59891429, -0.48792754, -0.47954899, -0.50693174, -0.61204815,\n",
       "          -0.57714645, -0.47954899, -0.55931502, -0.48792754, -0.48792754,\n",
       "          -0.54476044, -0.67006315, -0.48792754, -0.63096127, -0.59408224,\n",
       "          -0.47954899, -0.48792754, -0.53837524, -0.47954899, -0.67101858,\n",
       "          -0.61319354, -0.48792754, -0.47954899, -0.49303382, -0.47954899,\n",
       "          -0.48792754, -0.48792754, -0.47954899, -0.53090969, -0.47404055]),\n",
       "   'split8_test_score': array([-0.71112992, -0.6089152 , -0.36536485, -0.6231576 , -0.39579473,\n",
       "          -0.63641239, -0.4556524 , -0.50259117, -0.75530766, -0.55949055,\n",
       "          -0.4015958 , -0.45711191, -0.73583663, -0.36554033, -0.35073399,\n",
       "          -0.35193009, -0.43953865, -0.53737709, -0.72438397, -0.62422882,\n",
       "          -0.40174037, -0.47858587, -0.46856519, -0.49357602, -0.55977496,\n",
       "          -0.35919593, -0.35193009, -0.62422882, -0.52236427, -0.38026022,\n",
       "          -0.74085054, -0.62508089, -0.41916772, -0.35400456, -0.35354857,\n",
       "          -0.35400456, -0.44859384, -0.35400456, -0.36014349, -0.35986732,\n",
       "          -0.45893173, -0.44885073, -0.44885073, -0.51683141, -0.35193009,\n",
       "          -0.35852501, -0.35479702, -0.35836815, -0.35852501, -0.53509626,\n",
       "          -0.40644026, -0.35852501, -0.35852501, -0.74377689, -0.35818275,\n",
       "          -0.35354857, -0.35354857, -0.35852501, -0.48276356, -0.35479702,\n",
       "          -0.35280356, -0.36480478, -0.35400456, -0.36533187, -0.35852501,\n",
       "          -0.38026022, -0.38015356, -0.39329883, -0.3540148 , -0.36931605,\n",
       "          -0.34741965, -0.44885073, -0.36931605, -0.40510487, -0.37953508,\n",
       "          -0.35193009, -0.36931605, -0.36888987, -0.43953865, -0.43290742,\n",
       "          -0.63756477, -0.73338097, -0.43953865, -0.76020938, -0.36218607,\n",
       "          -0.36931605, -0.36533187, -0.48698094, -0.36931605, -0.7390271 ,\n",
       "          -0.46660188, -0.43953865, -0.36931605, -0.53362011, -0.36931605,\n",
       "          -0.36533187, -0.43953865, -0.36931605, -0.61515895, -0.36828843]),\n",
       "   'split9_test_score': array([-0.62849411, -0.64969269, -0.43265124, -0.72378864, -0.43710607,\n",
       "          -0.55190244, -0.49354785, -0.49005228, -0.69053351, -0.70444028,\n",
       "          -0.47028837, -0.47339242, -0.91965991, -0.46489272, -0.36050815,\n",
       "          -0.37406992, -0.44860481, -0.67987745, -0.68935193, -0.59223055,\n",
       "          -0.52905989, -0.46686725, -0.49296521, -0.503735  , -0.59658018,\n",
       "          -0.38832391, -0.37406992, -0.59223055, -0.5739105 , -0.50213381,\n",
       "          -0.75575701, -0.64121393, -0.47557798, -0.38817957, -0.37520353,\n",
       "          -0.38817957, -0.44014381, -0.38817957, -0.35739985, -0.37103902,\n",
       "          -0.44563346, -0.46013977, -0.46013977, -0.46092637, -0.37406992,\n",
       "          -0.35527383, -0.36508654, -0.41696211, -0.35527383, -0.60246443,\n",
       "          -0.50747832, -0.35527383, -0.35527383, -0.82027911, -0.42434725,\n",
       "          -0.37520353, -0.37520353, -0.35527383, -0.4485348 , -0.36508654,\n",
       "          -0.39028913, -0.3685269 , -0.38817957, -0.48443026, -0.35527383,\n",
       "          -0.50213381, -0.45890542, -0.41799582, -0.35405777, -0.46686725,\n",
       "          -0.41339652, -0.46013977, -0.46686725, -0.48102682, -0.46958262,\n",
       "          -0.37406992, -0.46686725, -0.366276  , -0.45954283, -0.45888568,\n",
       "          -0.4485348 , -0.68935193, -0.47709105, -0.74843201, -0.38537183,\n",
       "          -0.46686725, -0.48443026, -0.48585441, -0.46686725, -0.82233295,\n",
       "          -0.46092637, -0.44860481, -0.46686725, -0.41910418, -0.46686725,\n",
       "          -0.48443026, -0.47709105, -0.46686725, -0.6324908 , -0.52598368]),\n",
       "   'mean_test_score': array([-0.69629545, -0.65011115, -0.50691162, -0.69571482, -0.51889258,\n",
       "          -0.62472061, -0.54350444, -0.58048174, -0.67320108, -0.68448679,\n",
       "          -0.55607897, -0.52612578, -0.78766041, -0.52027773, -0.47298572,\n",
       "          -0.4750866 , -0.47364806, -0.60441175, -0.70782778, -0.63684688,\n",
       "          -0.54937132, -0.47514547, -0.57882303, -0.57724943, -0.63835205,\n",
       "          -0.48169469, -0.4750866 , -0.63917727, -0.57012282, -0.47128197,\n",
       "          -0.73348431, -0.63493057, -0.49209837, -0.48521458, -0.47382177,\n",
       "          -0.48521458, -0.5011058 , -0.48610218, -0.48007402, -0.48433612,\n",
       "          -0.48195741, -0.47216203, -0.47216203, -0.55148474, -0.4750866 ,\n",
       "          -0.47006094, -0.46770164, -0.48914894, -0.47006094, -0.58858961,\n",
       "          -0.54881148, -0.47006094, -0.47006094, -0.7506592 , -0.49688861,\n",
       "          -0.47766995, -0.48209169, -0.47006094, -0.559408  , -0.46770164,\n",
       "          -0.48300862, -0.48869871, -0.48610218, -0.47364135, -0.47006094,\n",
       "          -0.46885712, -0.50101326, -0.4929179 , -0.47601807, -0.46657688,\n",
       "          -0.48386097, -0.47125725, -0.46657688, -0.50774397, -0.53241331,\n",
       "          -0.47509757, -0.46657688, -0.47346114, -0.47338464, -0.47967877,\n",
       "          -0.58266544, -0.70872748, -0.47649668, -0.68874251, -0.48356352,\n",
       "          -0.46657688, -0.46865061, -0.5839053 , -0.46657688, -0.75560465,\n",
       "          -0.59816133, -0.47229084, -0.46657688, -0.54212622, -0.46657688,\n",
       "          -0.47364135, -0.47649668, -0.46657688, -0.58211   , -0.46650077]),\n",
       "   'std_test_score': array([0.0776309 , 0.06081204, 0.08954252, 0.05879572, 0.07459537,\n",
       "          0.05674888, 0.07329324, 0.0823886 , 0.05624319, 0.07445798,\n",
       "          0.09170237, 0.09245442, 0.07978531, 0.08397602, 0.09662891,\n",
       "          0.09416051, 0.07093257, 0.09048054, 0.06843567, 0.03466918,\n",
       "          0.06026534, 0.06880359, 0.08200589, 0.07363134, 0.08030378,\n",
       "          0.08486275, 0.09416051, 0.0356072 , 0.06145172, 0.0740465 ,\n",
       "          0.06838271, 0.04549891, 0.0652807 , 0.10365512, 0.09929127,\n",
       "          0.10365512, 0.08007601, 0.10335125, 0.10708012, 0.09944058,\n",
       "          0.06091434, 0.07162237, 0.07162237, 0.06131298, 0.09416051,\n",
       "          0.09415887, 0.09189082, 0.08269406, 0.09415887, 0.07988352,\n",
       "          0.08632942, 0.09415887, 0.09415887, 0.07313805, 0.09406913,\n",
       "          0.0985469 , 0.10296651, 0.09415887, 0.08952261, 0.09189082,\n",
       "          0.09897074, 0.09637671, 0.10335125, 0.07667273, 0.09415887,\n",
       "          0.07682384, 0.08415302, 0.11047071, 0.10357907, 0.07533055,\n",
       "          0.1011246 , 0.07152269, 0.07533055, 0.07424043, 0.08400571,\n",
       "          0.09415564, 0.07533055, 0.09683993, 0.07173236, 0.06929218,\n",
       "          0.09776342, 0.06870602, 0.07043993, 0.06369985, 0.08964084,\n",
       "          0.07533055, 0.07806068, 0.08846667, 0.07533055, 0.07405668,\n",
       "          0.08413327, 0.07201791, 0.07533055, 0.06117133, 0.07533055,\n",
       "          0.07667273, 0.07043993, 0.07533055, 0.07245102, 0.08039991]),\n",
       "   'rank_test_score': array([ 94,  89,  61,  93,  63,  84,  68,  77,  90,  91,  72,  65, 100,\n",
       "           64,  25,  32,  30,  83,  95,  86,  70,  36,  76,  75,  87,  43,\n",
       "           32,  88,  74,  21,  97,  85,  56,  50,  31,  50,  60,  52,  42,\n",
       "           49,  44,  22,  22,  71,  32,  14,  10,  55,  14,  81,  69,  14,\n",
       "           14,  98,  58,  40,  45,  14,  73,  10,  46,  54,  52,  28,  14,\n",
       "           13,  59,  57,  37,   2,  48,  20,   2,  62,  66,  35,   2,  27,\n",
       "           26,  41,  79,  96,  38,  92,  47,   2,  12,  80,   2,  99,  82,\n",
       "           24,   2,  67,   2,  28,  38,   2,  78,   1], dtype=int32)}},\n",
       " 'RF': {'best_estimator': RandomForestRegressor(max_depth=18, max_features='auto', min_samples_leaf=20,\n",
       "                        min_samples_split=0.01, n_estimators=400, n_jobs=6,\n",
       "                        random_state=0),\n",
       "  'best_params': OrderedDict([('bootstrap', True),\n",
       "               ('max_depth', 18),\n",
       "               ('max_features', 'auto'),\n",
       "               ('min_samples_leaf', 20),\n",
       "               ('min_samples_split', 0.01),\n",
       "               ('n_estimators', 400)]),\n",
       "  'best_score': -0.4191743709967299,\n",
       "  'optimization_history': {'mean_fit_time': array([  1.66009083,   1.03943028,   0.52188945,   1.5009151 ,\n",
       "            0.63798943,   0.62603467,   1.83516805,   0.63938506,\n",
       "            2.7789016 ,   2.06220379,   0.18881271, 113.02553844,\n",
       "           98.76380486,   6.54592762,   0.14626453,   6.54801018,\n",
       "            1.4356842 ,   0.20490551,   0.5073693 ,   6.59372101,\n",
       "            5.61071219,   6.53291602,   4.54071002,   6.53438928,\n",
       "            6.54154773,   4.29797299,  27.53915689,   6.56322091,\n",
       "            6.4345948 ,   6.54872501,   6.63204396,   2.60314069,\n",
       "            6.56978078,   6.5352474 ,   5.10546668,   4.75048254,\n",
       "            6.56074066,   6.64055698,   0.34017951,   6.64756501,\n",
       "            6.57348852,   5.71243551,   6.53450906,   6.57319133,\n",
       "            6.65794082,   6.66716971,   3.22642062,   6.64646862,\n",
       "            6.6395272 ,   3.43793452,   6.57174723,   6.6643445 ,\n",
       "            6.6247185 ,   6.58696089,   6.57635458,   6.65625136,\n",
       "           18.51027117,   6.72681961,   6.65897946,   6.48872929,\n",
       "            6.50970218,   6.54873915,   6.55382295,   6.54399929,\n",
       "           64.97741854,  76.37538197,  76.81140316,  76.73508472,\n",
       "            1.94902818,  34.92104964,  76.59665339,  75.86125023,\n",
       "           36.16012845,  25.646035  ,  45.22403996,  73.29369104,\n",
       "           75.06213222,   1.92708883,  48.22845623,  76.17810369,\n",
       "           63.07169452,  75.73562388,  53.02431936,   1.89253993,\n",
       "           63.62792439,  71.76166594,  75.77097485,   2.30120776,\n",
       "           61.51938477,  61.7173063 ,  62.65499339,  62.41411717,\n",
       "           63.52426195,  75.95872309,  75.60292411,   1.95773609,\n",
       "           78.59017913,  15.35266886,   3.5888432 ,   0.11960447]),\n",
       "   'std_fit_time': array([ 0.30440222,  0.23771867,  0.08678434,  0.2745392 ,  0.10997089,\n",
       "           0.1011899 ,  0.33061444,  0.12307972,  0.55126781,  0.38367454,\n",
       "           0.04478941, 22.31475518, 18.76855531,  1.28533203,  0.03121273,\n",
       "           1.26054528,  0.27624754,  0.02999977,  0.10088865,  1.25900098,\n",
       "           1.06136385,  1.2661645 ,  0.85686251,  1.24846532,  1.23937134,\n",
       "           0.81201673,  5.25117621,  1.24839263,  1.21409527,  1.26549524,\n",
       "           1.29128664,  0.49860575,  1.28091853,  1.28172879,  0.9636049 ,\n",
       "           0.90518741,  1.25770251,  1.27655594,  0.10000504,  1.28930061,\n",
       "           1.30614854,  1.18442004,  1.27457697,  1.24223565,  1.29428037,\n",
       "           1.28334369,  0.61802416,  1.28152135,  1.29159232,  0.64523761,\n",
       "           1.27686035,  1.28071318,  1.29584622,  1.30214229,  1.22003414,\n",
       "           1.27413914,  3.76102117,  1.31928688,  1.25487243,  1.32821018,\n",
       "           1.28611208,  1.24753028,  1.24827921,  1.29759829, 13.18804335,\n",
       "          15.38723358, 15.36667221, 15.75256872,  0.40689452,  7.03240664,\n",
       "          15.77296172, 15.01000312,  7.67641789,  5.17068523,  9.4550135 ,\n",
       "          14.94577112, 15.5432919 ,  0.37547731,  9.84843653, 15.59021503,\n",
       "          12.83795661, 15.43582756, 10.81687478,  0.36009971, 13.22223419,\n",
       "          14.73084163, 15.34524561,  0.44093725, 12.6777666 , 12.66310546,\n",
       "          12.79432268, 12.81881435, 12.60607001, 15.59002189, 15.3073816 ,\n",
       "           0.38782647, 15.12426258,  3.24737699,  0.74334507,  0.02525264]),\n",
       "   'mean_score_time': array([0.07401044, 0.03304377, 0.03807251, 0.06650543, 0.03905432,\n",
       "          0.04156923, 0.07514529, 0.0289881 , 0.06402736, 0.07890191,\n",
       "          0.0227525 , 0.09489474, 0.08892024, 0.08296645, 0.01711359,\n",
       "          0.09481318, 0.05482986, 0.01321814, 0.0209619 , 0.08990979,\n",
       "          0.07934306, 0.10002491, 0.08993964, 0.09889088, 0.09521227,\n",
       "          0.08312917, 0.06656828, 0.08953729, 0.09334981, 0.09097097,\n",
       "          0.09156089, 0.06914508, 0.08548782, 0.08647683, 0.09026175,\n",
       "          0.09047322, 0.08758755, 0.08434298, 0.015007  , 0.10186186,\n",
       "          0.10790813, 0.01559317, 0.0887866 , 0.09510508, 0.08825481,\n",
       "          0.08629329, 0.08639972, 0.09591424, 0.09702604, 0.02374334,\n",
       "          0.1412209 , 0.09420948, 0.10765114, 0.10185847, 0.08186285,\n",
       "          0.08394876, 0.04265447, 0.0876087 , 0.09104486, 0.12636905,\n",
       "          0.08535724, 0.09327645, 0.08536775, 0.08238773, 0.08427122,\n",
       "          0.08785861, 0.09309032, 0.09769757, 0.01447663, 0.05222752,\n",
       "          0.09852676, 0.08654048, 0.05254648, 0.07058303, 0.05597634,\n",
       "          0.103613  , 0.08797276, 0.01054945, 0.07115958, 0.09162323,\n",
       "          0.08178384, 0.09539583, 0.06546836, 0.01233742, 0.08164184,\n",
       "          0.09276135, 0.09328687, 0.08327894, 0.07605495, 0.06962397,\n",
       "          0.07680824, 0.07314837, 0.07704918, 0.08446021, 0.093523  ,\n",
       "          0.01281619, 0.0839787 , 0.04144297, 0.02851181, 0.01621232]),\n",
       "   'std_score_time': array([0.03844493, 0.01492   , 0.00982261, 0.01260677, 0.01159999,\n",
       "          0.01426344, 0.01680379, 0.00981318, 0.02146398, 0.015079  ,\n",
       "          0.01477152, 0.02268773, 0.01655833, 0.01560666, 0.01227507,\n",
       "          0.01834598, 0.01266389, 0.00328578, 0.00492663, 0.01831609,\n",
       "          0.01504048, 0.02005147, 0.02246973, 0.01995862, 0.00812265,\n",
       "          0.0122887 , 0.02432155, 0.01317905, 0.02701893, 0.01630831,\n",
       "          0.01835865, 0.02129776, 0.01600215, 0.02164875, 0.01953118,\n",
       "          0.01965177, 0.01837017, 0.01418258, 0.00449683, 0.02537501,\n",
       "          0.02229621, 0.00433965, 0.0180226 , 0.02272184, 0.01405194,\n",
       "          0.01593262, 0.01411526, 0.01961929, 0.02370989, 0.02554142,\n",
       "          0.06550431, 0.02168538, 0.03162012, 0.02057561, 0.01867214,\n",
       "          0.01985054, 0.02877884, 0.02307112, 0.0192383 , 0.05875365,\n",
       "          0.02261415, 0.02343356, 0.01779368, 0.02268947, 0.01796369,\n",
       "          0.03886498, 0.02383362, 0.01911589, 0.00445261, 0.01450637,\n",
       "          0.02032491, 0.01964229, 0.01052241, 0.04522871, 0.01460753,\n",
       "          0.0306342 , 0.02538369, 0.00406284, 0.02478918, 0.02241948,\n",
       "          0.01607971, 0.02390891, 0.01703952, 0.00409269, 0.02003025,\n",
       "          0.0214532 , 0.01928334, 0.01390546, 0.01972604, 0.02274455,\n",
       "          0.02009972, 0.02205757, 0.02277845, 0.02726984, 0.02456299,\n",
       "          0.00439277, 0.02372516, 0.01233608, 0.03311974, 0.0179813 ]),\n",
       "   'param_bootstrap': masked_array(data=[True, False, True, False, False, True, True, True,\n",
       "                      False, False, False, False, False, False, True, False,\n",
       "                      False, False, False, False, False, False, True, False,\n",
       "                      False, False, False, False, False, False, False, True,\n",
       "                      False, False, False, True, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      True, True, True, True, True, True, True, True, True,\n",
       "                      True, True, True, True, True, True, True, True, True,\n",
       "                      True, True, True, True, True, False, True, True, True,\n",
       "                      True, True, True, True, True, False, True, True, False],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_depth': masked_array(data=[14, 20, 4, 16, 7, 20, 16, 12, 18, 10, 15, 19, 15, 19,\n",
       "                      15, 20, 3, 20, 8, 20, 14, 16, 12, 18, 20, 20, 3, 20,\n",
       "                      14, 20, 20, 20, 19, 17, 11, 17, 20, 20, 11, 20, 20, 14,\n",
       "                      20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                      10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 19,\n",
       "                      16, 14, 15, 13, 20, 10, 12, 16, 17, 19, 19, 15, 14, 11,\n",
       "                      20, 20, 12, 3, 16, 20, 19, 20, 19, 17, 18, 14, 20, 20,\n",
       "                      20, 20],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_features': masked_array(data=['log2', 'sqrt', 'log2', 'log2', 'log2', 'log2', 'log2',\n",
       "                      'log2', 'sqrt', 'log2', 'sqrt', 'auto', 'auto', 'sqrt',\n",
       "                      'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                      'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'auto', 'sqrt',\n",
       "                      'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                      'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'auto',\n",
       "                      'sqrt', 'sqrt', 'sqrt', 'sqrt', 'log2', 'sqrt', 'sqrt',\n",
       "                      'auto', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                      'auto', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt', 'sqrt',\n",
       "                      'sqrt', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                      'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                      'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                      'auto', 'auto', 'auto', 'sqrt', 'auto', 'auto', 'auto',\n",
       "                      'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                      'auto', 'log2'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_min_samples_leaf': masked_array(data=[13, 12, 5, 10, 6, 10, 5, 2, 19, 16, 1, 20, 20, 20, 20,\n",
       "                      20, 19, 20, 11, 1, 10, 20, 1, 20, 20, 15, 17, 20, 20,\n",
       "                      20, 20, 16, 1, 1, 1, 1, 20, 20, 18, 20, 20, 11, 20, 20,\n",
       "                      20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 10, 20,\n",
       "                      20, 20, 20, 20, 20, 20, 5, 20, 1, 1, 20, 20, 20, 20,\n",
       "                      20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                      1, 6, 20, 20, 20, 20, 20, 20, 20, 1, 18, 4, 18, 1],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_min_samples_split': masked_array(data=[0.08728694484896253, 0.03362718304348816,\n",
       "                      0.03164168370753818, 0.0836125439825416,\n",
       "                      0.026298677076393044, 0.040007835106371355,\n",
       "                      0.031469174629693675, 0.01474531723241193,\n",
       "                      0.050373869876860045, 0.01631101512501576, 0.01, 0.01,\n",
       "                      0.024091457031890424, 0.01, 0.01, 0.01,\n",
       "                      0.011630142468411386, 0.01, 0.09996478214012676, 0.01,\n",
       "                      0.011472546623664676, 0.01, 0.010139112741336007, 0.01,\n",
       "                      0.01, 0.1, 0.09750184826772289, 0.01, 0.01, 0.01, 0.01,\n",
       "                      0.01001744386052707, 0.01, 0.01, 0.04209623381761253,\n",
       "                      0.01, 0.01, 0.01, 0.010137377264938019, 0.01, 0.01,\n",
       "                      0.010675641798119905, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                      0.01, 0.01, 0.019744649075313616, 0.01, 0.01, 0.01,\n",
       "                      0.01, 0.01, 0.01, 0.012233640644173833, 0.01, 0.01,\n",
       "                      0.01, 0.01, 0.01, 0.01, 0.01, 0.010133850285744575,\n",
       "                      0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                      0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                      0.01, 0.01, 0.014132824428116905, 0.01,\n",
       "                      0.06488269824504934, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                      0.01, 0.01, 0.01, 0.06497902448544271,\n",
       "                      0.07460851960142634, 0.056701235621418565, 0.01],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_n_estimators': masked_array(data=[392, 73, 143, 275, 109, 119, 344, 104, 222, 300, 10,\n",
       "                      400, 400, 400, 10, 400, 247, 10, 48, 400, 353, 400,\n",
       "                      394, 400, 400, 400, 271, 400, 400, 400, 400, 220, 400,\n",
       "                      400, 400, 400, 400, 400, 19, 400, 400, 20, 400, 400,\n",
       "                      400, 400, 400, 400, 400, 13, 400, 400, 400, 400, 400,\n",
       "                      400, 70, 400, 400, 400, 400, 400, 400, 400, 341, 400,\n",
       "                      400, 400, 10, 182, 400, 400, 190, 134, 238, 400, 400,\n",
       "                      10, 256, 400, 332, 400, 281, 10, 335, 400, 400, 400,\n",
       "                      327, 328, 333, 332, 335, 400, 400, 10, 400, 136, 28,\n",
       "                      10],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 14),\n",
       "                 ('max_features', 'log2'),\n",
       "                 ('min_samples_leaf', 13),\n",
       "                 ('min_samples_split', 0.08728694484896253),\n",
       "                 ('n_estimators', 392)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 12),\n",
       "                 ('min_samples_split', 0.03362718304348816),\n",
       "                 ('n_estimators', 73)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 4),\n",
       "                 ('max_features', 'log2'),\n",
       "                 ('min_samples_leaf', 5),\n",
       "                 ('min_samples_split', 0.03164168370753818),\n",
       "                 ('n_estimators', 143)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 16),\n",
       "                 ('max_features', 'log2'),\n",
       "                 ('min_samples_leaf', 10),\n",
       "                 ('min_samples_split', 0.0836125439825416),\n",
       "                 ('n_estimators', 275)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 7),\n",
       "                 ('max_features', 'log2'),\n",
       "                 ('min_samples_leaf', 6),\n",
       "                 ('min_samples_split', 0.026298677076393044),\n",
       "                 ('n_estimators', 109)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'log2'),\n",
       "                 ('min_samples_leaf', 10),\n",
       "                 ('min_samples_split', 0.040007835106371355),\n",
       "                 ('n_estimators', 119)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 16),\n",
       "                 ('max_features', 'log2'),\n",
       "                 ('min_samples_leaf', 5),\n",
       "                 ('min_samples_split', 0.031469174629693675),\n",
       "                 ('n_estimators', 344)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 12),\n",
       "                 ('max_features', 'log2'),\n",
       "                 ('min_samples_leaf', 2),\n",
       "                 ('min_samples_split', 0.01474531723241193),\n",
       "                 ('n_estimators', 104)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 18),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 19),\n",
       "                 ('min_samples_split', 0.050373869876860045),\n",
       "                 ('n_estimators', 222)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 10),\n",
       "                 ('max_features', 'log2'),\n",
       "                 ('min_samples_leaf', 16),\n",
       "                 ('min_samples_split', 0.01631101512501576),\n",
       "                 ('n_estimators', 300)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 15),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 10)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 19),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 15),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.024091457031890424),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 19),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 15),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 10)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 3),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 19),\n",
       "                 ('min_samples_split', 0.011630142468411386),\n",
       "                 ('n_estimators', 247)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 10)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 8),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 11),\n",
       "                 ('min_samples_split', 0.09996478214012676),\n",
       "                 ('n_estimators', 48)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 14),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 10),\n",
       "                 ('min_samples_split', 0.011472546623664676),\n",
       "                 ('n_estimators', 353)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 16),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 12),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.010139112741336007),\n",
       "                 ('n_estimators', 394)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 18),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 15),\n",
       "                 ('min_samples_split', 0.1),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 3),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 17),\n",
       "                 ('min_samples_split', 0.09750184826772289),\n",
       "                 ('n_estimators', 271)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 14),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 16),\n",
       "                 ('min_samples_split', 0.01001744386052707),\n",
       "                 ('n_estimators', 220)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 19),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 17),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 11),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.04209623381761253),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 17),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 11),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 18),\n",
       "                 ('min_samples_split', 0.010137377264938019),\n",
       "                 ('n_estimators', 19)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 14),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 11),\n",
       "                 ('min_samples_split', 0.010675641798119905),\n",
       "                 ('n_estimators', 20)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'log2'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 3),\n",
       "                 ('min_samples_split', 0.019744649075313616),\n",
       "                 ('n_estimators', 13)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 10),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 10),\n",
       "                 ('min_samples_split', 0.012233640644173833),\n",
       "                 ('n_estimators', 70)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 5),\n",
       "                 ('min_samples_split', 0.010133850285744575),\n",
       "                 ('n_estimators', 341)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 18),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 10)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 19),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 182)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 16),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 14),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 15),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 190)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 13),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 134)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 238)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 10),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 12),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 16),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 10)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 17),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 256)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 19),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 19),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 332)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 15),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 14),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 281)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 11),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 10)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 335)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.014132824428116905),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 12),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 3),\n",
       "                 ('max_features', 'sqrt'),\n",
       "                 ('min_samples_leaf', 6),\n",
       "                 ('min_samples_split', 0.06488269824504934),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 16),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 327)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 328)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 19),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 333)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 332)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 19),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 335)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 17),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 18),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 20),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 14),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 10)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 18),\n",
       "                 ('min_samples_split', 0.06497902448544271),\n",
       "                 ('n_estimators', 400)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 4),\n",
       "                 ('min_samples_split', 0.07460851960142634),\n",
       "                 ('n_estimators', 136)]),\n",
       "    OrderedDict([('bootstrap', True),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'auto'),\n",
       "                 ('min_samples_leaf', 18),\n",
       "                 ('min_samples_split', 0.056701235621418565),\n",
       "                 ('n_estimators', 28)]),\n",
       "    OrderedDict([('bootstrap', False),\n",
       "                 ('max_depth', 20),\n",
       "                 ('max_features', 'log2'),\n",
       "                 ('min_samples_leaf', 1),\n",
       "                 ('min_samples_split', 0.01),\n",
       "                 ('n_estimators', 10)])],\n",
       "   'split0_test_score': array([-0.62737673, -0.44788144, -0.66342317, -0.57541949, -0.54050573,\n",
       "          -0.54798394, -0.51631948, -0.48169778, -0.47311956, -0.48665739,\n",
       "          -0.42426002, -0.43186005, -0.50148277, -0.42220956, -0.45752667,\n",
       "          -0.42365966, -0.64324794, -0.42667481, -0.56072952, -0.41921524,\n",
       "          -0.42783044, -0.4196169 , -0.4367809 , -0.42241076, -0.42365966,\n",
       "          -0.54563705, -0.68741927, -0.42365966, -0.42335842, -0.42365966,\n",
       "          -0.42365966, -0.43605621, -0.42010269, -0.41784809, -0.46995957,\n",
       "          -0.43205189, -0.42365966, -0.42365966, -0.45128786, -0.42365966,\n",
       "          -0.42365966, -0.44235168, -0.42365966, -0.42365966, -0.42365966,\n",
       "          -0.42365966, -0.45310409, -0.42365966, -0.42365966, -0.49948358,\n",
       "          -0.42365966, -0.42365966, -0.42365966, -0.42365966, -0.42365966,\n",
       "          -0.42365966, -0.45987363, -0.42365966, -0.42365966, -0.42365966,\n",
       "          -0.42365966, -0.42365966, -0.42365966, -0.42365966, -0.42427225,\n",
       "          -0.42416621, -0.42571803, -0.42571803, -0.41173445, -0.42254522,\n",
       "          -0.42447166, -0.42472936, -0.42231807, -0.42627296, -0.42320874,\n",
       "          -0.43161747, -0.42498133, -0.41173445, -0.42498953, -0.42416621,\n",
       "          -0.42373333, -0.4245923 , -0.42696757, -0.44205234, -0.42355124,\n",
       "          -0.44497284, -0.42535199, -0.66013491, -0.42440816, -0.42414914,\n",
       "          -0.42366442, -0.42373333, -0.42355124, -0.4241829 , -0.42416621,\n",
       "          -0.41679648, -0.62133118, -0.62466716, -0.57272798, -0.42850422]),\n",
       "   'split1_test_score': array([-0.56998187, -0.43876904, -0.61924742, -0.52597417, -0.5217038 ,\n",
       "          -0.50120417, -0.49948044, -0.44964452, -0.46134885, -0.4652424 ,\n",
       "          -0.46496503, -0.63497117, -0.64201915, -0.41743521, -0.4251696 ,\n",
       "          -0.41598149, -0.63455431, -0.44354595, -0.52409241, -0.41518802,\n",
       "          -0.41540415, -0.41828888, -0.43040525, -0.42166889, -0.41598149,\n",
       "          -0.50556343, -0.65189651, -0.41598149, -0.41718745, -0.41598149,\n",
       "          -0.41598149, -0.42710858, -0.41677689, -0.41543217, -0.45431607,\n",
       "          -0.42263823, -0.41598149, -0.41598149, -0.4840962 , -0.41598149,\n",
       "          -0.41598149, -0.63954186, -0.41598149, -0.41598149, -0.41598149,\n",
       "          -0.41598149, -0.44980033, -0.41598149, -0.41598149, -0.63847124,\n",
       "          -0.41598149, -0.41598149, -0.41598149, -0.41598149, -0.41598149,\n",
       "          -0.41598149, -0.6442405 , -0.41598149, -0.41598149, -0.41598149,\n",
       "          -0.41598149, -0.41598149, -0.41598149, -0.41598149, -0.55882655,\n",
       "          -0.55704965, -0.56048582, -0.56048582, -0.51361521, -0.55255447,\n",
       "          -0.55723424, -0.55749096, -0.55406802, -0.55773396, -0.55643811,\n",
       "          -0.56290157, -0.55920168, -0.51361521, -0.5564755 , -0.55704965,\n",
       "          -0.55831761, -0.5572156 , -0.55767559, -0.5091674 , -0.55889917,\n",
       "          -0.56373002, -0.56049834, -0.63416537, -0.55819648, -0.55816721,\n",
       "          -0.55854048, -0.55831761, -0.55889917, -0.55722337, -0.55704965,\n",
       "          -0.52180504, -0.67279108, -0.62849249, -0.61941729, -0.49643342]),\n",
       "   'split2_test_score': array([-0.6088541 , -0.47868231, -0.63041619, -0.5631209 , -0.54200333,\n",
       "          -0.53937991, -0.52698156, -0.49984918, -0.49897397, -0.49245608,\n",
       "          -0.45044254, -0.39888749, -0.40724791, -0.42906085, -0.48148487,\n",
       "          -0.42909404, -0.63055693, -0.45842265, -0.54295026, -0.4311676 ,\n",
       "          -0.43333409, -0.43016495, -0.4461861 , -0.42958193, -0.42909404,\n",
       "          -0.53192271, -0.65484073, -0.42909404, -0.433178  , -0.42909404,\n",
       "          -0.42909404, -0.44592871, -0.43106346, -0.43060176, -0.4930731 ,\n",
       "          -0.44373424, -0.42909404, -0.42909404, -0.45536793, -0.42909404,\n",
       "          -0.42909404, -0.40794835, -0.42909404, -0.42909404, -0.42909404,\n",
       "          -0.42909404, -0.47395477, -0.42909404, -0.42909404, -0.41631366,\n",
       "          -0.42909404, -0.42909404, -0.42909404, -0.42909404, -0.42909404,\n",
       "          -0.42909404, -0.40471285, -0.42909404, -0.42909404, -0.42909404,\n",
       "          -0.42909404, -0.42909404, -0.42909404, -0.42909404, -0.33626854,\n",
       "          -0.33796238, -0.33631926, -0.33633154, -0.36007256, -0.33829521,\n",
       "          -0.3382112 , -0.33844474, -0.33758705, -0.33976822, -0.33736355,\n",
       "          -0.34438637, -0.33935129, -0.36007256, -0.33707003, -0.33796238,\n",
       "          -0.33798479, -0.33807916, -0.33827141, -0.36748457, -0.338296  ,\n",
       "          -0.34957099, -0.33751904, -0.63739519, -0.33822162, -0.3379719 ,\n",
       "          -0.3379317 , -0.33798479, -0.338296  , -0.33804966, -0.33794134,\n",
       "          -0.35807924, -0.47051699, -0.50792534, -0.47396728, -0.4779995 ]),\n",
       "   'split3_test_score': array([-0.58021459, -0.44291287, -0.61684803, -0.53386192, -0.5122538 ,\n",
       "          -0.52247078, -0.50630128, -0.49469429, -0.45765101, -0.47350353,\n",
       "          -0.42505113, -0.45835768, -0.46249204, -0.40807235, -0.44471497,\n",
       "          -0.40678379, -0.6129122 , -0.40251637, -0.49451457, -0.41086421,\n",
       "          -0.41503541, -0.40861306, -0.41918895, -0.40811868, -0.40678379,\n",
       "          -0.50075754, -0.58871744, -0.40678379, -0.41509372, -0.40678379,\n",
       "          -0.40678379, -0.42098061, -0.41200024, -0.41050488, -0.45249259,\n",
       "          -0.42373351, -0.40678379, -0.40678379, -0.38503613, -0.40678379,\n",
       "          -0.40678379, -0.44742261, -0.40678379, -0.40678379, -0.40678379,\n",
       "          -0.40678379, -0.44988262, -0.40678379, -0.40678379, -0.44383947,\n",
       "          -0.40678379, -0.40678379, -0.40678379, -0.40678379, -0.40678379,\n",
       "          -0.40678379, -0.45555907, -0.40678379, -0.40678379, -0.40678379,\n",
       "          -0.40678379, -0.40678379, -0.40678379, -0.40678379, -0.3845211 ,\n",
       "          -0.38464367, -0.38541165, -0.38533289, -0.38583665, -0.38236285,\n",
       "          -0.38446397, -0.38525293, -0.38156544, -0.38559051, -0.38275883,\n",
       "          -0.39163317, -0.38642215, -0.38583665, -0.38303993, -0.38464367,\n",
       "          -0.38494504, -0.38456872, -0.38459558, -0.38842253, -0.38447835,\n",
       "          -0.39001828, -0.38360466, -0.61547817, -0.38501346, -0.38499495,\n",
       "          -0.3849245 , -0.38494504, -0.38447835, -0.38463416, -0.38464367,\n",
       "          -0.38891952, -0.51562222, -0.48656624, -0.47472184, -0.47361736]),\n",
       "   'split4_test_score': array([-0.72604864, -0.57151951, -0.76977287, -0.6710008 , -0.64493504,\n",
       "          -0.66575568, -0.62163184, -0.59248455, -0.59306085, -0.58961765,\n",
       "          -0.54174949, -0.49577265, -0.50929392, -0.5204291 , -0.58089849,\n",
       "          -0.51921712, -0.77664701, -0.56020433, -0.67454724, -0.51823961,\n",
       "          -0.52678978, -0.51980063, -0.53761318, -0.51780888, -0.51921712,\n",
       "          -0.65745129, -0.66669212, -0.51921712, -0.52494697, -0.51921712,\n",
       "          -0.51921712, -0.53629395, -0.52085141, -0.52175111, -0.58329564,\n",
       "          -0.52432041, -0.51921712, -0.51921712, -0.55484302, -0.51921712,\n",
       "          -0.51921712, -0.50127701, -0.51921712, -0.51921712, -0.51921712,\n",
       "          -0.51921712, -0.5593365 , -0.51921712, -0.51921712, -0.51071561,\n",
       "          -0.51921712, -0.51921712, -0.51921712, -0.51921712, -0.51921712,\n",
       "          -0.51921712, -0.51307214, -0.51921712, -0.51921712, -0.51921712,\n",
       "          -0.51921712, -0.51921712, -0.51921712, -0.51921712, -0.44556673,\n",
       "          -0.44220456, -0.44654649, -0.44654649, -0.45035585, -0.44418939,\n",
       "          -0.44237494, -0.44259465, -0.44445783, -0.44172312, -0.44319807,\n",
       "          -0.44953285, -0.44424665, -0.45127018, -0.44371824, -0.44220456,\n",
       "          -0.44285421, -0.44259608, -0.44330495, -0.45096874, -0.44305143,\n",
       "          -0.44838613, -0.4491935 , -0.77743309, -0.44289939, -0.44274927,\n",
       "          -0.44290858, -0.44285421, -0.44305143, -0.44231131, -0.44220456,\n",
       "          -0.45604476, -0.513833  , -0.5528692 , -0.51090719, -0.6229921 ]),\n",
       "   'split5_test_score': array([-0.69399534, -0.50610968, -0.73931759, -0.61722876, -0.58719829,\n",
       "          -0.60156432, -0.57141913, -0.52971675, -0.53274608, -0.525777  ,\n",
       "          -0.50486438, -0.4069359 , -0.43626487, -0.4516118 , -0.46827092,\n",
       "          -0.45074194, -0.76240907, -0.4799346 , -0.61590764, -0.45510056,\n",
       "          -0.46430994, -0.45494933, -0.47132593, -0.44977966, -0.45074194,\n",
       "          -0.59412779, -0.71981326, -0.45074194, -0.45750008, -0.45074194,\n",
       "          -0.45074194, -0.46967386, -0.45165236, -0.45293983, -0.52137384,\n",
       "          -0.46725669, -0.45074194, -0.45074194, -0.48862403, -0.45074194,\n",
       "          -0.45074194, -0.40559023, -0.45074194, -0.45074194, -0.45074194,\n",
       "          -0.45074194, -0.48914083, -0.45074194, -0.45074194, -0.42571251,\n",
       "          -0.45074194, -0.45074194, -0.45074194, -0.45074194, -0.45074194,\n",
       "          -0.45074194, -0.41879011, -0.45074194, -0.45074194, -0.45074194,\n",
       "          -0.45074194, -0.45074194, -0.45074194, -0.45074194, -0.37367458,\n",
       "          -0.37542913, -0.37406803, -0.37410276, -0.38477592, -0.37631851,\n",
       "          -0.37541501, -0.3763593 , -0.37634009, -0.37698314, -0.37705011,\n",
       "          -0.37908171, -0.37723421, -0.38477592, -0.37627575, -0.37542913,\n",
       "          -0.37457341, -0.37546419, -0.37566229, -0.39150134, -0.37431274,\n",
       "          -0.39286879, -0.37406676, -0.764518  , -0.37487151, -0.37465138,\n",
       "          -0.37439492, -0.37457341, -0.37431274, -0.37541585, -0.37543644,\n",
       "          -0.38869774, -0.54547135, -0.58583815, -0.52303522, -0.48230634]),\n",
       "   'split6_test_score': array([-0.57753381, -0.51175187, -0.58286318, -0.53307081, -0.52330739,\n",
       "          -0.53162829, -0.5084236 , -0.50480463, -0.49748445, -0.49310751,\n",
       "          -0.47976438, -0.56625212, -0.60143526, -0.46474168, -0.47679383,\n",
       "          -0.4650691 , -0.56531718, -0.47911464, -0.54747844, -0.47046377,\n",
       "          -0.47680054, -0.46915791, -0.47661004, -0.4677935 , -0.4650691 ,\n",
       "          -0.53069281, -0.64492489, -0.4650691 , -0.4715587 , -0.4650691 ,\n",
       "          -0.4650691 , -0.47649829, -0.46890353, -0.46996038, -0.49946795,\n",
       "          -0.46984819, -0.4650691 , -0.4650691 , -0.48092882, -0.4650691 ,\n",
       "          -0.4650691 , -0.61523943, -0.4650691 , -0.4650691 , -0.4650691 ,\n",
       "          -0.4650691 , -0.47320927, -0.4650691 , -0.4650691 , -0.61484993,\n",
       "          -0.4650691 , -0.4650691 , -0.4650691 , -0.4650691 , -0.4650691 ,\n",
       "          -0.4650691 , -0.58840936, -0.4650691 , -0.4650691 , -0.4650691 ,\n",
       "          -0.4650691 , -0.4650691 , -0.4650691 , -0.4650691 , -0.53394004,\n",
       "          -0.52938832, -0.53273447, -0.53276032, -0.55058048, -0.52985205,\n",
       "          -0.5293975 , -0.52916812, -0.53030631, -0.52943578, -0.53108897,\n",
       "          -0.53115925, -0.52922428, -0.55058048, -0.53248766, -0.52938832,\n",
       "          -0.53145869, -0.52955516, -0.53058208, -0.53948792, -0.53138909,\n",
       "          -0.54932748, -0.5326324 , -0.56638669, -0.53157085, -0.53131569,\n",
       "          -0.53144882, -0.53145869, -0.53138909, -0.52934575, -0.52940037,\n",
       "          -0.5369673 , -0.67680285, -0.61474393, -0.60855909, -0.5338007 ]),\n",
       "   'split7_test_score': array([-0.5707693 , -0.44445671, -0.59969059, -0.52790475, -0.50133186,\n",
       "          -0.50903271, -0.48903425, -0.47087897, -0.46849595, -0.46535583,\n",
       "          -0.46478769, -0.56337259, -0.58391946, -0.42510658, -0.44500754,\n",
       "          -0.42496416, -0.60232822, -0.45452455, -0.504729  , -0.42630884,\n",
       "          -0.43117658, -0.42574914, -0.4358704 , -0.42530262, -0.42496416,\n",
       "          -0.50521674, -0.61703341, -0.42496416, -0.42839411, -0.42496416,\n",
       "          -0.42496416, -0.43627942, -0.42625961, -0.42927168, -0.46280204,\n",
       "          -0.43482851, -0.42496416, -0.42496416, -0.45736304, -0.42496416,\n",
       "          -0.42496416, -0.55717148, -0.42496416, -0.42496416, -0.42496416,\n",
       "          -0.42496416, -0.45787988, -0.42496416, -0.42496416, -0.59161406,\n",
       "          -0.42496416, -0.42496416, -0.42496416, -0.42496416, -0.42496416,\n",
       "          -0.42496416, -0.57808422, -0.42496416, -0.42496416, -0.42496416,\n",
       "          -0.42496416, -0.42496416, -0.42496416, -0.42496416, -0.52766985,\n",
       "          -0.51950422, -0.52652756, -0.52652756, -0.50839508, -0.52333852,\n",
       "          -0.51950422, -0.51941377, -0.52384323, -0.52300809, -0.5220474 ,\n",
       "          -0.52126986, -0.51951325, -0.50839508, -0.52107145, -0.51950422,\n",
       "          -0.52033335, -0.51955091, -0.52147469, -0.5090431 , -0.52004465,\n",
       "          -0.52721968, -0.52664956, -0.6053787 , -0.52061857, -0.52060756,\n",
       "          -0.52040885, -0.52033335, -0.52004465, -0.51950422, -0.51950422,\n",
       "          -0.51870805, -0.55779469, -0.58826808, -0.54282498, -0.48555939]),\n",
       "   'split8_test_score': array([-0.56220355, -0.39494804, -0.60729883, -0.5069461 , -0.47708343,\n",
       "          -0.49046926, -0.46746542, -0.43043792, -0.4304794 , -0.41987226,\n",
       "          -0.37204357, -0.34071464, -0.35015943, -0.35415015, -0.35726253,\n",
       "          -0.35413704, -0.62536239, -0.38859106, -0.49741798, -0.35082324,\n",
       "          -0.35630409, -0.35604761, -0.37127089, -0.35405519, -0.35413704,\n",
       "          -0.48973764, -0.62422882, -0.35413704, -0.35347768, -0.35413704,\n",
       "          -0.35413704, -0.37071932, -0.35159116, -0.34921006, -0.41936126,\n",
       "          -0.36023937, -0.35413704, -0.35413704, -0.36116051, -0.35413704,\n",
       "          -0.35413704, -0.34028276, -0.35413704, -0.35413704, -0.35413704,\n",
       "          -0.35413704, -0.38456154, -0.35413704, -0.35413704, -0.35548985,\n",
       "          -0.35413704, -0.35413704, -0.35413704, -0.35413704, -0.35413704,\n",
       "          -0.35413704, -0.35844831, -0.35413704, -0.35413704, -0.35413704,\n",
       "          -0.35413704, -0.35413704, -0.35413704, -0.35413704, -0.27722704,\n",
       "          -0.27575773, -0.27735093, -0.27735093, -0.28139692, -0.27975653,\n",
       "          -0.27578691, -0.27619491, -0.27866775, -0.27833454, -0.27849434,\n",
       "          -0.28739881, -0.27769886, -0.28139692, -0.27855372, -0.27575773,\n",
       "          -0.27552039, -0.27605746, -0.27690249, -0.28633057, -0.27544381,\n",
       "          -0.29197402, -0.27968165, -0.62834692, -0.27618029, -0.27590497,\n",
       "          -0.27536402, -0.27552039, -0.27544381, -0.27576488, -0.27575773,\n",
       "          -0.29078847, -0.4250084 , -0.48331287, -0.41195549, -0.43513617]),\n",
       "   'split9_test_score': array([-0.60185154, -0.47604559, -0.64932752, -0.54295933, -0.52520595,\n",
       "          -0.53370568, -0.50339833, -0.47504129, -0.47786127, -0.4727296 ,\n",
       "          -0.45053557, -0.35360275, -0.40787335, -0.42927288, -0.50904789,\n",
       "          -0.42994443, -0.65670461, -0.44646548, -0.54249983, -0.43046366,\n",
       "          -0.43755769, -0.43173823, -0.44334054, -0.43102867, -0.42994443,\n",
       "          -0.52111946, -0.61457167, -0.42994443, -0.43350754, -0.42994443,\n",
       "          -0.42994443, -0.44153368, -0.43051681, -0.43274156, -0.47208007,\n",
       "          -0.44251692, -0.42994443, -0.42994443, -0.42773532, -0.42994443,\n",
       "          -0.42994443, -0.36652885, -0.42994443, -0.42994443, -0.42994443,\n",
       "          -0.42994443, -0.44539327, -0.42994443, -0.42994443, -0.41066354,\n",
       "          -0.42994443, -0.42994443, -0.42994443, -0.42994443, -0.42994443,\n",
       "          -0.42994443, -0.39154842, -0.42994443, -0.42994443, -0.42994443,\n",
       "          -0.42994443, -0.42994443, -0.42994443, -0.42994443, -0.34657013,\n",
       "          -0.34563952, -0.35552048, -0.35552048, -0.36845512, -0.34635573,\n",
       "          -0.34572478, -0.34450936, -0.34613045, -0.34311053, -0.34426037,\n",
       "          -0.35318072, -0.34467475, -0.36845512, -0.3439917 , -0.34563952,\n",
       "          -0.3448375 , -0.3464028 , -0.34476467, -0.36144293, -0.34453868,\n",
       "          -0.36365591, -0.35619422, -0.65999959, -0.3446121 , -0.34454953,\n",
       "          -0.34478872, -0.3448375 , -0.34453868, -0.34563952, -0.34563952,\n",
       "          -0.37979063, -0.47059038, -0.4763937 , -0.4513927 , -0.47114692]),\n",
       "   'mean_test_score': array([-0.61188295, -0.47130771, -0.64782054, -0.5597487 , -0.53755286,\n",
       "          -0.54431947, -0.52104553, -0.49292499, -0.48912214, -0.48843193,\n",
       "          -0.45784638, -0.4650727 , -0.49021882, -0.43220902, -0.46461773,\n",
       "          -0.43195928, -0.65100399, -0.45399944, -0.55048669, -0.43278348,\n",
       "          -0.43845427, -0.43341266, -0.44685922, -0.43275488, -0.43195928,\n",
       "          -0.53822264, -0.64701381, -0.43195928, -0.43582027, -0.43195928,\n",
       "          -0.43195928, -0.44610726, -0.43297182, -0.43302615, -0.48282221,\n",
       "          -0.4421168 , -0.43195928, -0.43195928, -0.45464429, -0.43195928,\n",
       "          -0.43195928, -0.47233543, -0.43195928, -0.43195928, -0.43195928,\n",
       "          -0.43195928, -0.46362631, -0.43195928, -0.43195928, -0.49071535,\n",
       "          -0.43195928, -0.43195928, -0.43195928, -0.43195928, -0.43195928,\n",
       "          -0.43195928, -0.48127386, -0.43195928, -0.43195928, -0.43195928,\n",
       "          -0.43195928, -0.43195928, -0.43195928, -0.43195928, -0.42085368,\n",
       "          -0.41917454, -0.42206827, -0.42206768, -0.42152182, -0.41955685,\n",
       "          -0.41925844, -0.41941581, -0.41952842, -0.42019609, -0.41959085,\n",
       "          -0.42521618, -0.42025484, -0.42161326, -0.41976735, -0.41917454,\n",
       "          -0.41945583, -0.41940824, -0.42002013, -0.42459014, -0.41940052,\n",
       "          -0.43217241, -0.42253921, -0.65492366, -0.41965924, -0.41950616,\n",
       "          -0.4194375 , -0.41945583, -0.41940052, -0.41920716, -0.41917437,\n",
       "          -0.42565972, -0.54697621, -0.55490772, -0.51895091, -0.49074961]),\n",
       "   'std_test_score': array([0.05312526, 0.04683134, 0.05809164, 0.04748107, 0.04498806,\n",
       "          0.04981623, 0.04214429, 0.04262356, 0.04345386, 0.04232555,\n",
       "          0.04416292, 0.09300921, 0.09035727, 0.04034925, 0.05463846,\n",
       "          0.0401727 , 0.0638738 , 0.04521522, 0.05352108, 0.04118513,\n",
       "          0.04238321, 0.04036822, 0.04087193, 0.03981306, 0.0401727 ,\n",
       "          0.04867769, 0.03643899, 0.0401727 , 0.04179793, 0.0401727 ,\n",
       "          0.0401727 , 0.04062861, 0.04111947, 0.04210123, 0.04290073,\n",
       "          0.03966982, 0.0401727 , 0.0401727 , 0.05203891, 0.0401727 ,\n",
       "          0.0401727 , 0.09755385, 0.0401727 , 0.0401727 , 0.0401727 ,\n",
       "          0.0401727 , 0.04137319, 0.0401727 , 0.0401727 , 0.09195172,\n",
       "          0.0401727 , 0.0401727 , 0.0401727 , 0.0401727 , 0.0401727 ,\n",
       "          0.0401727 , 0.0907972 , 0.0401727 , 0.0401727 , 0.0401727 ,\n",
       "          0.0401727 , 0.0401727 , 0.0401727 , 0.0401727 , 0.08983562,\n",
       "          0.08800864, 0.08905224, 0.08905564, 0.07903307, 0.08717721,\n",
       "          0.08801792, 0.08796356, 0.08782556, 0.08804604, 0.08816875,\n",
       "          0.08603034, 0.08786701, 0.07906689, 0.08832946, 0.08800864,\n",
       "          0.08871164, 0.0879516 , 0.08837865, 0.07566714, 0.08880619,\n",
       "          0.08659577, 0.08866476, 0.0635345 , 0.08861651, 0.08865786,\n",
       "          0.08879917, 0.08871164, 0.08880619, 0.08802525, 0.08801173,\n",
       "          0.0767271 , 0.08183569, 0.05839812, 0.06454325, 0.05222997]),\n",
       "   'rank_test_score': array([ 96,  77,  98,  95,  89,  91,  88,  86,  82,  81,  73,  76,  83,\n",
       "           60,  75,  31,  99,  71,  93,  62,  67,  65,  70,  61,  31,  90,\n",
       "           97,  31,  66,  31,  31,  69,  63,  64,  80,  68,  31,  31,  72,\n",
       "           31,  31,  78,  31,  31,  31,  31,  74,  31,  31,  84,  31,  31,\n",
       "           31,  31,  31,  31,  79,  31,  31,  31,  31,  31,  31,  31,  22,\n",
       "            2,  26,  25,  23,  15,   5,   9,  14,  20,  16,  29,  21,  24,\n",
       "           18,   2,  12,   8,  19,  28,   6,  59,  27, 100,  17,  13,  10,\n",
       "           11,   6,   4,   1,  30,  92,  94,  87,  85], dtype=int32)}},\n",
       " 'XGB': {'best_estimator': XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=0.5, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "               gamma=0.0, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None, learning_rate=0.050107716228528415,\n",
       "               max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "               max_delta_step=None, max_depth=7, max_leaves=None,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               n_estimators=287, n_jobs=6, num_parallel_tree=None, predictor=None,\n",
       "               random_state=0, ...),\n",
       "  'best_params': OrderedDict([('colsample_bytree', 0.5),\n",
       "               ('gamma', 0.0),\n",
       "               ('learning_rate', 0.050107716228528415),\n",
       "               ('max_depth', 7),\n",
       "               ('n_estimators', 287),\n",
       "               ('subsample', 1.0)]),\n",
       "  'best_score': -0.31382143682389885,\n",
       "  'optimization_history': {'mean_fit_time': array([176.16625171,  47.07143366,  23.83896995, 105.20584536,\n",
       "           20.75158007,  68.66697855,  27.7141917 ,   3.7475949 ,\n",
       "           93.48384144,  18.50023263,   8.91808641,  49.51126676,\n",
       "           34.46022482,   8.27056272, 112.5157901 ,  35.61849597,\n",
       "            1.47920403, 180.96594284, 158.4266294 ,  50.07515452,\n",
       "          230.32460582, 282.8883657 , 150.72870619,  45.9711827 ,\n",
       "          102.36077337,  41.57406142,  71.51594784,  89.63215098,\n",
       "          184.08407257, 131.30891156, 224.54981151,  32.16598299,\n",
       "           20.06202629,  11.88024039,  25.94685345,  25.1809726 ,\n",
       "          199.87046173,  53.80536978,  13.41972721,  27.59933946,\n",
       "           25.3005244 , 129.19916232, 120.09825017,  47.20655792,\n",
       "           37.53295369,  38.22027626,  86.65334902, 259.85353377,\n",
       "           31.84479334,  21.86405492, 108.82200613,  47.55578573,\n",
       "           35.15399935, 292.93144677, 263.81455421, 196.17992177,\n",
       "           59.49113786,  89.49271407,  33.7783098 ,  57.17397182,\n",
       "          121.73429506, 140.02128444, 158.31185403,  72.74353633,\n",
       "           88.03566821,  97.83417311,  75.06829317, 149.41957314,\n",
       "           91.86353741, 112.91406233, 134.64199629,  88.30059407,\n",
       "           59.84735661, 120.11345842,  77.89918735, 169.16643932,\n",
       "          115.39840691,  55.13039052,  46.1678195 , 197.61433332,\n",
       "          174.58009005,  61.3949538 , 194.48069746,  47.72537384,\n",
       "           89.57135718,  85.91099811, 136.1137912 ,  63.44731827,\n",
       "           69.96024203, 188.77638533,  68.75936372,  50.68643489,\n",
       "           98.13971024,  86.88625915,  36.41701312, 232.89373126,\n",
       "           38.32113314,  31.43058915, 193.97780473,  23.90749762]),\n",
       "   'std_fit_time': array([33.36996524,  9.26223462,  4.53242774, 19.61396905,  3.93390103,\n",
       "          13.46141936,  5.22189323,  0.74791978, 19.07524786,  3.75781359,\n",
       "           1.64491824,  9.22244206,  6.73662497,  1.48447639, 21.33624678,\n",
       "           6.66674128,  0.30569065, 37.01198809, 30.72215055,  9.37845182,\n",
       "          43.71369393, 54.32936597, 30.71899605,  8.49457562, 20.88217563,\n",
       "           7.7149105 , 13.73197641, 17.31092055, 35.08764492, 24.26105405,\n",
       "          40.92875498,  6.6716139 ,  3.73407618,  2.29682177,  4.77608466,\n",
       "           4.59210778, 38.06773233,  9.88656529,  2.78159601,  4.9742463 ,\n",
       "           4.61345632, 25.31714687, 22.18108317,  9.56130886,  7.20274025,\n",
       "           7.35766345, 15.92247114, 51.50048017,  6.25762984,  4.33993569,\n",
       "          21.75192423,  9.51674519,  6.18280907, 56.0020119 , 52.02586323,\n",
       "          37.76757166, 10.90963471, 16.85710414,  6.32332984, 10.56704346,\n",
       "          24.08690023, 27.67840731, 31.7763326 , 13.86184085, 17.44121759,\n",
       "          18.05043327, 13.81668375, 29.59090863, 18.02222801, 20.61725508,\n",
       "          25.38425044, 19.42898472, 11.12792531, 22.76256415, 14.85078207,\n",
       "          32.04937443, 21.97151126, 10.95207087,  8.2580047 , 42.08626906,\n",
       "          33.10017921, 11.88495776, 32.13907059,  8.6220478 , 16.75667137,\n",
       "          16.36602553, 25.02846835, 12.69494276, 13.46151365, 38.47824144,\n",
       "          12.97985716, 10.26197391, 19.53798599, 16.70283677,  7.29534668,\n",
       "          43.03440179,  6.73930922,  6.56692191, 38.72632584,  4.51128355]),\n",
       "   'mean_score_time': array([0.03533518, 0.03268301, 0.03729734, 0.03405292, 0.03709209,\n",
       "          0.03590744, 0.04139023, 0.03915467, 0.03470774, 0.03165162,\n",
       "          0.04252381, 0.04596295, 0.03677521, 0.03327138, 0.04365799,\n",
       "          0.0398936 , 0.03541839, 0.04235036, 0.04653356, 0.05136418,\n",
       "          0.03883228, 0.0454102 , 0.04095502, 0.03793066, 0.03605866,\n",
       "          0.03812068, 0.03983452, 0.04010246, 0.03595169, 0.05137851,\n",
       "          0.06592762, 0.03691862, 0.03615496, 0.04034197, 0.03570771,\n",
       "          0.03560748, 0.03466668, 0.03018274, 0.03271408, 0.03347189,\n",
       "          0.03997784, 0.03279221, 0.04475663, 0.03519976, 0.04301028,\n",
       "          0.03600621, 0.04682643, 0.07108891, 0.03339169, 0.0366941 ,\n",
       "          0.03568318, 0.03357794, 0.03564231, 0.03841038, 0.06740382,\n",
       "          0.05834558, 0.04244478, 0.05918469, 0.02964382, 0.04569087,\n",
       "          0.04687557, 0.04850762, 0.03410814, 0.03413298, 0.03778634,\n",
       "          0.03949966, 0.03792865, 0.04658172, 0.04069171, 0.04278259,\n",
       "          0.04596338, 0.04047866, 0.03604605, 0.04539473, 0.04339752,\n",
       "          0.05565236, 0.05193911, 0.03406401, 0.04402919, 0.05644822,\n",
       "          0.05405731, 0.03477228, 0.05673475, 0.03901632, 0.04665735,\n",
       "          0.04212885, 0.04759202, 0.03901224, 0.03723061, 0.05378804,\n",
       "          0.03665886, 0.04005702, 0.04217765, 0.04204116, 0.03358338,\n",
       "          0.06901991, 0.03908129, 0.03465416, 0.05646882, 0.03105447]),\n",
       "   'std_score_time': array([0.00636475, 0.0067561 , 0.01689575, 0.0121795 , 0.02099523,\n",
       "          0.01002746, 0.01303573, 0.0157206 , 0.00776955, 0.0091738 ,\n",
       "          0.02007692, 0.01747925, 0.01413677, 0.00990938, 0.01297954,\n",
       "          0.01257763, 0.01172959, 0.00748495, 0.01048003, 0.02874664,\n",
       "          0.00781816, 0.01376282, 0.00662802, 0.00797643, 0.00420996,\n",
       "          0.01665387, 0.01421189, 0.01095235, 0.00590641, 0.0132593 ,\n",
       "          0.01468118, 0.01047982, 0.01033349, 0.01451924, 0.00921346,\n",
       "          0.00869723, 0.01155544, 0.00672752, 0.00666803, 0.00818763,\n",
       "          0.01324478, 0.00435691, 0.00798521, 0.00542321, 0.01373566,\n",
       "          0.00726545, 0.00891292, 0.01758431, 0.00726446, 0.0113101 ,\n",
       "          0.00673755, 0.00866587, 0.01071828, 0.0081714 , 0.01092636,\n",
       "          0.01124234, 0.0130864 , 0.0260203 , 0.00794481, 0.0216301 ,\n",
       "          0.01094221, 0.01039342, 0.00618282, 0.00732126, 0.00856412,\n",
       "          0.00528961, 0.01130913, 0.00703716, 0.01050249, 0.00655412,\n",
       "          0.00729216, 0.0055436 , 0.00753863, 0.00844927, 0.01093193,\n",
       "          0.00989489, 0.01103963, 0.00821761, 0.01871652, 0.00769387,\n",
       "          0.01650675, 0.00735596, 0.01066579, 0.01259683, 0.01249815,\n",
       "          0.00673894, 0.00490333, 0.00873461, 0.00408211, 0.00803765,\n",
       "          0.00577861, 0.01265816, 0.00531411, 0.00688513, 0.00779894,\n",
       "          0.02141081, 0.01099222, 0.00915223, 0.00742277, 0.00792427]),\n",
       "   'param_colsample_bytree': masked_array(data=[0.7654820824760737, 0.629185830986374,\n",
       "                      0.7643458710377254, 0.5737099059755859,\n",
       "                      0.6162570141151325, 0.9190831912766004,\n",
       "                      0.9835656124421499, 0.7552445232092422,\n",
       "                      0.546027248452608, 0.6847684887002612,\n",
       "                      0.6248983795264257, 1.0, 1.0, 0.7024028689196159,\n",
       "                      0.9580779499900448, 0.532301642920509,\n",
       "                      0.7998457399353642, 0.6018562194460246,\n",
       "                      0.821216420677032, 1.0, 0.8719791149698666,\n",
       "                      0.8834832536334787, 0.5, 0.9227002485231555,\n",
       "                      0.5044223523457106, 0.6216098182147348,\n",
       "                      0.9334313853154087, 0.7645122553009609,\n",
       "                      0.9941374254708888, 0.7676684266733903,\n",
       "                      0.8510764645021511, 0.5, 1.0, 0.5, 0.5,\n",
       "                      0.8468356807858183, 0.6662707806144759,\n",
       "                      0.5387901661080742, 0.7261922556389625,\n",
       "                      0.6153133290265459, 0.9283674863535822,\n",
       "                      0.5592465499551023, 0.9081257889168415, 0.5,\n",
       "                      0.7442537037828286, 0.5869641908274794,\n",
       "                      0.5489568143318961, 0.8480840051155694, 0.5,\n",
       "                      0.5059533191056128, 0.5101716002565101, 0.5,\n",
       "                      0.5647819148591594, 0.8146164385552804,\n",
       "                      0.6515990148415696, 0.7684844753422588,\n",
       "                      0.6886279043070598, 1.0, 0.519516477463954, 1.0, 0.5,\n",
       "                      0.5, 0.5985608057023988, 1.0, 0.5, 0.5,\n",
       "                      0.9600622822866933, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                      1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5159252062365536,\n",
       "                      0.5, 0.5873187246538628, 0.7421579527323023, 0.5, 0.5,\n",
       "                      0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5,\n",
       "                      0.5, 0.5],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_gamma': masked_array(data=[3.380397544384568, 4.894518292131808,\n",
       "                      0.28948921846765124, 3.916331353364969,\n",
       "                      1.216679677341995, 4.956120269464493,\n",
       "                      3.782764530210248, 2.6348951565750927,\n",
       "                      4.480863089293394, 2.200918168694508,\n",
       "                      3.7554357451815545, 3.567355203681986, 5.0,\n",
       "                      2.733273202122988, 4.027998727981891,\n",
       "                      0.9146954091320808, 0.8906098600653446,\n",
       "                      0.51255187136786, 4.020262148977595, 4.016217632714372,\n",
       "                      0.731287910212365, 3.828659791444338, 0.0,\n",
       "                      0.2728128414122597, 4.8993113038390685,\n",
       "                      2.167267368404788, 2.0187662194072287,\n",
       "                      0.8076518508683023, 4.755974945403515,\n",
       "                      0.9050076115524431, 0.0, 5.0, 0.0, 0.0, 0.0,\n",
       "                      2.293556407488239, 4.541127158787354,\n",
       "                      1.7760651031079373, 0.2077405523151894, 0.0,\n",
       "                      0.19940530149828492, 2.6018137209649868,\n",
       "                      4.170408628685219, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                      0.8326045851791686, 2.4174031224755654,\n",
       "                      1.1998709870795947, 0.394713295426119,\n",
       "                      0.7115113989530677, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                      0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                      0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_learning_rate': masked_array(data=[0.08314149149079444, 0.21972204394324293,\n",
       "                      0.032032745103304144, 0.049449776216282514,\n",
       "                      0.1190177982450834, 0.12115201170479983,\n",
       "                      0.04271271661426047, 0.11645353510171558,\n",
       "                      0.1486172413028015, 0.024356781908842783,\n",
       "                      0.29999999999999993, 0.04550768854251907,\n",
       "                      0.2386334708151223, 0.044952909957022336,\n",
       "                      0.019223290049456995, 0.09520693560993969,\n",
       "                      0.29999999999999993, 0.01, 0.01, 0.29999999999999993,\n",
       "                      0.08318398956261255, 0.01, 0.01, 0.1245067134299779,\n",
       "                      0.011510896683632086, 0.29999999999999993,\n",
       "                      0.29999999999999993, 0.01, 0.29999999999999993,\n",
       "                      0.012218439735878934, 0.29999999999999993,\n",
       "                      0.29999999999999993, 0.29999999999999993,\n",
       "                      0.29999999999999993, 0.01, 0.29999999999999993,\n",
       "                      0.29999999999999993, 0.12022465559066689,\n",
       "                      0.01000007798439082, 0.06622527533700699,\n",
       "                      0.030594481935516196, 0.055804889938853894,\n",
       "                      0.02288240584073935, 0.08389458254347083,\n",
       "                      0.03626687679803249, 0.015513397394683475,\n",
       "                      0.29999999999999993, 0.02519127641991046,\n",
       "                      0.29999999999999993, 0.06914582136689408,\n",
       "                      0.0652458337071177, 0.29999999999999993, 0.01,\n",
       "                      0.04683900701714945, 0.0296868601030192,\n",
       "                      0.026926254776763425, 0.056743810947979395,\n",
       "                      0.03324440066688052, 0.05886341841485722,\n",
       "                      0.060030242727782464, 0.01562177480593145, 0.01,\n",
       "                      0.11488730937531293, 0.03406044129233066,\n",
       "                      0.034892014379708854, 0.15321617238869373,\n",
       "                      0.012873551176869637, 0.026294641811445328,\n",
       "                      0.019647767237997965, 0.09000963986893498,\n",
       "                      0.29999999999999993, 0.05467325952566454,\n",
       "                      0.06639096025960842, 0.03348332360367818, 0.01,\n",
       "                      0.07685015416722239, 0.08733664504280685,\n",
       "                      0.03130071411500934, 0.10281775609825086,\n",
       "                      0.014767272782432872, 0.01, 0.031848665640132785,\n",
       "                      0.02358771695923188, 0.08871479408533041,\n",
       "                      0.023643254050668732, 0.022167041096454353,\n",
       "                      0.029920478447920885, 0.05647026972241418,\n",
       "                      0.022467177420443032, 0.039931056722452875,\n",
       "                      0.0473212644109228, 0.050107716228528415,\n",
       "                      0.033611143094103076, 0.017806797070513594,\n",
       "                      0.06689943603065518, 0.29999999999999993,\n",
       "                      0.29999999999999993, 0.11244895891098222,\n",
       "                      0.1504023217453543, 0.14721034498597618],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_depth': masked_array(data=[14, 13, 6, 11, 8, 11, 6, 3, 19, 17, 3, 12, 8, 3, 20, 3,\n",
       "                      3, 18, 16, 3, 18, 20, 20, 5, 19, 5, 5, 7, 17, 9, 20, 3,\n",
       "                      3, 3, 3, 3, 20, 9, 8, 8, 3, 20, 8, 20, 3, 8, 19, 20,\n",
       "                      20, 3, 20, 18, 3, 20, 20, 20, 10, 8, 8, 8, 12, 13, 20,\n",
       "                      7, 13, 13, 7, 14, 11, 10, 13, 20, 7, 11, 20, 16, 20,\n",
       "                      11, 3, 20, 11, 9, 18, 6, 11, 8, 16, 15, 8, 20, 7, 7,\n",
       "                      17, 9, 11, 14, 9, 15, 20, 3],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_n_estimators': masked_array(data=[345, 112, 104, 329, 81, 140, 103, 31, 185, 37, 90, 87,\n",
       "                      97, 76, 142, 400, 10, 368, 272, 370, 314, 400, 336,\n",
       "                      225, 226, 272, 317, 356, 232, 400, 372, 400, 136, 148,\n",
       "                      325, 196, 337, 215, 48, 111, 184, 259, 372, 94, 334,\n",
       "                      156, 166, 343, 61, 256, 228, 105, 385, 400, 400, 271,\n",
       "                      168, 236, 153, 151, 367, 400, 291, 225, 245, 281, 251,\n",
       "                      383, 307, 400, 400, 171, 329, 400, 109, 400, 129, 182,\n",
       "                      315, 400, 337, 249, 400, 270, 221, 400, 312, 155, 330,\n",
       "                      356, 400, 287, 219, 376, 120, 400, 167, 77, 400, 317],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_subsample': masked_array(data=[0.9902781313389692, 0.5813912477081276,\n",
       "                      0.6710635126567753, 0.8393610388527711,\n",
       "                      0.626801819113796, 0.6397934660675846,\n",
       "                      0.9282721006972143, 0.6201158574566924,\n",
       "                      0.7713544246339749, 0.871504897201705,\n",
       "                      0.8108230647840885, 0.8791434048370397, 1.0,\n",
       "                      0.8029162865268284, 1.0, 0.5393754285987584,\n",
       "                      0.5946254911598118, 0.5, 0.5073839733147059, 1.0,\n",
       "                      0.5619661300239687, 0.5048440801298613, 0.5,\n",
       "                      0.9660406531331696, 0.8472749811469577,\n",
       "                      0.7985007400365046, 0.5165613634412606,\n",
       "                      0.9467611062420427, 0.5755600283372945,\n",
       "                      0.9262641118671824, 0.5, 1.0, 0.5, 1.0,\n",
       "                      0.9334157102489788, 0.5060678130526741, 0.5,\n",
       "                      0.6297569333718962, 0.9560483328980955, 0.5, 0.5, 0.5,\n",
       "                      1.0, 0.5, 0.7143563890337498, 0.5717886203749474,\n",
       "                      0.5101580045257214, 0.5, 0.5, 0.5, 0.5,\n",
       "                      0.5146783736382263, 0.5, 1.0, 0.7174351823293252,\n",
       "                      0.7603077374397443, 0.6059627496121367, 0.5, 0.5, 0.5,\n",
       "                      0.5, 0.5, 0.5596383442923231, 0.7947463914738461, 0.5,\n",
       "                      0.5, 1.0, 0.5193076618041744, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                      0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5, 0.5, 0.5,\n",
       "                      0.5, 0.5, 0.5, 0.5, 0.5, 0.8359597413057825, 1.0, 1.0,\n",
       "                      0.5, 1.0, 0.5, 0.5971346909486269, 0.883163277718696,\n",
       "                      0.5, 0.5, 1.0],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [OrderedDict([('colsample_bytree', 0.7654820824760737),\n",
       "                 ('gamma', 3.380397544384568),\n",
       "                 ('learning_rate', 0.08314149149079444),\n",
       "                 ('max_depth', 14),\n",
       "                 ('n_estimators', 345),\n",
       "                 ('subsample', 0.9902781313389692)]),\n",
       "    OrderedDict([('colsample_bytree', 0.629185830986374),\n",
       "                 ('gamma', 4.894518292131808),\n",
       "                 ('learning_rate', 0.21972204394324293),\n",
       "                 ('max_depth', 13),\n",
       "                 ('n_estimators', 112),\n",
       "                 ('subsample', 0.5813912477081276)]),\n",
       "    OrderedDict([('colsample_bytree', 0.7643458710377254),\n",
       "                 ('gamma', 0.28948921846765124),\n",
       "                 ('learning_rate', 0.032032745103304144),\n",
       "                 ('max_depth', 6),\n",
       "                 ('n_estimators', 104),\n",
       "                 ('subsample', 0.6710635126567753)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5737099059755859),\n",
       "                 ('gamma', 3.916331353364969),\n",
       "                 ('learning_rate', 0.049449776216282514),\n",
       "                 ('max_depth', 11),\n",
       "                 ('n_estimators', 329),\n",
       "                 ('subsample', 0.8393610388527711)]),\n",
       "    OrderedDict([('colsample_bytree', 0.6162570141151325),\n",
       "                 ('gamma', 1.216679677341995),\n",
       "                 ('learning_rate', 0.1190177982450834),\n",
       "                 ('max_depth', 8),\n",
       "                 ('n_estimators', 81),\n",
       "                 ('subsample', 0.626801819113796)]),\n",
       "    OrderedDict([('colsample_bytree', 0.9190831912766004),\n",
       "                 ('gamma', 4.956120269464493),\n",
       "                 ('learning_rate', 0.12115201170479983),\n",
       "                 ('max_depth', 11),\n",
       "                 ('n_estimators', 140),\n",
       "                 ('subsample', 0.6397934660675846)]),\n",
       "    OrderedDict([('colsample_bytree', 0.9835656124421499),\n",
       "                 ('gamma', 3.782764530210248),\n",
       "                 ('learning_rate', 0.04271271661426047),\n",
       "                 ('max_depth', 6),\n",
       "                 ('n_estimators', 103),\n",
       "                 ('subsample', 0.9282721006972143)]),\n",
       "    OrderedDict([('colsample_bytree', 0.7552445232092422),\n",
       "                 ('gamma', 2.6348951565750927),\n",
       "                 ('learning_rate', 0.11645353510171558),\n",
       "                 ('max_depth', 3),\n",
       "                 ('n_estimators', 31),\n",
       "                 ('subsample', 0.6201158574566924)]),\n",
       "    OrderedDict([('colsample_bytree', 0.546027248452608),\n",
       "                 ('gamma', 4.480863089293394),\n",
       "                 ('learning_rate', 0.1486172413028015),\n",
       "                 ('max_depth', 19),\n",
       "                 ('n_estimators', 185),\n",
       "                 ('subsample', 0.7713544246339749)]),\n",
       "    OrderedDict([('colsample_bytree', 0.6847684887002612),\n",
       "                 ('gamma', 2.200918168694508),\n",
       "                 ('learning_rate', 0.024356781908842783),\n",
       "                 ('max_depth', 17),\n",
       "                 ('n_estimators', 37),\n",
       "                 ('subsample', 0.871504897201705)]),\n",
       "    OrderedDict([('colsample_bytree', 0.6248983795264257),\n",
       "                 ('gamma', 3.7554357451815545),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 3),\n",
       "                 ('n_estimators', 90),\n",
       "                 ('subsample', 0.8108230647840885)]),\n",
       "    OrderedDict([('colsample_bytree', 1.0),\n",
       "                 ('gamma', 3.567355203681986),\n",
       "                 ('learning_rate', 0.04550768854251907),\n",
       "                 ('max_depth', 12),\n",
       "                 ('n_estimators', 87),\n",
       "                 ('subsample', 0.8791434048370397)]),\n",
       "    OrderedDict([('colsample_bytree', 1.0),\n",
       "                 ('gamma', 5.0),\n",
       "                 ('learning_rate', 0.2386334708151223),\n",
       "                 ('max_depth', 8),\n",
       "                 ('n_estimators', 97),\n",
       "                 ('subsample', 1.0)]),\n",
       "    OrderedDict([('colsample_bytree', 0.7024028689196159),\n",
       "                 ('gamma', 2.733273202122988),\n",
       "                 ('learning_rate', 0.044952909957022336),\n",
       "                 ('max_depth', 3),\n",
       "                 ('n_estimators', 76),\n",
       "                 ('subsample', 0.8029162865268284)]),\n",
       "    OrderedDict([('colsample_bytree', 0.9580779499900448),\n",
       "                 ('gamma', 4.027998727981891),\n",
       "                 ('learning_rate', 0.019223290049456995),\n",
       "                 ('max_depth', 20),\n",
       "                 ('n_estimators', 142),\n",
       "                 ('subsample', 1.0)]),\n",
       "    OrderedDict([('colsample_bytree', 0.532301642920509),\n",
       "                 ('gamma', 0.9146954091320808),\n",
       "                 ('learning_rate', 0.09520693560993969),\n",
       "                 ('max_depth', 3),\n",
       "                 ('n_estimators', 400),\n",
       "                 ('subsample', 0.5393754285987584)]),\n",
       "    OrderedDict([('colsample_bytree', 0.7998457399353642),\n",
       "                 ('gamma', 0.8906098600653446),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 3),\n",
       "                 ('n_estimators', 10),\n",
       "                 ('subsample', 0.5946254911598118)]),\n",
       "    OrderedDict([('colsample_bytree', 0.6018562194460246),\n",
       "                 ('gamma', 0.51255187136786),\n",
       "                 ('learning_rate', 0.01),\n",
       "                 ('max_depth', 18),\n",
       "                 ('n_estimators', 368),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.821216420677032),\n",
       "                 ('gamma', 4.020262148977595),\n",
       "                 ('learning_rate', 0.01),\n",
       "                 ('max_depth', 16),\n",
       "                 ('n_estimators', 272),\n",
       "                 ('subsample', 0.5073839733147059)]),\n",
       "    OrderedDict([('colsample_bytree', 1.0),\n",
       "                 ('gamma', 4.016217632714372),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 3),\n",
       "                 ('n_estimators', 370),\n",
       "                 ('subsample', 1.0)]),\n",
       "    OrderedDict([('colsample_bytree', 0.8719791149698666),\n",
       "                 ('gamma', 0.731287910212365),\n",
       "                 ('learning_rate', 0.08318398956261255),\n",
       "                 ('max_depth', 18),\n",
       "                 ('n_estimators', 314),\n",
       "                 ('subsample', 0.5619661300239687)]),\n",
       "    OrderedDict([('colsample_bytree', 0.8834832536334787),\n",
       "                 ('gamma', 3.828659791444338),\n",
       "                 ('learning_rate', 0.01),\n",
       "                 ('max_depth', 20),\n",
       "                 ('n_estimators', 400),\n",
       "                 ('subsample', 0.5048440801298613)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.01),\n",
       "                 ('max_depth', 20),\n",
       "                 ('n_estimators', 336),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.9227002485231555),\n",
       "                 ('gamma', 0.2728128414122597),\n",
       "                 ('learning_rate', 0.1245067134299779),\n",
       "                 ('max_depth', 5),\n",
       "                 ('n_estimators', 225),\n",
       "                 ('subsample', 0.9660406531331696)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5044223523457106),\n",
       "                 ('gamma', 4.8993113038390685),\n",
       "                 ('learning_rate', 0.011510896683632086),\n",
       "                 ('max_depth', 19),\n",
       "                 ('n_estimators', 226),\n",
       "                 ('subsample', 0.8472749811469577)]),\n",
       "    OrderedDict([('colsample_bytree', 0.6216098182147348),\n",
       "                 ('gamma', 2.167267368404788),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 5),\n",
       "                 ('n_estimators', 272),\n",
       "                 ('subsample', 0.7985007400365046)]),\n",
       "    OrderedDict([('colsample_bytree', 0.9334313853154087),\n",
       "                 ('gamma', 2.0187662194072287),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 5),\n",
       "                 ('n_estimators', 317),\n",
       "                 ('subsample', 0.5165613634412606)]),\n",
       "    OrderedDict([('colsample_bytree', 0.7645122553009609),\n",
       "                 ('gamma', 0.8076518508683023),\n",
       "                 ('learning_rate', 0.01),\n",
       "                 ('max_depth', 7),\n",
       "                 ('n_estimators', 356),\n",
       "                 ('subsample', 0.9467611062420427)]),\n",
       "    OrderedDict([('colsample_bytree', 0.9941374254708888),\n",
       "                 ('gamma', 4.755974945403515),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 17),\n",
       "                 ('n_estimators', 232),\n",
       "                 ('subsample', 0.5755600283372945)]),\n",
       "    OrderedDict([('colsample_bytree', 0.7676684266733903),\n",
       "                 ('gamma', 0.9050076115524431),\n",
       "                 ('learning_rate', 0.012218439735878934),\n",
       "                 ('max_depth', 9),\n",
       "                 ('n_estimators', 400),\n",
       "                 ('subsample', 0.9262641118671824)]),\n",
       "    OrderedDict([('colsample_bytree', 0.8510764645021511),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 20),\n",
       "                 ('n_estimators', 372),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 5.0),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 3),\n",
       "                 ('n_estimators', 400),\n",
       "                 ('subsample', 1.0)]),\n",
       "    OrderedDict([('colsample_bytree', 1.0),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 3),\n",
       "                 ('n_estimators', 136),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 3),\n",
       "                 ('n_estimators', 148),\n",
       "                 ('subsample', 1.0)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.01),\n",
       "                 ('max_depth', 3),\n",
       "                 ('n_estimators', 325),\n",
       "                 ('subsample', 0.9334157102489788)]),\n",
       "    OrderedDict([('colsample_bytree', 0.8468356807858183),\n",
       "                 ('gamma', 2.293556407488239),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 3),\n",
       "                 ('n_estimators', 196),\n",
       "                 ('subsample', 0.5060678130526741)]),\n",
       "    OrderedDict([('colsample_bytree', 0.6662707806144759),\n",
       "                 ('gamma', 4.541127158787354),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 20),\n",
       "                 ('n_estimators', 337),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5387901661080742),\n",
       "                 ('gamma', 1.7760651031079373),\n",
       "                 ('learning_rate', 0.12022465559066689),\n",
       "                 ('max_depth', 9),\n",
       "                 ('n_estimators', 215),\n",
       "                 ('subsample', 0.6297569333718962)]),\n",
       "    OrderedDict([('colsample_bytree', 0.7261922556389625),\n",
       "                 ('gamma', 0.2077405523151894),\n",
       "                 ('learning_rate', 0.01000007798439082),\n",
       "                 ('max_depth', 8),\n",
       "                 ('n_estimators', 48),\n",
       "                 ('subsample', 0.9560483328980955)]),\n",
       "    OrderedDict([('colsample_bytree', 0.6153133290265459),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.06622527533700699),\n",
       "                 ('max_depth', 8),\n",
       "                 ('n_estimators', 111),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.9283674863535822),\n",
       "                 ('gamma', 0.19940530149828492),\n",
       "                 ('learning_rate', 0.030594481935516196),\n",
       "                 ('max_depth', 3),\n",
       "                 ('n_estimators', 184),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5592465499551023),\n",
       "                 ('gamma', 2.6018137209649868),\n",
       "                 ('learning_rate', 0.055804889938853894),\n",
       "                 ('max_depth', 20),\n",
       "                 ('n_estimators', 259),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.9081257889168415),\n",
       "                 ('gamma', 4.170408628685219),\n",
       "                 ('learning_rate', 0.02288240584073935),\n",
       "                 ('max_depth', 8),\n",
       "                 ('n_estimators', 372),\n",
       "                 ('subsample', 1.0)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.08389458254347083),\n",
       "                 ('max_depth', 20),\n",
       "                 ('n_estimators', 94),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.7442537037828286),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.03626687679803249),\n",
       "                 ('max_depth', 3),\n",
       "                 ('n_estimators', 334),\n",
       "                 ('subsample', 0.7143563890337498)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5869641908274794),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.015513397394683475),\n",
       "                 ('max_depth', 8),\n",
       "                 ('n_estimators', 156),\n",
       "                 ('subsample', 0.5717886203749474)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5489568143318961),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 19),\n",
       "                 ('n_estimators', 166),\n",
       "                 ('subsample', 0.5101580045257214)]),\n",
       "    OrderedDict([('colsample_bytree', 0.8480840051155694),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.02519127641991046),\n",
       "                 ('max_depth', 20),\n",
       "                 ('n_estimators', 343),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 20),\n",
       "                 ('n_estimators', 61),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5059533191056128),\n",
       "                 ('gamma', 0.8326045851791686),\n",
       "                 ('learning_rate', 0.06914582136689408),\n",
       "                 ('max_depth', 3),\n",
       "                 ('n_estimators', 256),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5101716002565101),\n",
       "                 ('gamma', 2.4174031224755654),\n",
       "                 ('learning_rate', 0.0652458337071177),\n",
       "                 ('max_depth', 20),\n",
       "                 ('n_estimators', 228),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 1.1998709870795947),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 18),\n",
       "                 ('n_estimators', 105),\n",
       "                 ('subsample', 0.5146783736382263)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5647819148591594),\n",
       "                 ('gamma', 0.394713295426119),\n",
       "                 ('learning_rate', 0.01),\n",
       "                 ('max_depth', 3),\n",
       "                 ('n_estimators', 385),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.8146164385552804),\n",
       "                 ('gamma', 0.7115113989530677),\n",
       "                 ('learning_rate', 0.04683900701714945),\n",
       "                 ('max_depth', 20),\n",
       "                 ('n_estimators', 400),\n",
       "                 ('subsample', 1.0)]),\n",
       "    OrderedDict([('colsample_bytree', 0.6515990148415696),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.0296868601030192),\n",
       "                 ('max_depth', 20),\n",
       "                 ('n_estimators', 400),\n",
       "                 ('subsample', 0.7174351823293252)]),\n",
       "    OrderedDict([('colsample_bytree', 0.7684844753422588),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.026926254776763425),\n",
       "                 ('max_depth', 20),\n",
       "                 ('n_estimators', 271),\n",
       "                 ('subsample', 0.7603077374397443)]),\n",
       "    OrderedDict([('colsample_bytree', 0.6886279043070598),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.056743810947979395),\n",
       "                 ('max_depth', 10),\n",
       "                 ('n_estimators', 168),\n",
       "                 ('subsample', 0.6059627496121367)]),\n",
       "    OrderedDict([('colsample_bytree', 1.0),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.03324440066688052),\n",
       "                 ('max_depth', 8),\n",
       "                 ('n_estimators', 236),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.519516477463954),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.05886341841485722),\n",
       "                 ('max_depth', 8),\n",
       "                 ('n_estimators', 153),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 1.0),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.060030242727782464),\n",
       "                 ('max_depth', 8),\n",
       "                 ('n_estimators', 151),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.01562177480593145),\n",
       "                 ('max_depth', 12),\n",
       "                 ('n_estimators', 367),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.01),\n",
       "                 ('max_depth', 13),\n",
       "                 ('n_estimators', 400),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5985608057023988),\n",
       "                 ('gamma', 5.0),\n",
       "                 ('learning_rate', 0.11488730937531293),\n",
       "                 ('max_depth', 20),\n",
       "                 ('n_estimators', 291),\n",
       "                 ('subsample', 0.5596383442923231)]),\n",
       "    OrderedDict([('colsample_bytree', 1.0),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.03406044129233066),\n",
       "                 ('max_depth', 7),\n",
       "                 ('n_estimators', 225),\n",
       "                 ('subsample', 0.7947463914738461)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.034892014379708854),\n",
       "                 ('max_depth', 13),\n",
       "                 ('n_estimators', 245),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.15321617238869373),\n",
       "                 ('max_depth', 13),\n",
       "                 ('n_estimators', 281),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.9600622822866933),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.012873551176869637),\n",
       "                 ('max_depth', 7),\n",
       "                 ('n_estimators', 251),\n",
       "                 ('subsample', 1.0)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.026294641811445328),\n",
       "                 ('max_depth', 14),\n",
       "                 ('n_estimators', 383),\n",
       "                 ('subsample', 0.5193076618041744)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.019647767237997965),\n",
       "                 ('max_depth', 11),\n",
       "                 ('n_estimators', 307),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.09000963986893498),\n",
       "                 ('max_depth', 10),\n",
       "                 ('n_estimators', 400),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 13),\n",
       "                 ('n_estimators', 400),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.05467325952566454),\n",
       "                 ('max_depth', 20),\n",
       "                 ('n_estimators', 171),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.06639096025960842),\n",
       "                 ('max_depth', 7),\n",
       "                 ('n_estimators', 329),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.03348332360367818),\n",
       "                 ('max_depth', 11),\n",
       "                 ('n_estimators', 400),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 1.0),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.01),\n",
       "                 ('max_depth', 20),\n",
       "                 ('n_estimators', 109),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.07685015416722239),\n",
       "                 ('max_depth', 16),\n",
       "                 ('n_estimators', 400),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 1.0),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.08733664504280685),\n",
       "                 ('max_depth', 20),\n",
       "                 ('n_estimators', 129),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.03130071411500934),\n",
       "                 ('max_depth', 11),\n",
       "                 ('n_estimators', 182),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 1.0),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.10281775609825086),\n",
       "                 ('max_depth', 3),\n",
       "                 ('n_estimators', 315),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.014767272782432872),\n",
       "                 ('max_depth', 20),\n",
       "                 ('n_estimators', 400),\n",
       "                 ('subsample', 1.0)]),\n",
       "    OrderedDict([('colsample_bytree', 1.0),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.01),\n",
       "                 ('max_depth', 11),\n",
       "                 ('n_estimators', 337),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5159252062365536),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.031848665640132785),\n",
       "                 ('max_depth', 9),\n",
       "                 ('n_estimators', 249),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.02358771695923188),\n",
       "                 ('max_depth', 18),\n",
       "                 ('n_estimators', 400),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5873187246538628),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.08871479408533041),\n",
       "                 ('max_depth', 6),\n",
       "                 ('n_estimators', 270),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.7421579527323023),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.023643254050668732),\n",
       "                 ('max_depth', 11),\n",
       "                 ('n_estimators', 221),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.022167041096454353),\n",
       "                 ('max_depth', 8),\n",
       "                 ('n_estimators', 400),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.029920478447920885),\n",
       "                 ('max_depth', 16),\n",
       "                 ('n_estimators', 312),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.05647026972241418),\n",
       "                 ('max_depth', 15),\n",
       "                 ('n_estimators', 155),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.022467177420443032),\n",
       "                 ('max_depth', 8),\n",
       "                 ('n_estimators', 330),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.039931056722452875),\n",
       "                 ('max_depth', 20),\n",
       "                 ('n_estimators', 356),\n",
       "                 ('subsample', 0.8359597413057825)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.0473212644109228),\n",
       "                 ('max_depth', 7),\n",
       "                 ('n_estimators', 400),\n",
       "                 ('subsample', 1.0)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.050107716228528415),\n",
       "                 ('max_depth', 7),\n",
       "                 ('n_estimators', 287),\n",
       "                 ('subsample', 1.0)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.033611143094103076),\n",
       "                 ('max_depth', 17),\n",
       "                 ('n_estimators', 219),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.017806797070513594),\n",
       "                 ('max_depth', 9),\n",
       "                 ('n_estimators', 376),\n",
       "                 ('subsample', 1.0)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.06689943603065518),\n",
       "                 ('max_depth', 11),\n",
       "                 ('n_estimators', 120),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 1.0),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 14),\n",
       "                 ('n_estimators', 400),\n",
       "                 ('subsample', 0.5971346909486269)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 9),\n",
       "                 ('n_estimators', 167),\n",
       "                 ('subsample', 0.883163277718696)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.11244895891098222),\n",
       "                 ('max_depth', 15),\n",
       "                 ('n_estimators', 77),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.1504023217453543),\n",
       "                 ('max_depth', 20),\n",
       "                 ('n_estimators', 400),\n",
       "                 ('subsample', 0.5)]),\n",
       "    OrderedDict([('colsample_bytree', 0.5),\n",
       "                 ('gamma', 0.0),\n",
       "                 ('learning_rate', 0.14721034498597618),\n",
       "                 ('max_depth', 3),\n",
       "                 ('n_estimators', 317),\n",
       "                 ('subsample', 1.0)])],\n",
       "   'split0_test_score': array([-0.38426476, -0.37793956, -0.39575276, -0.37072595, -0.36913058,\n",
       "          -0.38811514, -0.37096107, -0.46430027, -0.38152331, -0.48772555,\n",
       "          -0.36198609, -0.38169978, -0.41271021, -0.4742391 , -0.39879208,\n",
       "          -0.34427988, -0.46599967, -0.36807681, -0.3967407 , -0.39744985,\n",
       "          -0.38004304, -0.38964527, -0.36534227, -0.36839483, -0.39111045,\n",
       "          -0.36170255, -0.38167296, -0.3830632 , -0.39383613, -0.37502869,\n",
       "          -0.36644645, -0.37273756, -0.36510258, -0.36909091, -0.49048122,\n",
       "          -0.3518785 , -0.40314936, -0.35949187, -0.59693779, -0.3657152 ,\n",
       "          -0.42660988, -0.37456961, -0.3769044 , -0.37834926, -0.39905288,\n",
       "          -0.39314955, -0.40430583, -0.36345187, -0.40488916, -0.37383472,\n",
       "          -0.38267459, -0.39752778, -0.47034217, -0.37484308, -0.34882702,\n",
       "          -0.35662385, -0.36920237, -0.34988415, -0.37407473, -0.36026464,\n",
       "          -0.34793901, -0.3573322 , -0.38224039, -0.35988026, -0.36196895,\n",
       "          -0.38220606, -0.38157316, -0.34809254, -0.35034745, -0.36479607,\n",
       "          -0.38940132, -0.37669651, -0.37192872, -0.35537833, -0.454528  ,\n",
       "          -0.37008688, -0.36908886, -0.36514488, -0.36069025, -0.3467532 ,\n",
       "          -0.37147403, -0.3618778 , -0.35161317, -0.3789799 , -0.36584383,\n",
       "          -0.3499886 , -0.34925521, -0.37069436, -0.35254378, -0.354161  ,\n",
       "          -0.34256434, -0.3355497 , -0.36201519, -0.34331676, -0.36068666,\n",
       "          -0.39845013, -0.37852235, -0.37599204, -0.39012973, -0.34772835]),\n",
       "   'split1_test_score': array([-0.47880406, -0.43082374, -0.39994663, -0.40285576, -0.40337027,\n",
       "          -0.46732055, -0.40791983, -0.46795549, -0.45399691, -0.51762867,\n",
       "          -0.36619014, -0.50109166, -0.49270131, -0.45688643, -0.48963023,\n",
       "          -0.36028913, -0.49068229, -0.38439166, -0.44494287, -0.36741735,\n",
       "          -0.47130456, -0.43978311, -0.37743338, -0.38713165, -0.40524859,\n",
       "          -0.37331209, -0.4517731 , -0.41607166, -0.46990516, -0.43606561,\n",
       "          -0.49437239, -0.3912504 , -0.34888852, -0.39662673, -0.46015865,\n",
       "          -0.34725759, -0.42500392, -0.43050645, -0.60204491, -0.35310963,\n",
       "          -0.41863389, -0.38661467, -0.45807451, -0.37949548, -0.37580489,\n",
       "          -0.40212842, -0.46124282, -0.45869887, -0.45259052, -0.38290311,\n",
       "          -0.36770438, -0.45193371, -0.44494186, -0.47318672, -0.39796381,\n",
       "          -0.44435205, -0.40306113, -0.43508495, -0.36755334, -0.4306749 ,\n",
       "          -0.36345822, -0.37559425, -0.38530266, -0.43021447, -0.3530424 ,\n",
       "          -0.43110594, -0.43091558, -0.35782247, -0.36154502, -0.37761805,\n",
       "          -0.45481658, -0.35847821, -0.36432177, -0.35225521, -0.53584526,\n",
       "          -0.37737153, -0.5118235 , -0.35777063, -0.35942907, -0.38279925,\n",
       "          -0.49463615, -0.35916769, -0.3601799 , -0.36099626, -0.41275811,\n",
       "          -0.36081341, -0.36073584, -0.36103382, -0.36390258, -0.37168607,\n",
       "          -0.3880379 , -0.4011856 , -0.34752869, -0.39074258, -0.36674359,\n",
       "          -0.53011113, -0.46511793, -0.41103594, -0.43326164, -0.35981682]),\n",
       "   'split2_test_score': array([-0.2902115 , -0.29859083, -0.30772946, -0.2727564 , -0.2726961 ,\n",
       "          -0.2941964 , -0.29899127, -0.3947041 , -0.28303196, -0.49103836,\n",
       "          -0.3584473 , -0.30959502, -0.31074805, -0.4049917 , -0.33194753,\n",
       "          -0.31604716, -0.42351658, -0.28348915, -0.31513146, -0.33420078,\n",
       "          -0.25722883, -0.29487836, -0.28650456, -0.29446317, -0.34136677,\n",
       "          -0.3092248 , -0.31111407, -0.29128851, -0.29963587, -0.28281898,\n",
       "          -0.32494575, -0.34091195, -0.29822551, -0.3105596 , -0.41570111,\n",
       "          -0.32631402, -0.33607887, -0.26949934, -0.62801733, -0.25011335,\n",
       "          -0.36384451, -0.27438466, -0.28865485, -0.26484017, -0.33222472,\n",
       "          -0.33132305, -0.28238933, -0.26768253, -0.32616232, -0.32431819,\n",
       "          -0.27626831, -0.26433926, -0.39337708, -0.28070117, -0.2619011 ,\n",
       "          -0.26321718, -0.27251865, -0.25219883, -0.27011572, -0.25667705,\n",
       "          -0.26642594, -0.2786395 , -0.30359929, -0.26878801, -0.25892624,\n",
       "          -0.30538622, -0.29243819, -0.26141501, -0.26560227, -0.28639899,\n",
       "          -0.28753999, -0.25969733, -0.25346279, -0.26393284, -0.42661368,\n",
       "          -0.25624345, -0.2726069 , -0.27009256, -0.28609204, -0.25486075,\n",
       "          -0.28042649, -0.26372485, -0.25681985, -0.26696846, -0.26502116,\n",
       "          -0.26110627, -0.26167468, -0.26118278, -0.26452906, -0.26656456,\n",
       "          -0.25332457, -0.2436961 , -0.26392144, -0.26469635, -0.25713013,\n",
       "          -0.3008122 , -0.34495801, -0.26923376, -0.3084222 , -0.30134522]),\n",
       "   'split3_test_score': array([-0.29699091, -0.32422191, -0.3180807 , -0.33378144, -0.30763616,\n",
       "          -0.32009124, -0.30746346, -0.39840078, -0.35192661, -0.45255046,\n",
       "          -0.37117905, -0.32911862, -0.34674885, -0.41526057, -0.33594584,\n",
       "          -0.367535  , -0.43996436, -0.30047135, -0.3220312 , -0.34761098,\n",
       "          -0.29084466, -0.31095804, -0.29694259, -0.30918054, -0.3428024 ,\n",
       "          -0.31153428, -0.35267578, -0.30631507, -0.31651466, -0.29745819,\n",
       "          -0.28896286, -0.37180364, -0.31646431, -0.34056759, -0.41775994,\n",
       "          -0.34779892, -0.34342531, -0.32215145, -0.57558899, -0.2909862 ,\n",
       "          -0.38465706, -0.32695297, -0.32082449, -0.31376659, -0.34435356,\n",
       "          -0.3396064 , -0.37041606, -0.27526757, -0.3817083 , -0.34636386,\n",
       "          -0.32606082, -0.36824501, -0.40154571, -0.29414593, -0.28869181,\n",
       "          -0.27081455, -0.28970011, -0.29980458, -0.30972756, -0.28889073,\n",
       "          -0.28485562, -0.29148555, -0.34772127, -0.31375158, -0.2918625 ,\n",
       "          -0.334409  , -0.31242189, -0.2823351 , -0.28386655, -0.29575439,\n",
       "          -0.34839159, -0.29459497, -0.30540809, -0.2923897 , -0.40256457,\n",
       "          -0.3092868 , -0.30329823, -0.29600741, -0.32858015, -0.28651907,\n",
       "          -0.30100745, -0.30336112, -0.28181034, -0.30691613, -0.28890985,\n",
       "          -0.29500205, -0.28910289, -0.30267711, -0.2978174 , -0.28465625,\n",
       "          -0.28579191, -0.28325634, -0.28948963, -0.29549586, -0.29865024,\n",
       "          -0.31977844, -0.33155107, -0.33391622, -0.34121208, -0.35366373]),\n",
       "   'split4_test_score': array([-0.37865986, -0.41844666, -0.39049088, -0.39551653, -0.38932306,\n",
       "          -0.3925986 , -0.35868673, -0.49471537, -0.38757374, -0.58848476,\n",
       "          -0.41807017, -0.3981302 , -0.40660577, -0.50459585, -0.42823691,\n",
       "          -0.38360629, -0.48931814, -0.39922928, -0.41921016, -0.36904033,\n",
       "          -0.34706565, -0.39124894, -0.40641558, -0.33533556, -0.44642232,\n",
       "          -0.33952342, -0.36386241, -0.38731964, -0.36544795, -0.38040853,\n",
       "          -0.34801037, -0.39847818, -0.36139027, -0.35796791, -0.52062335,\n",
       "          -0.36541504, -0.39480628, -0.35179313, -0.70324772, -0.37313451,\n",
       "          -0.42324622, -0.37198902, -0.38581776, -0.39571394, -0.38390996,\n",
       "          -0.44121011, -0.38353279, -0.36873139, -0.40219246, -0.38426717,\n",
       "          -0.39508964, -0.39602009, -0.48564783, -0.37898536, -0.37045629,\n",
       "          -0.36897379, -0.36644064, -0.34113663, -0.36972059, -0.34446008,\n",
       "          -0.37579385, -0.39249798, -0.39417649, -0.35242302, -0.37633765,\n",
       "          -0.39290544, -0.39909003, -0.37975972, -0.37464273, -0.38879673,\n",
       "          -0.38075232, -0.38764588, -0.37196796, -0.37145731, -0.54932847,\n",
       "          -0.39778639, -0.38462115, -0.37316058, -0.38840672, -0.38192898,\n",
       "          -0.39058587, -0.36868152, -0.373489  , -0.3502091 , -0.37465587,\n",
       "          -0.36929298, -0.37402997, -0.38948688, -0.36963057, -0.38019071,\n",
       "          -0.38188594, -0.37632906, -0.3732186 , -0.37968   , -0.38923492,\n",
       "          -0.40519433, -0.40898221, -0.39803167, -0.38784096, -0.37747768]),\n",
       "   'split5_test_score': array([-0.3205697 , -0.34668788, -0.34039467, -0.33831703, -0.33223766,\n",
       "          -0.3348991 , -0.34001823, -0.49262553, -0.36221643, -0.55728087,\n",
       "          -0.35057544, -0.3245141 , -0.3404221 , -0.50218683, -0.34731769,\n",
       "          -0.33946698, -0.50463738, -0.33700153, -0.35902381, -0.37634735,\n",
       "          -0.31207653, -0.3372246 , -0.3446099 , -0.33398164, -0.3838837 ,\n",
       "          -0.38203112, -0.33719847, -0.3284568 , -0.3281323 , -0.32334245,\n",
       "          -0.34309743, -0.37194515, -0.345909  , -0.36129164, -0.50701042,\n",
       "          -0.34651973, -0.34569822, -0.32600097, -0.71699024, -0.3308793 ,\n",
       "          -0.42902361, -0.34771697, -0.3269416 , -0.34435855, -0.35791235,\n",
       "          -0.36819378, -0.37429821, -0.30912915, -0.35072361, -0.35062629,\n",
       "          -0.34244102, -0.3433464 , -0.47581618, -0.31545838, -0.32319884,\n",
       "          -0.30609581, -0.31555811, -0.30735953, -0.33121619, -0.31317906,\n",
       "          -0.32510081, -0.33468855, -0.34212505, -0.3189511 , -0.32586723,\n",
       "          -0.34846003, -0.33508689, -0.32329986, -0.32782891, -0.35139295,\n",
       "          -0.33020687, -0.34397615, -0.32831448, -0.32210755, -0.48064376,\n",
       "          -0.34749656, -0.30658502, -0.33069707, -0.34111729, -0.31419173,\n",
       "          -0.31855076, -0.32021632, -0.32559662, -0.32482079, -0.31393767,\n",
       "          -0.31882746, -0.32483308, -0.34581967, -0.32367178, -0.33039176,\n",
       "          -0.31081429, -0.30129688, -0.32395295, -0.30708632, -0.34022472,\n",
       "          -0.32048954, -0.35894422, -0.34940711, -0.33935416, -0.35461586]),\n",
       "   'split6_test_score': array([-0.43217722, -0.41640711, -0.45254286, -0.40208946, -0.43792812,\n",
       "          -0.46427791, -0.45807815, -0.47653163, -0.42943892, -0.57719007,\n",
       "          -0.41417082, -0.46618063, -0.42854315, -0.48423005, -0.48021008,\n",
       "          -0.42759492, -0.52011574, -0.4073136 , -0.4497739 , -0.4474472 ,\n",
       "          -0.4199428 , -0.43855871, -0.40478657, -0.40611348, -0.45094791,\n",
       "          -0.4950707 , -0.47772512, -0.44435095, -0.47565727, -0.42558161,\n",
       "          -0.44092492, -0.47079958, -0.42309508, -0.46664588, -0.49361981,\n",
       "          -0.4414831 , -0.45954079, -0.36205457, -0.67242498, -0.43035819,\n",
       "          -0.4484221 , -0.37594879, -0.45670663, -0.37461846, -0.420993  ,\n",
       "          -0.43683763, -0.39604627, -0.42929567, -0.40879287, -0.39348368,\n",
       "          -0.38905426, -0.45801578, -0.47159904, -0.42769695, -0.40900927,\n",
       "          -0.4351084 , -0.41399381, -0.4427164 , -0.36999227, -0.43470152,\n",
       "          -0.39424298, -0.39597231, -0.39052811, -0.43587937, -0.37802989,\n",
       "          -0.38773919, -0.45971903, -0.39564862, -0.38186123, -0.38217732,\n",
       "          -0.38576058, -0.37662458, -0.36781131, -0.37614204, -0.54876865,\n",
       "          -0.37161685, -0.45407745, -0.38044114, -0.40630934, -0.39770626,\n",
       "          -0.45231744, -0.37874433, -0.38401563, -0.38855158, -0.39889557,\n",
       "          -0.3955045 , -0.38051371, -0.3732872 , -0.39055957, -0.39608954,\n",
       "          -0.41266603, -0.39899554, -0.38565879, -0.39200839, -0.36316453,\n",
       "          -0.45032184, -0.47241149, -0.38086918, -0.39046272, -0.38033297]),\n",
       "   'split7_test_score': array([-0.33119563, -0.34443815, -0.35845866, -0.33995455, -0.3322978 ,\n",
       "          -0.39162212, -0.37829767, -0.42909371, -0.35500182, -0.51967086,\n",
       "          -0.37532003, -0.42543097, -0.39882898, -0.41586481, -0.4349057 ,\n",
       "          -0.3304949 , -0.44988106, -0.33719666, -0.39602308, -0.34273887,\n",
       "          -0.38307148, -0.38408567, -0.33166699, -0.36475758, -0.36857569,\n",
       "          -0.34386546, -0.37624222, -0.35889262, -0.42097253, -0.35722156,\n",
       "          -0.36758878, -0.36031382, -0.33742267, -0.3343352 , -0.43617792,\n",
       "          -0.34812799, -0.37058155, -0.34991188, -0.63537258, -0.33308083,\n",
       "          -0.37248154, -0.33456108, -0.38927429, -0.32383817, -0.34182986,\n",
       "          -0.37251512, -0.36546734, -0.37597187, -0.34528109, -0.32751598,\n",
       "          -0.31775535, -0.3614285 , -0.41020713, -0.37706008, -0.33342075,\n",
       "          -0.35383164, -0.32549166, -0.37614978, -0.32335429, -0.3735961 ,\n",
       "          -0.31948308, -0.32263537, -0.33622294, -0.37463606, -0.32119437,\n",
       "          -0.31854106, -0.39678449, -0.32059868, -0.31756886, -0.3184233 ,\n",
       "          -0.36260678, -0.32223624, -0.31706141, -0.32504939, -0.53468025,\n",
       "          -0.32167502, -0.43272586, -0.32215446, -0.33942157, -0.33044632,\n",
       "          -0.42647296, -0.31420872, -0.32659122, -0.33243875, -0.3487736 ,\n",
       "          -0.31925281, -0.32803068, -0.32386121, -0.32084139, -0.329289  ,\n",
       "          -0.33091203, -0.33783729, -0.32600856, -0.32672404, -0.31489202,\n",
       "          -0.45514475, -0.35337752, -0.3124078 , -0.31175753, -0.32777164]),\n",
       "   'split8_test_score': array([-0.19734975, -0.23196253, -0.23393451, -0.21346691, -0.19823906,\n",
       "          -0.18630998, -0.22350156, -0.37575661, -0.22000971, -0.37614022,\n",
       "          -0.26299714, -0.21320697, -0.21008247, -0.37864676, -0.23872248,\n",
       "          -0.22031984, -0.38853834, -0.20519572, -0.24334373, -0.24944781,\n",
       "          -0.19688214, -0.22172701, -0.21557099, -0.18989592, -0.26869713,\n",
       "          -0.25734188, -0.22922793, -0.20771875, -0.21777065, -0.19161294,\n",
       "          -0.19611729, -0.24840799, -0.22595138, -0.2526693 , -0.39070329,\n",
       "          -0.22798112, -0.23116529, -0.20111707, -0.52032529, -0.18510825,\n",
       "          -0.29741406, -0.20900978, -0.20671899, -0.18419811, -0.22620818,\n",
       "          -0.24437524, -0.21568643, -0.17948348, -0.20853596, -0.21316415,\n",
       "          -0.2050278 , -0.21875455, -0.36017227, -0.20108384, -0.18424043,\n",
       "          -0.18556342, -0.17929687, -0.18659186, -0.19206127, -0.18320594,\n",
       "          -0.19657888, -0.20496593, -0.2194828 , -0.17732354, -0.18689185,\n",
       "          -0.19958425, -0.213253  , -0.18176276, -0.19062527, -0.17512228,\n",
       "          -0.21393548, -0.17585226, -0.18507496, -0.1867586 , -0.32676828,\n",
       "          -0.18909493, -0.20671049, -0.19219506, -0.21869845, -0.19095017,\n",
       "          -0.19700667, -0.18177119, -0.19148704, -0.18867041, -0.18216717,\n",
       "          -0.18751895, -0.1900562 , -0.17412363, -0.19331642, -0.19275414,\n",
       "          -0.18293282, -0.17980342, -0.18964039, -0.19319007, -0.18312356,\n",
       "          -0.21140159, -0.23225042, -0.18885694, -0.20204554, -0.20680888]),\n",
       "   'split9_test_score': array([-0.30361129, -0.35417836, -0.31781049, -0.30395317, -0.30759921,\n",
       "          -0.30761148, -0.31401458, -0.37876881, -0.34616178, -0.49692757,\n",
       "          -0.29132598, -0.30590358, -0.30851903, -0.39044313, -0.3160463 ,\n",
       "          -0.31578634, -0.41832353, -0.31030362, -0.32745629, -0.30546576,\n",
       "          -0.31648425, -0.31874594, -0.32191011, -0.29373951, -0.35706153,\n",
       "          -0.32099208, -0.29065359, -0.29193614, -0.35815018, -0.28663705,\n",
       "          -0.33473741, -0.31923786, -0.2761868 , -0.33026168, -0.4071528 ,\n",
       "          -0.31158338, -0.31660149, -0.28632676, -0.65834755, -0.29632169,\n",
       "          -0.34687512, -0.3156222 , -0.28480308, -0.30977073, -0.32269209,\n",
       "          -0.33733678, -0.32078277, -0.31313135, -0.33102572, -0.32174096,\n",
       "          -0.31970306, -0.30755959, -0.38417266, -0.28701788, -0.30241699,\n",
       "          -0.30019845, -0.28159746, -0.28757761, -0.30279638, -0.2993664 ,\n",
       "          -0.30551995, -0.31281565, -0.34439114, -0.28729255, -0.30501859,\n",
       "          -0.33157585, -0.29623811, -0.30725463, -0.30512996, -0.30142252,\n",
       "          -0.33990533, -0.2972583 , -0.30283929, -0.29913558, -0.43528039,\n",
       "          -0.30764708, -0.33301405, -0.30296236, -0.28592808, -0.30636166,\n",
       "          -0.30179545, -0.30070373, -0.30299445, -0.27478826, -0.29601687,\n",
       "          -0.29315962, -0.30714729, -0.29885569, -0.28725923, -0.3167313 ,\n",
       "          -0.28389291, -0.28026443, -0.31255503, -0.28222289, -0.30000993,\n",
       "          -0.3163592 , -0.31865163, -0.31253462, -0.30473392, -0.32738198]),\n",
       "   'mean_test_score': array([-0.34138347, -0.35436967, -0.35151416, -0.33734172, -0.3350458 ,\n",
       "          -0.35470425, -0.34579326, -0.43728523, -0.35708812, -0.50646374,\n",
       "          -0.35702622, -0.36548715, -0.36559099, -0.44273452, -0.38017548,\n",
       "          -0.34054204, -0.45909771, -0.33326694, -0.36736772, -0.35371663,\n",
       "          -0.33749439, -0.35268556, -0.33511829, -0.32829939, -0.37561165,\n",
       "          -0.34945984, -0.35721456, -0.34154133, -0.36460227, -0.33561756,\n",
       "          -0.35052037, -0.36458861, -0.32986361, -0.35200164, -0.45393885,\n",
       "          -0.34143594, -0.36260511, -0.32588535, -0.63092974, -0.32088071,\n",
       "          -0.3911208 , -0.33173698, -0.34947206, -0.32689495, -0.35049815,\n",
       "          -0.36666761, -0.35741678, -0.33408438, -0.3611902 , -0.34182181,\n",
       "          -0.33217792, -0.35671707, -0.42978219, -0.34101794, -0.32201263,\n",
       "          -0.32847791, -0.32168608, -0.32785043, -0.32106123, -0.32850164,\n",
       "          -0.31793983, -0.32666273, -0.34457901, -0.331914  , -0.31591397,\n",
       "          -0.3431913 , -0.35175204, -0.31579894, -0.31590182, -0.32419026,\n",
       "          -0.34933168, -0.31930604, -0.31681908, -0.31446066, -0.46950213,\n",
       "          -0.32483055, -0.35745515, -0.31906262, -0.3314673 , -0.31925174,\n",
       "          -0.35342733, -0.31524573, -0.31545972, -0.31733396, -0.32469797,\n",
       "          -0.31504667, -0.31653795, -0.32010224, -0.31640718, -0.32225143,\n",
       "          -0.31728227, -0.31382144, -0.31739893, -0.31751633, -0.31738603,\n",
       "          -0.37080631, -0.36647669, -0.33322853, -0.34092205, -0.33369431]),\n",
       "   'std_test_score': array([0.07593088, 0.05789355, 0.0584777 , 0.05799539, 0.06594271,\n",
       "          0.08026823, 0.06162946, 0.04491517, 0.06372118, 0.05931441,\n",
       "          0.0456476 , 0.08143358, 0.07520875, 0.04474265, 0.07557941,\n",
       "          0.05131627, 0.04014195, 0.05845658, 0.06245698, 0.05037011,\n",
       "          0.07626285, 0.06513313, 0.05570433, 0.05864745, 0.05094131,\n",
       "          0.059553  , 0.06915635, 0.06674726, 0.07544476, 0.07052692,\n",
       "          0.07616138, 0.05426435, 0.051443  , 0.0529608 , 0.04414316,\n",
       "          0.04983004, 0.06065033, 0.05912446, 0.05694194, 0.06553811,\n",
       "          0.04431747, 0.05226688, 0.07519246, 0.06117274, 0.05080042,\n",
       "          0.05502088, 0.0653683 , 0.07825806, 0.06358822, 0.04974764,\n",
       "          0.05550159, 0.0727018 , 0.04277296, 0.07606082, 0.06373632,\n",
       "          0.07561816, 0.06691617, 0.0749625 , 0.05435145, 0.07344191,\n",
       "          0.05552096, 0.05576662, 0.05006214, 0.07339739, 0.05632711,\n",
       "          0.06050355, 0.07119575, 0.05955775, 0.05530147, 0.06147317,\n",
       "          0.06150531, 0.06215304, 0.05723947, 0.05468944, 0.07036869,\n",
       "          0.06042279, 0.08703204, 0.05453891, 0.05243429, 0.0607241 ,\n",
       "          0.08554993, 0.0564265 , 0.05629962, 0.05757882, 0.06642576,\n",
       "          0.05728644, 0.05520097, 0.06171681, 0.05568058, 0.05805279,\n",
       "          0.06587237, 0.06703638, 0.05547542, 0.05967596, 0.05865749,\n",
       "          0.08897729, 0.06717083, 0.06357219, 0.06173271, 0.04798883]),\n",
       "   'rank_test_score': array([ 54,  72,  66,  49,  46,  73,  60,  94,  76,  99,  75,  84,  85,\n",
       "           95,  91,  51,  97,  43,  88,  71,  50,  69,  47,  34,  90,  62,\n",
       "           77,  56,  83,  48,  65,  82,  37,  68,  96,  55,  81,  30, 100,\n",
       "           22,  92,  39,  63,  32,  64,  87,  78,  45,  80,  57,  41,  74,\n",
       "           93,  53,  25,  35,  24,  33,  23,  36,  17,  31,  59,  40,   8,\n",
       "           58,  67,   6,   7,  27,  61,  20,  11,   2,  98,  29,  79,  18,\n",
       "           38,  19,  70,   4,   5,  13,  28,   3,  10,  21,   9,  26,  12,\n",
       "            1,  15,  16,  14,  89,  86,  42,  52,  44], dtype=int32)}},\n",
       " 'NN': {'best_estimator': MLPRegressor(alpha=0.1, hidden_layer_sizes=64,\n",
       "               learning_rate_init=0.003987326755316223, random_state=0),\n",
       "  'best_params': OrderedDict([('activation', 'relu'),\n",
       "               ('alpha', 0.1),\n",
       "               ('hidden_layer_sizes', 64),\n",
       "               ('learning_rate_init', 0.003987326755316223)]),\n",
       "  'best_score': -0.3556001712347897,\n",
       "  'optimization_history': {'mean_fit_time': array([ 7.64344568,  6.46067653, 17.61543798,  8.25848114, 12.16328654,\n",
       "           5.67620513, 10.63818755, 17.96063502,  7.67601063,  5.79032476,\n",
       "           7.2365087 ,  4.40445533,  6.72805991, 13.76196449, 10.50134528,\n",
       "           4.52461817,  6.29357727,  7.92604523,  3.47086244,  6.84774168,\n",
       "          27.88854296, 16.24087005, 13.87729495, 29.36864743,  6.74471674,\n",
       "           7.15101395,  5.76152654,  5.70354817,  6.45384462,  8.61946168,\n",
       "           4.07549427, 24.71650774, 24.73176115,  8.66080751, 24.05229177,\n",
       "          12.8134784 , 20.33140333,  3.46158206,  7.53170288, 14.55052483,\n",
       "           9.98459682, 13.87363117, 15.73934631, 18.9068532 , 22.39019511,\n",
       "          13.44721477, 13.21706231, 11.79448459, 12.98083253, 12.82087955,\n",
       "           6.32247036, 13.09385021, 13.76622791, 12.2079236 , 12.77618539,\n",
       "          13.44322681, 12.58746972, 12.30328445, 15.45108018, 13.96597979,\n",
       "           4.04732838,  4.57905481, 13.75050056, 11.78244061, 14.03203273,\n",
       "          13.38650508, 13.93364718, 13.41471975, 14.08519387, 14.52082286,\n",
       "          14.14499185, 12.87683766, 13.56852107, 12.6808538 , 11.88026786,\n",
       "          12.63216877, 13.05369689, 13.07854924, 14.65199819, 13.34232285,\n",
       "          13.28809106, 13.78941782, 13.09862201, 13.38814194, 12.56787975,\n",
       "          14.925986  , 14.74332643, 14.29808609, 13.57432132, 12.65310922,\n",
       "          12.75223365, 13.25056262, 12.76891861, 13.52939241, 16.83256249,\n",
       "          13.78206666, 13.70361202, 13.85378661, 13.61205773, 13.13335526]),\n",
       "   'std_fit_time': array([1.25651236, 0.76049133, 2.82004606, 1.90002948, 1.84263809,\n",
       "          0.67472318, 1.76992876, 3.01693789, 4.03823597, 0.96621649,\n",
       "          0.74246646, 1.77179223, 0.97431558, 1.93754047, 1.51809624,\n",
       "          0.51982811, 0.74916092, 1.11175077, 0.72095686, 0.82612336,\n",
       "          3.62009255, 3.4688185 , 2.31041015, 4.11502274, 1.21027455,\n",
       "          0.82093201, 0.53003952, 1.62857039, 1.27768821, 1.76187408,\n",
       "          0.4567378 , 4.47419802, 4.16374719, 1.28128852, 3.17124194,\n",
       "          2.32558245, 2.70851683, 0.87456618, 1.56875119, 1.98150469,\n",
       "          1.12374603, 2.96665619, 3.1345173 , 2.72276774, 3.48549868,\n",
       "          2.63238566, 3.1303726 , 2.14678584, 1.10989509, 1.98796467,\n",
       "          2.38605163, 2.07024196, 2.88891994, 1.79254843, 1.51623653,\n",
       "          2.03576539, 1.42967966, 1.8051038 , 3.32123748, 2.60024508,\n",
       "          0.28267034, 1.0847218 , 1.22374829, 1.5918503 , 1.54049479,\n",
       "          2.59569749, 2.46732551, 2.08589701, 2.7369593 , 2.19748368,\n",
       "          4.24096634, 1.75083642, 1.54512165, 1.53145996, 2.3344332 ,\n",
       "          2.24903215, 1.12523715, 2.50820235, 2.37476654, 1.82345588,\n",
       "          1.89304331, 2.50600134, 1.93010395, 2.55858094, 1.83346517,\n",
       "          1.65637436, 2.53764844, 2.66273545, 2.2216978 , 2.51357643,\n",
       "          1.88094416, 1.53142893, 1.47792936, 2.12375486, 1.87574819,\n",
       "          1.80407222, 2.16235302, 2.87375829, 1.95724347, 1.3296785 ]),\n",
       "   'mean_score_time': array([0.01022618, 0.01020489, 0.01301947, 0.00845714, 0.01056037,\n",
       "          0.01060028, 0.00872591, 0.00879045, 0.00997782, 0.00806558,\n",
       "          0.01009266, 0.01239219, 0.00957546, 0.00776441, 0.01024463,\n",
       "          0.00719411, 0.0125396 , 0.0126631 , 0.00628049, 0.00832582,\n",
       "          0.01496027, 0.00748084, 0.00666525, 0.01370456, 0.01118557,\n",
       "          0.00978873, 0.00776083, 0.00678222, 0.01209168, 0.01075737,\n",
       "          0.01037419, 0.01254494, 0.01261535, 0.01073923, 0.01218135,\n",
       "          0.0117873 , 0.01098373, 0.00783544, 0.00785632, 0.01185744,\n",
       "          0.01190836, 0.0112026 , 0.01218147, 0.01260109, 0.00995598,\n",
       "          0.01090271, 0.01035476, 0.01165223, 0.01134353, 0.01085141,\n",
       "          0.00770133, 0.01117773, 0.01008718, 0.01008234, 0.0117152 ,\n",
       "          0.01187379, 0.01100323, 0.01057479, 0.00606465, 0.00810628,\n",
       "          0.01251881, 0.00683651, 0.01244555, 0.01111755, 0.01053679,\n",
       "          0.00976977, 0.01051347, 0.01007345, 0.01172678, 0.01087289,\n",
       "          0.01129286, 0.01258457, 0.00995264, 0.00999038, 0.01135485,\n",
       "          0.01057699, 0.01059284, 0.0104799 , 0.01126678, 0.01049485,\n",
       "          0.01105015, 0.01305628, 0.00990009, 0.01020844, 0.01063037,\n",
       "          0.01008298, 0.00970509, 0.0094734 , 0.00982111, 0.0103586 ,\n",
       "          0.00928175, 0.01162364, 0.0111414 , 0.00991483, 0.00943201,\n",
       "          0.01131067, 0.01138601, 0.0102479 , 0.01203127, 0.01029017]),\n",
       "   'std_score_time': array([0.00356371, 0.00303679, 0.00675584, 0.0030441 , 0.00314281,\n",
       "          0.00309513, 0.00251531, 0.00251497, 0.00254336, 0.00287594,\n",
       "          0.00373584, 0.00279176, 0.00349575, 0.00306988, 0.00260325,\n",
       "          0.002592  , 0.00340215, 0.00590458, 0.00161623, 0.00231656,\n",
       "          0.00698347, 0.00279068, 0.00163261, 0.00216609, 0.00503866,\n",
       "          0.00413408, 0.00175013, 0.00220151, 0.00271369, 0.00299507,\n",
       "          0.00152166, 0.00333903, 0.00364809, 0.00250192, 0.00361401,\n",
       "          0.00337646, 0.00199782, 0.00307603, 0.00299584, 0.00315983,\n",
       "          0.00358316, 0.00300357, 0.00364836, 0.00294302, 0.0015478 ,\n",
       "          0.00301486, 0.00220114, 0.00347889, 0.00314884, 0.00288038,\n",
       "          0.00299513, 0.00326681, 0.0021897 , 0.00240135, 0.00341757,\n",
       "          0.00327684, 0.00318239, 0.0030146 , 0.00135438, 0.00364369,\n",
       "          0.00321785, 0.0022073 , 0.00373579, 0.00304425, 0.00244033,\n",
       "          0.0014282 , 0.00303966, 0.00244146, 0.00350718, 0.00284771,\n",
       "          0.00326809, 0.00337555, 0.00145907, 0.00233026, 0.00303933,\n",
       "          0.0030931 , 0.00255972, 0.00260713, 0.00311813, 0.00230949,\n",
       "          0.00298356, 0.00433266, 0.0018772 , 0.00223357, 0.002521  ,\n",
       "          0.00233748, 0.00176803, 0.00101155, 0.00172647, 0.00249007,\n",
       "          0.00067682, 0.00339372, 0.00396453, 0.00211367, 0.00085764,\n",
       "          0.00329661, 0.00301883, 0.00215935, 0.00438509, 0.00218335]),\n",
       "   'param_activation': masked_array(data=['relu', 'relu', 'relu', 'logistic', 'logistic', 'tanh',\n",
       "                      'tanh', 'relu', 'logistic', 'relu', 'relu', 'logistic',\n",
       "                      'relu', 'logistic', 'relu', 'relu', 'tanh', 'relu',\n",
       "                      'tanh', 'relu', 'tanh', 'logistic', 'tanh', 'logistic',\n",
       "                      'relu', 'relu', 'relu', 'logistic', 'tanh', 'relu',\n",
       "                      'logistic', 'logistic', 'logistic', 'relu', 'relu',\n",
       "                      'relu', 'logistic', 'logistic', 'tanh', 'relu', 'relu',\n",
       "                      'relu', 'relu', 'tanh', 'relu', 'relu', 'relu', 'relu',\n",
       "                      'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                      'relu', 'relu', 'relu', 'tanh', 'tanh', 'tanh',\n",
       "                      'logistic', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                      'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                      'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                      'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                      'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                      'relu', 'relu', 'relu', 'relu', 'relu'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_alpha': masked_array(data=[0.01067182086439393, 0.08643924706566204,\n",
       "                      0.00014917413598024762, 0.022376842857058803,\n",
       "                      0.000537041449556418, 0.09411788553131789,\n",
       "                      0.01860624426490807, 0.003810106313233624,\n",
       "                      0.04881101667405022, 0.0020919480782183625,\n",
       "                      0.015755020001597193, 0.1, 0.021684538201962467, 0.1,\n",
       "                      0.0009836368146650025, 0.012845029344548238, 0.0001,\n",
       "                      0.03340366002251056, 0.1, 0.03158534992629275,\n",
       "                      0.07987815492520782, 0.00796293435993093, 0.0001,\n",
       "                      0.0749529666878695, 0.018336561014524688,\n",
       "                      0.026346497259717917, 0.03484883823728036, 0.0001,\n",
       "                      0.017023134172461648, 0.03377595593474076,\n",
       "                      0.0018577167583958122, 0.1, 0.015568602549342761, 0.1,\n",
       "                      0.1, 0.1, 0.0001, 0.1, 0.001269260233656421, 0.1, 0.1,\n",
       "                      0.1, 0.1, 0.0029646967527711017, 0.1, 0.1, 0.1, 0.1,\n",
       "                      0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                      0.0026817041301704747, 0.1, 0.0026815454331723947, 0.1,\n",
       "                      0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                      0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                      0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                      0.1, 0.1, 0.1, 0.1],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_hidden_layer_sizes': masked_array(data=[41, 58, 23, 31, 47, 47, 28, 47, 51, 18, 42, 64, 39, 2,\n",
       "                      58, 11, 64, 57, 2, 40, 64, 2, 2, 63, 37, 43, 40, 2, 64,\n",
       "                      64, 64, 64, 64, 64, 64, 64, 64, 2, 2, 64, 64, 64, 64,\n",
       "                      64, 64, 64, 64, 64, 64, 64, 2, 64, 64, 64, 64, 64, 64,\n",
       "                      64, 2, 2, 64, 2, 64, 64, 64, 64, 64, 64, 64, 64, 64,\n",
       "                      64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64,\n",
       "                      64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64,\n",
       "                      64],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_learning_rate_init': masked_array(data=[0.01964987907789673, 0.015800978361793398,\n",
       "                      0.0024150786795740864, 0.008130379794328103,\n",
       "                      0.0037245610632901916, 0.009383087297142335,\n",
       "                      0.00233646067299026, 0.0011339396010997423,\n",
       "                      0.07359867334365049, 0.03946731566016232,\n",
       "                      0.02773785064303718, 0.1, 0.03422362723712954, 0.001,\n",
       "                      0.1, 0.045169922617805655, 0.1, 0.06620329608958397,\n",
       "                      0.1, 0.012240555007382647, 0.001, 0.001, 0.001, 0.001,\n",
       "                      0.05014704335458955, 0.02321040513928226,\n",
       "                      0.028080631647860125, 0.1, 0.020324889156897282,\n",
       "                      0.013016462720886648, 0.1, 0.0019986988654026646,\n",
       "                      0.001, 0.00759267887397679, 0.001307170559172089,\n",
       "                      0.003846411713523205, 0.001, 0.1, 0.1,\n",
       "                      0.0035554295598027256, 0.0050847819656532015,\n",
       "                      0.003776252821141145, 0.0028201010283948574, 0.001,\n",
       "                      0.0014748097215342992, 0.0042835607437877975,\n",
       "                      0.003741297579649547, 0.004171879498260022,\n",
       "                      0.0036750718100782144, 0.0036054795152665824,\n",
       "                      0.005893941124714771, 0.0038350234047145105,\n",
       "                      0.003980019559666405, 0.0039903999090706715,\n",
       "                      0.003951522008363818, 0.003949880089245841,\n",
       "                      0.0040547056200675256, 0.0041633434222819515, 0.001,\n",
       "                      0.001, 0.1, 0.1, 0.004026507879523483,\n",
       "                      0.003998172115346527, 0.004053176925645204,\n",
       "                      0.004035225650497707, 0.004043459393294996,\n",
       "                      0.004032003712868045, 0.004007589310463604,\n",
       "                      0.003986969898764101, 0.004006786999466222,\n",
       "                      0.003992292106073465, 0.003975304839087659,\n",
       "                      0.003990352862958081, 0.004008556752522145,\n",
       "                      0.00399574767148889, 0.003987326755316223,\n",
       "                      0.0038153182015268758, 0.003791927343772441,\n",
       "                      0.0037806269120917602, 0.0037749708646714814,\n",
       "                      0.0037412933397792682, 0.003746962605161534,\n",
       "                      0.0037409728668477693, 0.003741372918383198,\n",
       "                      0.0037337820025026077, 0.003733828880208384,\n",
       "                      0.003739344637573236, 0.003750705725519369,\n",
       "                      0.0037340739420875764, 0.0037364463636585426,\n",
       "                      0.003728059205756677, 0.0037371656952170157,\n",
       "                      0.003730700057823354, 0.0023980940141993114,\n",
       "                      0.0036255256312259228, 0.0036297527738139313,\n",
       "                      0.0036313257676571925, 0.0036357387545519477,\n",
       "                      0.003640181769135812],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.01067182086439393),\n",
       "                 ('hidden_layer_sizes', 41),\n",
       "                 ('learning_rate_init', 0.01964987907789673)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.08643924706566204),\n",
       "                 ('hidden_layer_sizes', 58),\n",
       "                 ('learning_rate_init', 0.015800978361793398)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.00014917413598024762),\n",
       "                 ('hidden_layer_sizes', 23),\n",
       "                 ('learning_rate_init', 0.0024150786795740864)]),\n",
       "    OrderedDict([('activation', 'logistic'),\n",
       "                 ('alpha', 0.022376842857058803),\n",
       "                 ('hidden_layer_sizes', 31),\n",
       "                 ('learning_rate_init', 0.008130379794328103)]),\n",
       "    OrderedDict([('activation', 'logistic'),\n",
       "                 ('alpha', 0.000537041449556418),\n",
       "                 ('hidden_layer_sizes', 47),\n",
       "                 ('learning_rate_init', 0.0037245610632901916)]),\n",
       "    OrderedDict([('activation', 'tanh'),\n",
       "                 ('alpha', 0.09411788553131789),\n",
       "                 ('hidden_layer_sizes', 47),\n",
       "                 ('learning_rate_init', 0.009383087297142335)]),\n",
       "    OrderedDict([('activation', 'tanh'),\n",
       "                 ('alpha', 0.01860624426490807),\n",
       "                 ('hidden_layer_sizes', 28),\n",
       "                 ('learning_rate_init', 0.00233646067299026)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.003810106313233624),\n",
       "                 ('hidden_layer_sizes', 47),\n",
       "                 ('learning_rate_init', 0.0011339396010997423)]),\n",
       "    OrderedDict([('activation', 'logistic'),\n",
       "                 ('alpha', 0.04881101667405022),\n",
       "                 ('hidden_layer_sizes', 51),\n",
       "                 ('learning_rate_init', 0.07359867334365049)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.0020919480782183625),\n",
       "                 ('hidden_layer_sizes', 18),\n",
       "                 ('learning_rate_init', 0.03946731566016232)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.015755020001597193),\n",
       "                 ('hidden_layer_sizes', 42),\n",
       "                 ('learning_rate_init', 0.02773785064303718)]),\n",
       "    OrderedDict([('activation', 'logistic'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.1)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.021684538201962467),\n",
       "                 ('hidden_layer_sizes', 39),\n",
       "                 ('learning_rate_init', 0.03422362723712954)]),\n",
       "    OrderedDict([('activation', 'logistic'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 2),\n",
       "                 ('learning_rate_init', 0.001)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.0009836368146650025),\n",
       "                 ('hidden_layer_sizes', 58),\n",
       "                 ('learning_rate_init', 0.1)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.012845029344548238),\n",
       "                 ('hidden_layer_sizes', 11),\n",
       "                 ('learning_rate_init', 0.045169922617805655)]),\n",
       "    OrderedDict([('activation', 'tanh'),\n",
       "                 ('alpha', 0.0001),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.1)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.03340366002251056),\n",
       "                 ('hidden_layer_sizes', 57),\n",
       "                 ('learning_rate_init', 0.06620329608958397)]),\n",
       "    OrderedDict([('activation', 'tanh'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 2),\n",
       "                 ('learning_rate_init', 0.1)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.03158534992629275),\n",
       "                 ('hidden_layer_sizes', 40),\n",
       "                 ('learning_rate_init', 0.012240555007382647)]),\n",
       "    OrderedDict([('activation', 'tanh'),\n",
       "                 ('alpha', 0.07987815492520782),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.001)]),\n",
       "    OrderedDict([('activation', 'logistic'),\n",
       "                 ('alpha', 0.00796293435993093),\n",
       "                 ('hidden_layer_sizes', 2),\n",
       "                 ('learning_rate_init', 0.001)]),\n",
       "    OrderedDict([('activation', 'tanh'),\n",
       "                 ('alpha', 0.0001),\n",
       "                 ('hidden_layer_sizes', 2),\n",
       "                 ('learning_rate_init', 0.001)]),\n",
       "    OrderedDict([('activation', 'logistic'),\n",
       "                 ('alpha', 0.0749529666878695),\n",
       "                 ('hidden_layer_sizes', 63),\n",
       "                 ('learning_rate_init', 0.001)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.018336561014524688),\n",
       "                 ('hidden_layer_sizes', 37),\n",
       "                 ('learning_rate_init', 0.05014704335458955)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.026346497259717917),\n",
       "                 ('hidden_layer_sizes', 43),\n",
       "                 ('learning_rate_init', 0.02321040513928226)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.03484883823728036),\n",
       "                 ('hidden_layer_sizes', 40),\n",
       "                 ('learning_rate_init', 0.028080631647860125)]),\n",
       "    OrderedDict([('activation', 'logistic'),\n",
       "                 ('alpha', 0.0001),\n",
       "                 ('hidden_layer_sizes', 2),\n",
       "                 ('learning_rate_init', 0.1)]),\n",
       "    OrderedDict([('activation', 'tanh'),\n",
       "                 ('alpha', 0.017023134172461648),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.020324889156897282)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.03377595593474076),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.013016462720886648)]),\n",
       "    OrderedDict([('activation', 'logistic'),\n",
       "                 ('alpha', 0.0018577167583958122),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.1)]),\n",
       "    OrderedDict([('activation', 'logistic'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0019986988654026646)]),\n",
       "    OrderedDict([('activation', 'logistic'),\n",
       "                 ('alpha', 0.015568602549342761),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.001)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.00759267887397679)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.001307170559172089)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.003846411713523205)]),\n",
       "    OrderedDict([('activation', 'logistic'),\n",
       "                 ('alpha', 0.0001),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.001)]),\n",
       "    OrderedDict([('activation', 'logistic'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 2),\n",
       "                 ('learning_rate_init', 0.1)]),\n",
       "    OrderedDict([('activation', 'tanh'),\n",
       "                 ('alpha', 0.001269260233656421),\n",
       "                 ('hidden_layer_sizes', 2),\n",
       "                 ('learning_rate_init', 0.1)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0035554295598027256)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0050847819656532015)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.003776252821141145)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0028201010283948574)]),\n",
       "    OrderedDict([('activation', 'tanh'),\n",
       "                 ('alpha', 0.0029646967527711017),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.001)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0014748097215342992)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0042835607437877975)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.003741297579649547)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.004171879498260022)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0036750718100782144)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0036054795152665824)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 2),\n",
       "                 ('learning_rate_init', 0.005893941124714771)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0038350234047145105)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.003980019559666405)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0039903999090706715)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.003951522008363818)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.003949880089245841)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0040547056200675256)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0041633434222819515)]),\n",
       "    OrderedDict([('activation', 'tanh'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 2),\n",
       "                 ('learning_rate_init', 0.001)]),\n",
       "    OrderedDict([('activation', 'tanh'),\n",
       "                 ('alpha', 0.0026817041301704747),\n",
       "                 ('hidden_layer_sizes', 2),\n",
       "                 ('learning_rate_init', 0.001)]),\n",
       "    OrderedDict([('activation', 'tanh'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.1)]),\n",
       "    OrderedDict([('activation', 'logistic'),\n",
       "                 ('alpha', 0.0026815454331723947),\n",
       "                 ('hidden_layer_sizes', 2),\n",
       "                 ('learning_rate_init', 0.1)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.004026507879523483)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.003998172115346527)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.004053176925645204)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.004035225650497707)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.004043459393294996)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.004032003712868045)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.004007589310463604)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.003986969898764101)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.004006786999466222)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.003992292106073465)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.003975304839087659)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.003990352862958081)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.004008556752522145)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.00399574767148889)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.003987326755316223)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0038153182015268758)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.003791927343772441)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0037806269120917602)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0037749708646714814)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0037412933397792682)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.003746962605161534)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0037409728668477693)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.003741372918383198)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0037337820025026077)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.003733828880208384)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.003739344637573236)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.003750705725519369)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0037340739420875764)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0037364463636585426)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.003728059205756677)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0037371656952170157)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.003730700057823354)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0023980940141993114)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0036255256312259228)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0036297527738139313)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0036313257676571925)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.0036357387545519477)]),\n",
       "    OrderedDict([('activation', 'relu'),\n",
       "                 ('alpha', 0.1),\n",
       "                 ('hidden_layer_sizes', 64),\n",
       "                 ('learning_rate_init', 0.003640181769135812)])],\n",
       "   'split0_test_score': array([-0.45778827, -0.50656192, -0.50644374, -0.51651678, -0.57853584,\n",
       "          -0.46661733, -0.4991159 , -0.48678152, -0.44268708, -0.4495637 ,\n",
       "          -0.45404527, -0.66077016, -0.39949447, -0.52933058, -0.48326492,\n",
       "          -0.48024053, -0.71057429, -0.42443111, -0.64338043, -0.44506394,\n",
       "          -0.50632754, -0.52481735, -0.58090386, -0.46999853, -0.44077495,\n",
       "          -0.43872228, -0.43428327, -0.63152672, -0.49313902, -0.41295341,\n",
       "          -0.59771204, -0.44721248, -0.5521269 , -0.39491801, -0.42400784,\n",
       "          -0.46786523, -0.62967546, -0.57371621, -0.71154581, -0.44518227,\n",
       "          -0.43097271, -0.46385139, -0.47449531, -0.57602009, -0.42430261,\n",
       "          -0.45028578, -0.44290295, -0.4581203 , -0.48262458, -0.46225739,\n",
       "          -0.51918769, -0.45329785, -0.46313295, -0.45711397, -0.45077311,\n",
       "          -0.44839445, -0.47422592, -0.45782211, -0.49078531, -0.57040074,\n",
       "          -0.56811345, -0.67386894, -0.47845415, -0.45682408, -0.46837305,\n",
       "          -0.50318952, -0.47707144, -0.46480953, -0.47792415, -0.46275448,\n",
       "          -0.46314145, -0.43466272, -0.49074119, -0.49532077, -0.48210539,\n",
       "          -0.47430329, -0.43305701, -0.44719748, -0.40941871, -0.4365966 ,\n",
       "          -0.48618701, -0.42770572, -0.48082989, -0.39857784, -0.44373026,\n",
       "          -0.42663105, -0.46556594, -0.4250871 , -0.4433018 , -0.42966197,\n",
       "          -0.43804753, -0.44178975, -0.4259007 , -0.42651034, -0.40961234,\n",
       "          -0.47590112, -0.44661302, -0.46352108, -0.41488531, -0.44970742]),\n",
       "   'split1_test_score': array([-0.34335061, -0.34178743, -0.45742482, -0.43606463, -0.43594131,\n",
       "          -0.46428537, -0.41788022, -0.38816735, -0.46414156, -0.34517571,\n",
       "          -0.34072788, -0.54545698, -0.33589216, -0.46038563, -0.35588764,\n",
       "          -0.36223871, -0.61417272, -0.30989835, -0.72253567, -0.37335439,\n",
       "          -0.38652743, -0.45079479, -0.55984867, -0.37804578, -0.37351634,\n",
       "          -0.30973889, -0.35024746, -0.63456424, -0.45396224, -0.35846355,\n",
       "          -0.51982587, -0.33182753, -0.4040738 , -0.3281999 , -0.26841911,\n",
       "          -0.30335388, -0.50051382, -0.50975437, -0.51670341, -0.34271808,\n",
       "          -0.30732936, -0.34952874, -0.35554022, -0.38762759, -0.30247573,\n",
       "          -0.30634098, -0.30584932, -0.33460626, -0.32694733, -0.30727213,\n",
       "          -0.35662278, -0.32885414, -0.33036967, -0.33119976, -0.31724261,\n",
       "          -0.33378741, -0.35271859, -0.31468791, -0.54622315, -0.55513121,\n",
       "          -0.41156354, -0.5856646 , -0.32119194, -0.29644411, -0.32907813,\n",
       "          -0.27837984, -0.31589903, -0.33145779, -0.29937807, -0.28332479,\n",
       "          -0.31791629, -0.32553022, -0.30830858, -0.26097188, -0.30910698,\n",
       "          -0.28340006, -0.30374471, -0.30779928, -0.33346614, -0.32949613,\n",
       "          -0.377966  , -0.27956383, -0.32094446, -0.31537725, -0.30131116,\n",
       "          -0.30844998, -0.30751525, -0.30838115, -0.3272295 , -0.27491907,\n",
       "          -0.33912985, -0.30142617, -0.33264557, -0.29040756, -0.33151472,\n",
       "          -0.35341224, -0.33555384, -0.30310548, -0.31777797, -0.33184075]),\n",
       "   'split2_test_score': array([-0.39495053, -0.36317729, -0.88591938, -0.40260715, -0.44089136,\n",
       "          -0.42183291, -0.47255617, -0.55927865, -0.57350556, -0.44705232,\n",
       "          -0.39975987, -0.60164854, -0.40287108, -0.50622165, -0.50877215,\n",
       "          -0.41758342, -0.60211669, -0.45985906, -0.67258634, -0.40673469,\n",
       "          -0.43183521, -0.51283991, -0.55245981, -0.36661392, -0.41419746,\n",
       "          -0.36416818, -0.3887501 , -0.57280051, -0.46933898, -0.42917515,\n",
       "          -0.53176208, -0.42123776, -0.40684706, -0.35188333, -0.37268288,\n",
       "          -0.384656  , -0.52031098, -0.51848377, -0.56334717, -0.34045848,\n",
       "          -0.33847803, -0.35807158, -0.377277  , -0.50086581, -0.39435157,\n",
       "          -0.3352352 , -0.3369619 , -0.31751868, -0.35773011, -0.36478374,\n",
       "          -0.40251706, -0.35981952, -0.3565268 , -0.34260948, -0.34147342,\n",
       "          -0.35156015, -0.31070314, -0.32347107, -0.52024054, -0.54960764,\n",
       "          -0.68273124, -0.65522556, -0.34390826, -0.34828336, -0.3344382 ,\n",
       "          -0.3477782 , -0.34591807, -0.34946853, -0.35253494, -0.34669144,\n",
       "          -0.38077774, -0.36906269, -0.35691329, -0.36291146, -0.34613266,\n",
       "          -0.37103572, -0.33141672, -0.36139097, -0.3552214 , -0.32929954,\n",
       "          -0.34353764, -0.36853362, -0.38517142, -0.33017716, -0.3371478 ,\n",
       "          -0.33142592, -0.33670169, -0.32446557, -0.37241521, -0.38793855,\n",
       "          -0.36463223, -0.31307679, -0.34446537, -0.34990334, -0.35040403,\n",
       "          -0.36214642, -0.36582861, -0.33211581, -0.36827114, -0.34251443]),\n",
       "   'split3_test_score': array([-0.39011037, -0.4001914 , -2.54233768, -0.43436892, -0.67019544,\n",
       "          -0.40673821, -0.4688412 , -1.05627101, -0.48831095, -0.82169689,\n",
       "          -0.41582823, -0.4591341 , -0.41808642, -0.42882507, -0.70422125,\n",
       "          -0.47788468, -0.58646464, -0.39899047, -0.69448665, -0.42883796,\n",
       "          -0.42835241, -0.82178988, -0.72861151, -0.37661595, -0.40022161,\n",
       "          -0.37940801, -0.43472791, -0.58075139, -0.61210602, -0.40509296,\n",
       "          -0.59243538, -0.5183763 , -0.49122059, -0.38604957, -0.42900216,\n",
       "          -0.35694891, -0.87781825, -0.5144269 , -0.55492296, -0.37987474,\n",
       "          -0.36224299, -0.32052328, -0.33129592, -0.57648443, -0.44512856,\n",
       "          -0.36232536, -0.34785745, -0.34620256, -0.30436845, -0.35343576,\n",
       "          -0.53852657, -0.33982863, -0.36080993, -0.36345403, -0.38268847,\n",
       "          -0.36981244, -0.33214752, -0.33007633, -0.58648972, -0.72427315,\n",
       "          -0.48433557, -0.52044621, -0.37459515, -0.32280187, -0.35591183,\n",
       "          -0.38917713, -0.35847074, -0.33716341, -0.35531919, -0.32417452,\n",
       "          -0.36626965, -0.31007669, -0.30122593, -0.33812587, -0.36115448,\n",
       "          -0.3640045 , -0.304549  , -0.39586849, -0.37196092, -0.38110142,\n",
       "          -0.39703565, -0.34813559, -0.34976039, -0.35708018, -0.35564246,\n",
       "          -0.35289454, -0.36539977, -0.33014919, -0.37136844, -0.3520285 ,\n",
       "          -0.36107803, -0.35201254, -0.36186266, -0.34208175, -0.37966279,\n",
       "          -0.32427164, -0.30017471, -0.34657133, -0.3696508 , -0.35442751]),\n",
       "   'split4_test_score': array([-0.47797977, -0.41748631, -2.19396357, -0.52493881, -0.61983242,\n",
       "          -0.58115279, -0.57918325, -1.07857444, -0.52251942, -0.77258603,\n",
       "          -0.43081656, -0.51906608, -0.38885785, -0.53596304, -0.64833883,\n",
       "          -0.4394456 , -0.63642284, -0.40950119, -0.70446014, -0.46552209,\n",
       "          -0.48513706, -0.8483802 , -0.60578576, -0.46657492, -0.50610842,\n",
       "          -0.4364626 , -0.41188447, -0.63741564, -0.48924579, -0.43195288,\n",
       "          -0.56185211, -0.49385749, -0.55972219, -0.44078949, -0.44085532,\n",
       "          -0.47832551, -0.83747665, -0.52943845, -0.61977182, -0.4104985 ,\n",
       "          -0.43248369, -0.40162239, -0.40380599, -0.52182508, -0.44201049,\n",
       "          -0.47200379, -0.44404948, -0.42521065, -0.44791694, -0.40849364,\n",
       "          -0.49977414, -0.44579291, -0.39848093, -0.39585753, -0.41293229,\n",
       "          -0.44333213, -0.40402763, -0.42687094, -0.557273  , -0.60921664,\n",
       "          -0.61229945, -0.54022246, -0.4337666 , -0.43172312, -0.41582905,\n",
       "          -0.42672803, -0.43411652, -0.44672193, -0.42778621, -0.40490349,\n",
       "          -0.40523259, -0.41525517, -0.39021831, -0.4049164 , -0.45773345,\n",
       "          -0.3851991 , -0.41623102, -0.46775048, -0.38159166, -0.41657334,\n",
       "          -0.41403949, -0.41310492, -0.4276577 , -0.44149729, -0.40536593,\n",
       "          -0.40552381, -0.43232876, -0.42766247, -0.45193655, -0.4493674 ,\n",
       "          -0.41381388, -0.44198419, -0.41951144, -0.45853598, -0.46003142,\n",
       "          -0.41165839, -0.42890105, -0.41919317, -0.43076004, -0.38981549]),\n",
       "   'split5_test_score': array([-0.3454125 , -0.40783921, -1.19116457, -0.44900239, -0.62896718,\n",
       "          -0.424324  , -0.48843565, -0.6831116 , -0.50405233, -0.64192911,\n",
       "          -0.40263415, -0.4796687 , -0.36626298, -0.46994721, -0.41558783,\n",
       "          -0.40277926, -0.61724539, -0.4140895 , -0.57001145, -0.33303217,\n",
       "          -0.49276375, -0.60888207, -0.63954979, -0.50374879, -0.39105614,\n",
       "          -0.39882501, -0.37343   , -0.56922556, -0.5489917 , -0.36380567,\n",
       "          -0.48468409, -0.49623373, -0.50685558, -0.38242279, -0.40016487,\n",
       "          -0.37820188, -0.67402614, -0.62277651, -0.51520175, -0.39465898,\n",
       "          -0.34886719, -0.38657313, -0.36708694, -0.44419024, -0.38909555,\n",
       "          -0.3844478 , -0.36190108, -0.35109972, -0.37735083, -0.37015897,\n",
       "          -0.43871879, -0.31618356, -0.33494062, -0.38468895, -0.3658337 ,\n",
       "          -0.30578914, -0.37629462, -0.33103267, -0.54112434, -0.64818061,\n",
       "          -0.55866751, -0.53555382, -0.34552494, -0.34306198, -0.38095586,\n",
       "          -0.3421774 , -0.32687535, -0.40619011, -0.36545626, -0.33471568,\n",
       "          -0.32135891, -0.35771387, -0.35888082, -0.37987165, -0.39740648,\n",
       "          -0.37122216, -0.36136798, -0.37141119, -0.39728217, -0.37262419,\n",
       "          -0.35907446, -0.3442228 , -0.37081835, -0.35698093, -0.40712802,\n",
       "          -0.39135759, -0.3337798 , -0.33124572, -0.36495781, -0.38343558,\n",
       "          -0.40728251, -0.35949464, -0.38969085, -0.34370778, -0.3632773 ,\n",
       "          -0.38303468, -0.37773647, -0.36020686, -0.36866337, -0.3518852 ]),\n",
       "   'split6_test_score': array([-0.42830503, -0.42066086, -1.65230796, -0.48230797, -0.46802038,\n",
       "          -0.49766257, -0.55778617, -0.82197988, -0.5688188 , -0.74424564,\n",
       "          -0.43369352, -0.57465152, -0.42640681, -0.47292477, -0.82163375,\n",
       "          -0.48283853, -0.59169439, -0.4123118 , -0.74925618, -0.44123789,\n",
       "          -0.52307951, -0.65024394, -0.78241831, -0.42663792, -0.4000226 ,\n",
       "          -0.38282553, -0.38125435, -0.69455147, -0.54914985, -0.39575401,\n",
       "          -0.61337923, -0.46088053, -0.39512492, -0.3738393 , -0.41411996,\n",
       "          -0.39228429, -0.54927922, -0.79765371, -0.57468299, -0.43844246,\n",
       "          -0.41114702, -0.43434773, -0.36777794, -0.79327613, -0.40720167,\n",
       "          -0.41718469, -0.47216662, -0.40461595, -0.3848991 , -0.41542507,\n",
       "          -0.58275382, -0.45875293, -0.37699637, -0.44420943, -0.42561051,\n",
       "          -0.41215204, -0.39294412, -0.42487589, -0.76617668, -0.78008077,\n",
       "          -0.64032148, -0.71238039, -0.41725383, -0.42765171, -0.42798838,\n",
       "          -0.47604255, -0.44774171, -0.43195453, -0.46175354, -0.41645083,\n",
       "          -0.46267346, -0.47465358, -0.43648491, -0.43474367, -0.45744195,\n",
       "          -0.43316778, -0.40809814, -0.44304296, -0.42575937, -0.44108897,\n",
       "          -0.43995473, -0.42836856, -0.42166802, -0.47189865, -0.4075276 ,\n",
       "          -0.44052466, -0.39831404, -0.41823535, -0.44273972, -0.4193161 ,\n",
       "          -0.40554721, -0.39831646, -0.43250901, -0.44630477, -0.38124088,\n",
       "          -0.34651558, -0.3997234 , -0.42300449, -0.39547574, -0.42794948]),\n",
       "   'split7_test_score': array([-0.40381355, -0.41418786, -0.72366877, -0.32664734, -0.45511082,\n",
       "          -0.33335498, -0.38221299, -0.56110536, -0.50402422, -0.46400833,\n",
       "          -0.34944277, -0.37039456, -0.38586259, -0.40145876, -4.11602325,\n",
       "          -0.3936272 , -0.56214173, -0.46313252, -0.59649029, -0.35270166,\n",
       "          -0.37215562, -0.46198365, -0.48512153, -0.32574388, -0.36363983,\n",
       "          -0.38769218, -0.32901227, -0.56747177, -0.48852601, -0.39448032,\n",
       "          -0.48921348, -0.34227404, -0.34316405, -0.38937986, -0.35519708,\n",
       "          -0.33588814, -0.47800831, -0.54514409, -0.60516215, -0.32972824,\n",
       "          -0.34912369, -0.35066681, -0.37524485, -0.47230759, -0.34278665,\n",
       "          -0.37144129, -0.38538462, -0.33293586, -0.3613595 , -0.32541949,\n",
       "          -0.430929  , -0.31351216, -0.37757503, -0.3540124 , -0.3209036 ,\n",
       "          -0.32156301, -0.29387078, -0.36343181, -0.47077969, -0.48791361,\n",
       "          -0.4457916 , -0.54501983, -0.35807978, -0.33463816, -0.35894972,\n",
       "          -0.38439835, -0.30490343, -0.38581532, -0.31754132, -0.35161366,\n",
       "          -0.34791024, -0.37586999, -0.35717538, -0.30836857, -0.35285546,\n",
       "          -0.3275233 , -0.29401937, -0.35355991, -0.33259598, -0.3329308 ,\n",
       "          -0.38572338, -0.36805022, -0.32821274, -0.33929583, -0.36647727,\n",
       "          -0.36289741, -0.31374264, -0.36169104, -0.38471529, -0.35090801,\n",
       "          -0.34353299, -0.35323121, -0.31844186, -0.31872975, -0.3462178 ,\n",
       "          -0.35900759, -0.34379195, -0.35587091, -0.33697157, -0.36487106]),\n",
       "   'split8_test_score': array([-0.36389154, -0.32870351, -1.5334976 , -0.41865321, -0.55816961,\n",
       "          -0.41746292, -0.39812852, -0.85810142, -0.51669804, -0.6951284 ,\n",
       "          -0.32793879, -0.44358306, -0.32374414, -0.37077354, -0.62877028,\n",
       "          -0.42797847, -0.53356983, -0.34932356, -0.55736028, -0.33763401,\n",
       "          -0.46196749, -0.56339775, -0.53269287, -0.45388821, -0.28388156,\n",
       "          -0.3110047 , -0.35187955, -0.57719316, -0.41291306, -0.35918862,\n",
       "          -0.56303848, -0.39948601, -0.44974218, -0.32047813, -0.34897925,\n",
       "          -0.33728433, -0.66446519, -0.52801201, -0.57257818, -0.33584632,\n",
       "          -0.30898443, -0.31444736, -0.36737338, -0.40841302, -0.3437953 ,\n",
       "          -0.32715125, -0.34777164, -0.40926997, -0.37675105, -0.40635438,\n",
       "          -0.40719542, -0.31686747, -0.35830676, -0.37344617, -0.35570355,\n",
       "          -0.34483374, -0.30009752, -0.3394912 , -0.47224496, -0.53143863,\n",
       "          -0.55285701, -0.50177457, -0.37336062, -0.33976038, -0.31320731,\n",
       "          -0.31845485, -0.30455782, -0.3261936 , -0.33784971, -0.37851407,\n",
       "          -0.34952933, -0.32738612, -0.32085131, -0.33372839, -0.34248392,\n",
       "          -0.35198583, -0.28545531, -0.33761781, -0.4047659 , -0.35504577,\n",
       "          -0.39305897, -0.34566722, -0.34998799, -0.36237213, -0.40084672,\n",
       "          -0.35544338, -0.36951895, -0.35026613, -0.35611825, -0.32887852,\n",
       "          -0.35287042, -0.3251588 , -0.38233947, -0.34496946, -0.37033347,\n",
       "          -0.32154855, -0.38596902, -0.32053476, -0.32808022, -0.33426069]),\n",
       "   'split9_test_score': array([-0.44082965, -0.47440891, -1.66161046, -0.56865203, -0.61054432,\n",
       "          -0.62335443, -0.6551479 , -0.9625803 , -0.62135004, -0.61507601,\n",
       "          -0.43974456, -0.48039789, -0.41465526, -0.50535538, -0.62249414,\n",
       "          -0.52837196, -0.60776964, -0.53023827, -0.5942628 , -0.42175922,\n",
       "          -0.4563529 , -0.56926853, -0.73840337, -0.54918269, -0.46059415,\n",
       "          -0.43547808, -0.54071377, -0.60166037, -0.52345037, -0.47369722,\n",
       "          -0.61264165, -0.57474727, -0.57032124, -0.448048  , -0.45419531,\n",
       "          -0.4387404 , -0.7493045 , -0.59813834, -0.60222397, -0.44803178,\n",
       "          -0.48557812, -0.47325874, -0.43087894, -0.55772935, -0.46962977,\n",
       "          -0.41887005, -0.4758764 , -0.45809008, -0.4386136 , -0.47249817,\n",
       "          -0.6073639 , -0.43398931, -0.4530248 , -0.4396545 , -0.44959018,\n",
       "          -0.4834114 , -0.47268858, -0.44846794, -0.60509923, -0.74430496,\n",
       "          -0.57535932, -0.68169603, -0.41375412, -0.44036155, -0.43384171,\n",
       "          -0.4935911 , -0.51375449, -0.4322722 , -0.47591636, -0.46861755,\n",
       "          -0.43263307, -0.46903985, -0.45498784, -0.44733684, -0.46336037,\n",
       "          -0.47857167, -0.41806244, -0.44987653, -0.46186866, -0.44902599,\n",
       "          -0.47481406, -0.45961333, -0.43112274, -0.44524382, -0.45295005,\n",
       "          -0.44340344, -0.45670636, -0.46183448, -0.448547  , -0.42413849,\n",
       "          -0.47085217, -0.45610304, -0.47323173, -0.46454334, -0.40709071,\n",
       "          -0.41734445, -0.42999683, -0.43335433, -0.43033536, -0.42836301]),\n",
       "   'mean_test_score': array([-0.40464318, -0.40750047, -1.33483385, -0.45597592, -0.54662087,\n",
       "          -0.46367855, -0.4919288 , -0.74559515, -0.5206108 , -0.59964621,\n",
       "          -0.39946316, -0.51347716, -0.38621338, -0.46811856, -0.93049941,\n",
       "          -0.44129884, -0.60621721, -0.41717758, -0.65048302, -0.4005878 ,\n",
       "          -0.45444989, -0.60123981, -0.62057955, -0.43170506, -0.40340131,\n",
       "          -0.38443255, -0.39961831, -0.60671608, -0.5040823 , -0.40245638,\n",
       "          -0.55665444, -0.44861331, -0.46791985, -0.38160084, -0.39076238,\n",
       "          -0.38735486, -0.64808785, -0.57375444, -0.58361402, -0.38654398,\n",
       "          -0.37752072, -0.38528911, -0.38507765, -0.52387393, -0.39607779,\n",
       "          -0.38452862, -0.39207215, -0.383767  , -0.38585615, -0.38860987,\n",
       "          -0.47835892, -0.37668985, -0.38101639, -0.38862462, -0.38227514,\n",
       "          -0.38146359, -0.37097184, -0.37602279, -0.55564366, -0.6200548 ,\n",
       "          -0.55320402, -0.59518524, -0.38598894, -0.37415503, -0.38185732,\n",
       "          -0.3959917 , -0.38293086, -0.3912047 , -0.38714598, -0.37717605,\n",
       "          -0.38474427, -0.38592509, -0.37757876, -0.37662955, -0.39697811,\n",
       "          -0.38404134, -0.35560017, -0.39355151, -0.38739309, -0.38437827,\n",
       "          -0.40713914, -0.37829658, -0.38661737, -0.38185011, -0.38781273,\n",
       "          -0.38185518, -0.37795732, -0.37390182, -0.39633296, -0.38005922,\n",
       "          -0.38967868, -0.37425936, -0.38805987, -0.37856941, -0.37993855,\n",
       "          -0.37548407, -0.38142889, -0.37574782, -0.37608715, -0.37756351]),\n",
       "   'std_test_score': array([0.04393585, 0.05210834, 0.67044567, 0.06609796, 0.08404195,\n",
       "          0.08131584, 0.081168  , 0.23245713, 0.05112991, 0.15499322,\n",
       "          0.04254658, 0.08050708, 0.03276275, 0.05170881, 1.0700151 ,\n",
       "          0.04786689, 0.04452896, 0.05771032, 0.06446706, 0.04548933,\n",
       "          0.04738081, 0.13050503, 0.09396782, 0.06600766, 0.05680326,\n",
       "          0.04459504, 0.05773698, 0.03964323, 0.05357706, 0.03490876,\n",
       "          0.04592388, 0.07304362, 0.07554019, 0.03963315, 0.05295283,\n",
       "          0.05536242, 0.1330279 , 0.08286982, 0.0539234 , 0.04521025,\n",
       "          0.05629776, 0.05386773, 0.0391189 , 0.10983955, 0.05023201,\n",
       "          0.05169259, 0.05836754, 0.0507175 , 0.05258977, 0.05161849,\n",
       "          0.07921059, 0.05985345, 0.04298045, 0.04234297, 0.04762155,\n",
       "          0.05796725, 0.06249165, 0.05391059, 0.0822441 , 0.0947491 ,\n",
       "          0.08058812, 0.07383108, 0.04610412, 0.05518178, 0.04941182,\n",
       "          0.07322278, 0.07391349, 0.04955707, 0.06402985, 0.05744665,\n",
       "          0.05135149, 0.0565907 , 0.06121003, 0.06694962, 0.05958765,\n",
       "          0.05880766, 0.05564086, 0.05255141, 0.03888571, 0.04567336,\n",
       "          0.04462997, 0.05084913, 0.04944235, 0.05145496, 0.04488762,\n",
       "          0.04439911, 0.05496865, 0.05136754, 0.04345675, 0.05111854,\n",
       "          0.04190188, 0.053887  , 0.04710698, 0.06043448, 0.03571906,\n",
       "          0.04528678, 0.04426853, 0.05182699, 0.03899422, 0.04126025]),\n",
       "   'rank_test_score': array([ 65,  67, 100,  73,  83,  74,  78,  98,  81,  90,  60,  80,  41,\n",
       "           76,  99,  70,  92,  68,  97,  62,  72,  91,  95,  69,  64,  33,\n",
       "           61,  93,  79,  63,  86,  71,  75,  24,  52,  45,  96,  87,  88,\n",
       "           42,  13,  37,  36,  82,  57,  34,  54,  30,  38,  49,  77,  11,\n",
       "           21,  50,  28,  23,   2,   8,  85,  94,  84,  89,  40,   4,  27,\n",
       "           56,  29,  53,  44,  12,  35,  39,  15,  10,  59,  31,   1,  55,\n",
       "           46,  32,  66,  17,  43,  25,  47,  26,  16,   3,  58,  20,  51,\n",
       "            5,  48,  18,  19,   6,  22,   7,   9,  14], dtype=int32)}},\n",
       " 'LightGBM': {'best_estimator': LGBMRegressor(bagging_fraction=0.5, feature_fraction=0.7213088905100546,\n",
       "                learning_rate=0.11793423693158603, max_depth=15,\n",
       "                min_child_samples=100, n_estimators=867, n_jobs=6, num_leaves=10,\n",
       "                random_state=0),\n",
       "  'best_params': OrderedDict([('bagging_fraction', 0.5),\n",
       "               ('feature_fraction', 0.7213088905100546),\n",
       "               ('learning_rate', 0.11793423693158603),\n",
       "               ('max_depth', 15),\n",
       "               ('min_child_samples', 100),\n",
       "               ('n_estimators', 867),\n",
       "               ('num_leaves', 10)]),\n",
       "  'best_score': -0.3046625582721595,\n",
       "  'optimization_history': {'mean_fit_time': array([ 56.63082831,  31.66761889,  21.15201614,  41.45004394,\n",
       "           10.28947775,  28.47821441,  29.10242226,   4.69806008,\n",
       "           70.9918237 , 173.7626143 ,   5.34875281, 121.11070261,\n",
       "           54.10336442,  62.61251717,   5.25116155,  11.24495883,\n",
       "           11.8715611 ,   9.72465112,   8.20167143,  15.6168112 ,\n",
       "           12.98654995,  38.64961443,  27.28376613, 227.7966722 ,\n",
       "           26.01625121,   3.99205883,  15.01746593,  24.88714132,\n",
       "           28.18113246,   8.12577972,  14.49273756,  40.22962735,\n",
       "           23.29434669,  13.14183459,  14.32513971,  62.03740792,\n",
       "           28.61015356,  23.76389847,  23.9744221 ,  81.90730152,\n",
       "           27.50580893,   7.48742378,  20.08475044,  99.47109549,\n",
       "           13.59682834,  23.20647984, 345.86913631,  20.02233078,\n",
       "           27.6535543 ,  22.42976377,  23.74843886,  43.28322608,\n",
       "            8.89893026,  25.48073626,  11.78034422,  20.00765738,\n",
       "          199.49581962, 268.79173636,   9.7254148 ,   2.55414333,\n",
       "           16.76275201,  44.28249266,  15.78275785,   3.06015987,\n",
       "          314.36443508,  16.23518083,  15.9214191 , 118.88629389,\n",
       "           84.2600863 ,  15.64057093,  14.16901968,  13.15306587,\n",
       "           90.16032689,   6.73767033,  28.09738522,  15.10267031,\n",
       "           54.46113322, 126.65296392,  28.11037042,  35.36563544,\n",
       "          158.09396651, 246.9672255 ,  12.8170701 ,  12.95244422,\n",
       "           12.56762257,  14.6870589 , 234.09280064,  12.59607925,\n",
       "           10.75071378,  13.42003975,   2.38672194, 297.76504836,\n",
       "           11.90531042,  12.28484282,  14.45264513,  14.68545318,\n",
       "           18.59712582, 196.29134629,  49.32431121,  14.3257005 ]),\n",
       "   'std_fit_time': array([14.4265644 ,  7.92685179,  5.03312275,  9.64415451,  2.96862147,\n",
       "           6.08829467,  7.04247968,  0.8439954 , 17.70016359, 43.48865555,\n",
       "           1.36509371, 27.37262381, 14.51215842, 16.09418675,  1.20034801,\n",
       "           2.68704293,  2.77679643,  2.23744258,  1.93310557,  2.5215989 ,\n",
       "           2.95708426, 10.00184098,  6.28701808, 52.55181688,  3.76366562,\n",
       "           0.83481418,  3.35466958,  9.07013389,  6.52671636,  1.88705576,\n",
       "           2.7636213 ,  9.53320131,  5.65272122,  3.25937005,  3.30067717,\n",
       "          14.33629433,  6.47547273,  4.72395018,  5.33913644, 21.10208763,\n",
       "           6.23853836,  1.64978156,  4.5180787 , 23.97541937,  2.94621579,\n",
       "           4.89541062, 89.30566566,  5.30420329,  6.11975653,  4.9530896 ,\n",
       "           5.11614865, 12.11443957,  2.04603677,  6.06220595,  2.77296022,\n",
       "           5.16112383, 51.50929095, 66.41801443,  2.24346881,  0.60620466,\n",
       "           3.74158811, 10.49787255,  3.78149416,  0.7473289 , 78.60576102,\n",
       "           3.80271897,  3.85333999, 28.07097434, 21.27984211,  4.00118337,\n",
       "           3.42446322,  3.17296656, 21.97037079,  1.63368921,  6.40122557,\n",
       "           3.60996019, 12.13967083, 31.71339878,  6.25630953,  8.0923365 ,\n",
       "          38.54559299, 64.01520504,  3.04891202,  2.46743352,  2.97501247,\n",
       "           3.52363211, 63.30799888,  2.97235838,  2.42840273,  2.11737822,\n",
       "           0.57480914, 81.5639231 ,  2.59653626,  2.81365915,  3.4423073 ,\n",
       "           3.50277823,  4.46148468, 49.87341632, 11.86627049,  3.21893644]),\n",
       "   'mean_score_time': array([0.07867131, 0.02986252, 0.02959683, 0.04996803, 0.02260785,\n",
       "          0.03561473, 0.03969493, 0.02635858, 0.06667838, 0.08768477,\n",
       "          0.02183118, 0.10005627, 0.04586275, 0.05110397, 0.02617462,\n",
       "          0.02344995, 0.02939596, 0.03184304, 0.03005259, 0.03766756,\n",
       "          0.03386121, 0.03215361, 0.04184644, 0.12204936, 0.03100021,\n",
       "          0.02329674, 0.02485507, 0.03042016, 0.04087963, 0.01587679,\n",
       "          0.02942843, 0.04462531, 0.03133781, 0.03381763, 0.02641902,\n",
       "          0.04487758, 0.03920381, 0.02743633, 0.03556957, 0.05414193,\n",
       "          0.03845072, 0.02358088, 0.03259234, 0.07646599, 0.02682836,\n",
       "          0.03366871, 0.12484171, 0.03808191, 0.04230907, 0.03388741,\n",
       "          0.03089976, 0.02084017, 0.03639312, 0.0373596 , 0.02229488,\n",
       "          0.03607183, 0.0740653 , 0.08661773, 0.02819412, 0.02268414,\n",
       "          0.02904856, 0.03984935, 0.04081454, 0.02007923, 0.12149236,\n",
       "          0.03768096, 0.03497593, 0.0861208 , 0.05443146, 0.03848267,\n",
       "          0.03297226, 0.0265954 , 0.08975182, 0.02433238, 0.03426445,\n",
       "          0.03222625, 0.05646241, 0.09415321, 0.03210256, 0.03744926,\n",
       "          0.0904712 , 0.08248539, 0.03386774, 0.03573658, 0.02514224,\n",
       "          0.04321887, 0.10601096, 0.02748792, 0.02663476, 0.03443797,\n",
       "          0.01998074, 0.10752749, 0.03046336, 0.02978067, 0.03522995,\n",
       "          0.03477051, 0.03935809, 0.07620592, 0.04508331, 0.03858972]),\n",
       "   'std_score_time': array([0.00891468, 0.00511501, 0.00663879, 0.00651979, 0.00704603,\n",
       "          0.00472146, 0.01167913, 0.01433525, 0.00634316, 0.00733481,\n",
       "          0.01205392, 0.00826313, 0.00554745, 0.0076943 , 0.0192059 ,\n",
       "          0.00950541, 0.00585512, 0.01990127, 0.01525601, 0.01829234,\n",
       "          0.01622785, 0.01018855, 0.01715416, 0.00512119, 0.00960224,\n",
       "          0.01617632, 0.01000727, 0.00719723, 0.01379251, 0.00437487,\n",
       "          0.00612397, 0.00759871, 0.00767   , 0.01267356, 0.0099898 ,\n",
       "          0.00518263, 0.00925879, 0.00824345, 0.01163891, 0.01109907,\n",
       "          0.01177456, 0.01083171, 0.01342377, 0.00859766, 0.0126287 ,\n",
       "          0.01301764, 0.00343923, 0.00827583, 0.01059542, 0.01164933,\n",
       "          0.01118594, 0.00617143, 0.01708905, 0.0134398 , 0.00684891,\n",
       "          0.01066213, 0.00678348, 0.00549698, 0.01681629, 0.01897158,\n",
       "          0.01087745, 0.00831811, 0.02583478, 0.011421  , 0.01374663,\n",
       "          0.0141868 , 0.01028146, 0.00539342, 0.00545783, 0.01628652,\n",
       "          0.01551217, 0.00596803, 0.01097851, 0.01114442, 0.01035997,\n",
       "          0.0094972 , 0.00516573, 0.00495065, 0.00835362, 0.0058655 ,\n",
       "          0.00930694, 0.01230798, 0.0137835 , 0.01492227, 0.00635948,\n",
       "          0.02395545, 0.00528393, 0.01155212, 0.01529825, 0.00798708,\n",
       "          0.00833307, 0.02187867, 0.01315978, 0.01581612, 0.01351044,\n",
       "          0.0147789 , 0.012921  , 0.02676365, 0.00697197, 0.02103229]),\n",
       "   'param_bagging_fraction': masked_array(data=[0.7654820824760737, 0.629185830986374,\n",
       "                      0.7643458710377254, 0.5737099059755859,\n",
       "                      0.6162570141151325, 0.9190831912766004,\n",
       "                      0.9835656124421499, 0.7552445232092422,\n",
       "                      0.546027248452608, 0.6847684887002612,\n",
       "                      0.7702157793924279, 0.5581635896410128, 0.5, 1.0,\n",
       "                      0.695388745250626, 0.6010607512842553,\n",
       "                      0.8109525010758685, 0.5413766773266244,\n",
       "                      0.9687211934001123, 0.5, 0.5, 0.7988240732519352,\n",
       "                      0.7043591453544604, 0.8284635523142878, 1.0, 1.0,\n",
       "                      0.5233668230146984, 0.9642100459094738,\n",
       "                      0.6624357179010059, 0.5051280271051379,\n",
       "                      0.7954806102031173, 0.8489173577194873,\n",
       "                      0.991501942286271, 0.6249500138684704,\n",
       "                      0.9091900732331768, 0.7199533731256063,\n",
       "                      0.7728216607363545, 0.6437844134547452,\n",
       "                      0.5899544838425143, 1.0, 0.7382668290280634,\n",
       "                      0.9398644747208972, 0.5345692040165404, 1.0,\n",
       "                      0.9698399160129514, 0.9856124647994302,\n",
       "                      0.6389064676271512, 0.5, 0.8118929555283037, 0.5,\n",
       "                      0.7082843226968932, 1.0, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0,\n",
       "                      0.5, 0.5, 0.5, 0.7065451482709622, 0.7388928029926499,\n",
       "                      0.5276954526883374, 0.5, 0.6189633097648055,\n",
       "                      0.8778014457239963, 0.9756908253050366, 0.5,\n",
       "                      0.5602471751326271, 0.9829546076664571, 1.0, 0.5,\n",
       "                      0.9457936447726392, 0.5251181027794909, 0.5, 1.0, 1.0,\n",
       "                      0.8795321843941388, 1.0, 0.515401886946663, 0.5,\n",
       "                      0.7702835112979058, 0.5, 0.5, 0.5, 0.5,\n",
       "                      0.7602844043654979, 0.5540885426228469, 0.5,\n",
       "                      0.8350281884426594, 0.5, 0.629442121161646, 0.5, 0.5,\n",
       "                      1.0, 0.5, 0.530056102176457, 0.5879342643769147, 0.5],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_feature_fraction': masked_array(data=[0.8380397544384568, 0.9894518292131809,\n",
       "                      0.5289489218467651, 0.8916331353364969,\n",
       "                      0.6216679677341995, 0.9956120269464492,\n",
       "                      0.8782764530210248, 0.7634895156575092,\n",
       "                      0.9480863089293394, 0.7200918168694508,\n",
       "                      0.5494369771275383, 1.0, 0.5918273078858426,\n",
       "                      0.608887766563851, 0.5978395437331077,\n",
       "                      0.6040001789618271, 0.8224983929326299, 0.5,\n",
       "                      0.7319015248142358, 0.5, 0.5, 0.9701911127551537, 0.5,\n",
       "                      0.5, 0.5, 0.5, 0.5007232322168101, 0.9495968117006099,\n",
       "                      0.5263814497514758, 0.5694413101740193,\n",
       "                      0.723226860434972, 0.6697010314498838, 0.5,\n",
       "                      0.8399968249028467, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                      0.7276147634418255, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                      1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5,\n",
       "                      0.5, 1.0, 0.5, 0.9426618146192435, 1.0, 0.5, 1.0, 1.0,\n",
       "                      0.7327978832817351, 0.5, 0.5, 0.7272057454468276, 1.0,\n",
       "                      1.0, 0.5, 0.722172192797577, 0.5, 0.7467555456720641,\n",
       "                      0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.7634355677431282, 1.0,\n",
       "                      0.5, 0.7213088905100546, 0.5, 0.5097466354757849,\n",
       "                      0.5020694803375102, 1.0, 1.0, 0.5, 0.5140598674041665,\n",
       "                      1.0, 0.7392350355401398, 0.6938839605264809,\n",
       "                      0.6587109527343454, 0.5588232543804782, 0.5,\n",
       "                      0.8941674821965382],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_learning_rate': masked_array(data=[0.08314149149079444, 0.21972204394324293,\n",
       "                      0.032032745103304144, 0.049449776216282514,\n",
       "                      0.1190177982450834, 0.12115201170479983,\n",
       "                      0.04271271661426047, 0.11645353510171558,\n",
       "                      0.1486172413028015, 0.024356781908842783,\n",
       "                      0.2401494673311723, 0.012318800654625175,\n",
       "                      0.07112452805775092, 0.21599918969665383,\n",
       "                      0.015707669158091166, 0.2674260462575013,\n",
       "                      0.05089906482119187, 0.02441809989966988,\n",
       "                      0.01542454766520675, 0.12364029542225896,\n",
       "                      0.10445058792790128, 0.04122357224708655,\n",
       "                      0.04183597282721872, 0.033014457474377604,\n",
       "                      0.29999999999999993, 0.06343434718788815,\n",
       "                      0.12553591064581016, 0.11705546355786939,\n",
       "                      0.033227125732213106, 0.29999999999999993,\n",
       "                      0.07818856301885409, 0.07358645808440814,\n",
       "                      0.04483446385807818, 0.16861600003402072,\n",
       "                      0.04017325250077454, 0.04128478135331031,\n",
       "                      0.06854283431859318, 0.09499580635601686,\n",
       "                      0.29999999999999993, 0.07578805476646036,\n",
       "                      0.12517666943119937, 0.29999999999999993,\n",
       "                      0.29999999999999993, 0.034329663047473015,\n",
       "                      0.29999999999999993, 0.054190067328569486,\n",
       "                      0.08809122298423301, 0.061285600915627174, 0.01,\n",
       "                      0.09926418039739486, 0.01878940876591552, 0.01,\n",
       "                      0.03462588413383409, 0.05023714292247402,\n",
       "                      0.057845313391782574, 0.03127269531404244,\n",
       "                      0.032735071660325944, 0.033052817131465566,\n",
       "                      0.1904418246210875, 0.29999999999999993,\n",
       "                      0.028522587898938412, 0.03787707350211597,\n",
       "                      0.29999999999999993, 0.29999999999999993,\n",
       "                      0.04157440064482507, 0.01, 0.047313058629263494,\n",
       "                      0.08859351030996918, 0.05639550304354074,\n",
       "                      0.06584901735758429, 0.06316197356512364, 0.01,\n",
       "                      0.04458958559333021, 0.1197776089601163,\n",
       "                      0.04714049770462612, 0.07012921659161192,\n",
       "                      0.07005267705003174, 0.01, 0.29999999999999993,\n",
       "                      0.05355348349794165, 0.01, 0.027466335147272206,\n",
       "                      0.29999999999999993, 0.052174562007203946,\n",
       "                      0.29999999999999993, 0.11793423693158603,\n",
       "                      0.29999999999999993, 0.07296690094920716,\n",
       "                      0.28823019205862344, 0.29999999999999993,\n",
       "                      0.29999999999999993, 0.01, 0.08872895944943734,\n",
       "                      0.29999999999999993, 0.12582795184170764,\n",
       "                      0.10594291719692726, 0.07108124772843037,\n",
       "                      0.010221696757043843, 0.024702773864231718,\n",
       "                      0.10912752207504794],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_max_depth': masked_array(data=[14, 13, 6, 11, 8, 11, 6, 3, 19, 17, 13, 19, 11, 16, 5,\n",
       "                      15, 14, 17, 3, 20, 20, 20, 11, 20, 3, 3, 8, 11, 20, 7,\n",
       "                      20, 8, 11, 5, 20, 7, 7, 3, 3, 20, 20, 20, 16, 12, 3, 3,\n",
       "                      20, 20, 19, 12, 3, 20, 20, 20, 20, 17, 20, 20, 20, 20,\n",
       "                      3, 12, 20, 3, 20, 20, 20, 20, 20, 20, 16, 3, 20, 12, 8,\n",
       "                      11, 11, 20, 20, 11, 20, 12, 20, 3, 20, 15, 20, 5, 3, 3,\n",
       "                      3, 14, 3, 10, 15, 15, 13, 19, 13, 15],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_min_child_samples': masked_array(data=[87, 30, 28, 83, 22, 37, 28, 10, 48, 12, 40, 86, 31, 37,\n",
       "                      75, 5, 52, 5, 34, 5, 60, 10, 9, 26, 100, 22, 5, 8, 37,\n",
       "                      57, 11, 30, 62, 100, 32, 12, 8, 5, 35, 5, 5, 13, 76,\n",
       "                      33, 95, 94, 5, 21, 5, 100, 39, 5, 5, 5, 5, 81, 10, 5,\n",
       "                      5, 100, 100, 43, 15, 69, 5, 14, 5, 52, 49, 100, 43, 74,\n",
       "                      100, 54, 100, 5, 100, 100, 65, 78, 63, 5, 85, 100, 100,\n",
       "                      100, 18, 23, 99, 100, 72, 23, 17, 6, 100, 100, 100, 12,\n",
       "                      100, 100],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_n_estimators': masked_array(data=[983, 247, 408, 711, 328, 352, 871, 316, 588, 769, 100,\n",
       "                      1000, 659, 436, 179, 473, 668, 304, 601, 515, 437, 198,\n",
       "                      1000, 1000, 1000, 100, 382, 1000, 1000, 265, 828, 901,\n",
       "                      833, 831, 490, 1000, 1000, 1000, 1000, 763, 973, 239,\n",
       "                      708, 1000, 567, 1000, 1000, 1000, 900, 776, 1000, 100,\n",
       "                      431, 867, 371, 1000, 571, 690, 320, 100, 699, 424, 944,\n",
       "                      100, 1000, 801, 929, 783, 474, 900, 813, 1000, 837,\n",
       "                      362, 538, 891, 887, 1000, 1000, 436, 825, 857, 762,\n",
       "                      1000, 100, 867, 812, 336, 443, 1000, 100, 1000, 487,\n",
       "                      712, 848, 874, 1000, 532, 475, 834],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_num_leaves': masked_array(data=[60, 311, 260, 340, 16, 341, 185, 62, 155, 296, 23, 348,\n",
       "                      142, 387, 10, 10, 10, 10, 400, 10, 10, 163, 10, 400,\n",
       "                      10, 10, 10, 10, 10, 10, 10, 400, 10, 10, 10, 269, 10,\n",
       "                      10, 400, 110, 10, 10, 10, 184, 10, 400, 400, 10, 10,\n",
       "                      10, 235, 400, 10, 10, 10, 10, 400, 400, 10, 10, 10,\n",
       "                      398, 10, 400, 400, 10, 10, 400, 400, 10, 10, 10, 400,\n",
       "                      10, 400, 10, 253, 400, 10, 175, 400, 400, 10, 10, 400,\n",
       "                      10, 400, 385, 389, 10, 10, 400, 353, 10, 10, 10, 10,\n",
       "                      366, 400, 10],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [OrderedDict([('bagging_fraction', 0.7654820824760737),\n",
       "                 ('feature_fraction', 0.8380397544384568),\n",
       "                 ('learning_rate', 0.08314149149079444),\n",
       "                 ('max_depth', 14),\n",
       "                 ('min_child_samples', 87),\n",
       "                 ('n_estimators', 983),\n",
       "                 ('num_leaves', 60)]),\n",
       "    OrderedDict([('bagging_fraction', 0.629185830986374),\n",
       "                 ('feature_fraction', 0.9894518292131809),\n",
       "                 ('learning_rate', 0.21972204394324293),\n",
       "                 ('max_depth', 13),\n",
       "                 ('min_child_samples', 30),\n",
       "                 ('n_estimators', 247),\n",
       "                 ('num_leaves', 311)]),\n",
       "    OrderedDict([('bagging_fraction', 0.7643458710377254),\n",
       "                 ('feature_fraction', 0.5289489218467651),\n",
       "                 ('learning_rate', 0.032032745103304144),\n",
       "                 ('max_depth', 6),\n",
       "                 ('min_child_samples', 28),\n",
       "                 ('n_estimators', 408),\n",
       "                 ('num_leaves', 260)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5737099059755859),\n",
       "                 ('feature_fraction', 0.8916331353364969),\n",
       "                 ('learning_rate', 0.049449776216282514),\n",
       "                 ('max_depth', 11),\n",
       "                 ('min_child_samples', 83),\n",
       "                 ('n_estimators', 711),\n",
       "                 ('num_leaves', 340)]),\n",
       "    OrderedDict([('bagging_fraction', 0.6162570141151325),\n",
       "                 ('feature_fraction', 0.6216679677341995),\n",
       "                 ('learning_rate', 0.1190177982450834),\n",
       "                 ('max_depth', 8),\n",
       "                 ('min_child_samples', 22),\n",
       "                 ('n_estimators', 328),\n",
       "                 ('num_leaves', 16)]),\n",
       "    OrderedDict([('bagging_fraction', 0.9190831912766004),\n",
       "                 ('feature_fraction', 0.9956120269464492),\n",
       "                 ('learning_rate', 0.12115201170479983),\n",
       "                 ('max_depth', 11),\n",
       "                 ('min_child_samples', 37),\n",
       "                 ('n_estimators', 352),\n",
       "                 ('num_leaves', 341)]),\n",
       "    OrderedDict([('bagging_fraction', 0.9835656124421499),\n",
       "                 ('feature_fraction', 0.8782764530210248),\n",
       "                 ('learning_rate', 0.04271271661426047),\n",
       "                 ('max_depth', 6),\n",
       "                 ('min_child_samples', 28),\n",
       "                 ('n_estimators', 871),\n",
       "                 ('num_leaves', 185)]),\n",
       "    OrderedDict([('bagging_fraction', 0.7552445232092422),\n",
       "                 ('feature_fraction', 0.7634895156575092),\n",
       "                 ('learning_rate', 0.11645353510171558),\n",
       "                 ('max_depth', 3),\n",
       "                 ('min_child_samples', 10),\n",
       "                 ('n_estimators', 316),\n",
       "                 ('num_leaves', 62)]),\n",
       "    OrderedDict([('bagging_fraction', 0.546027248452608),\n",
       "                 ('feature_fraction', 0.9480863089293394),\n",
       "                 ('learning_rate', 0.1486172413028015),\n",
       "                 ('max_depth', 19),\n",
       "                 ('min_child_samples', 48),\n",
       "                 ('n_estimators', 588),\n",
       "                 ('num_leaves', 155)]),\n",
       "    OrderedDict([('bagging_fraction', 0.6847684887002612),\n",
       "                 ('feature_fraction', 0.7200918168694508),\n",
       "                 ('learning_rate', 0.024356781908842783),\n",
       "                 ('max_depth', 17),\n",
       "                 ('min_child_samples', 12),\n",
       "                 ('n_estimators', 769),\n",
       "                 ('num_leaves', 296)]),\n",
       "    OrderedDict([('bagging_fraction', 0.7702157793924279),\n",
       "                 ('feature_fraction', 0.5494369771275383),\n",
       "                 ('learning_rate', 0.2401494673311723),\n",
       "                 ('max_depth', 13),\n",
       "                 ('min_child_samples', 40),\n",
       "                 ('n_estimators', 100),\n",
       "                 ('num_leaves', 23)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5581635896410128),\n",
       "                 ('feature_fraction', 1.0),\n",
       "                 ('learning_rate', 0.012318800654625175),\n",
       "                 ('max_depth', 19),\n",
       "                 ('min_child_samples', 86),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 348)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 0.5918273078858426),\n",
       "                 ('learning_rate', 0.07112452805775092),\n",
       "                 ('max_depth', 11),\n",
       "                 ('min_child_samples', 31),\n",
       "                 ('n_estimators', 659),\n",
       "                 ('num_leaves', 142)]),\n",
       "    OrderedDict([('bagging_fraction', 1.0),\n",
       "                 ('feature_fraction', 0.608887766563851),\n",
       "                 ('learning_rate', 0.21599918969665383),\n",
       "                 ('max_depth', 16),\n",
       "                 ('min_child_samples', 37),\n",
       "                 ('n_estimators', 436),\n",
       "                 ('num_leaves', 387)]),\n",
       "    OrderedDict([('bagging_fraction', 0.695388745250626),\n",
       "                 ('feature_fraction', 0.5978395437331077),\n",
       "                 ('learning_rate', 0.015707669158091166),\n",
       "                 ('max_depth', 5),\n",
       "                 ('min_child_samples', 75),\n",
       "                 ('n_estimators', 179),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.6010607512842553),\n",
       "                 ('feature_fraction', 0.6040001789618271),\n",
       "                 ('learning_rate', 0.2674260462575013),\n",
       "                 ('max_depth', 15),\n",
       "                 ('min_child_samples', 5),\n",
       "                 ('n_estimators', 473),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.8109525010758685),\n",
       "                 ('feature_fraction', 0.8224983929326299),\n",
       "                 ('learning_rate', 0.05089906482119187),\n",
       "                 ('max_depth', 14),\n",
       "                 ('min_child_samples', 52),\n",
       "                 ('n_estimators', 668),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5413766773266244),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.02441809989966988),\n",
       "                 ('max_depth', 17),\n",
       "                 ('min_child_samples', 5),\n",
       "                 ('n_estimators', 304),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.9687211934001123),\n",
       "                 ('feature_fraction', 0.7319015248142358),\n",
       "                 ('learning_rate', 0.01542454766520675),\n",
       "                 ('max_depth', 3),\n",
       "                 ('min_child_samples', 34),\n",
       "                 ('n_estimators', 601),\n",
       "                 ('num_leaves', 400)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.12364029542225896),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 5),\n",
       "                 ('n_estimators', 515),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.10445058792790128),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 60),\n",
       "                 ('n_estimators', 437),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.7988240732519352),\n",
       "                 ('feature_fraction', 0.9701911127551537),\n",
       "                 ('learning_rate', 0.04122357224708655),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 10),\n",
       "                 ('n_estimators', 198),\n",
       "                 ('num_leaves', 163)]),\n",
       "    OrderedDict([('bagging_fraction', 0.7043591453544604),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.04183597282721872),\n",
       "                 ('max_depth', 11),\n",
       "                 ('min_child_samples', 9),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.8284635523142878),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.033014457474377604),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 26),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 400)]),\n",
       "    OrderedDict([('bagging_fraction', 1.0),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 3),\n",
       "                 ('min_child_samples', 100),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 1.0),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.06343434718788815),\n",
       "                 ('max_depth', 3),\n",
       "                 ('min_child_samples', 22),\n",
       "                 ('n_estimators', 100),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5233668230146984),\n",
       "                 ('feature_fraction', 0.5007232322168101),\n",
       "                 ('learning_rate', 0.12553591064581016),\n",
       "                 ('max_depth', 8),\n",
       "                 ('min_child_samples', 5),\n",
       "                 ('n_estimators', 382),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.9642100459094738),\n",
       "                 ('feature_fraction', 0.9495968117006099),\n",
       "                 ('learning_rate', 0.11705546355786939),\n",
       "                 ('max_depth', 11),\n",
       "                 ('min_child_samples', 8),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.6624357179010059),\n",
       "                 ('feature_fraction', 0.5263814497514758),\n",
       "                 ('learning_rate', 0.033227125732213106),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 37),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5051280271051379),\n",
       "                 ('feature_fraction', 0.5694413101740193),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 7),\n",
       "                 ('min_child_samples', 57),\n",
       "                 ('n_estimators', 265),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.7954806102031173),\n",
       "                 ('feature_fraction', 0.723226860434972),\n",
       "                 ('learning_rate', 0.07818856301885409),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 11),\n",
       "                 ('n_estimators', 828),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.8489173577194873),\n",
       "                 ('feature_fraction', 0.6697010314498838),\n",
       "                 ('learning_rate', 0.07358645808440814),\n",
       "                 ('max_depth', 8),\n",
       "                 ('min_child_samples', 30),\n",
       "                 ('n_estimators', 901),\n",
       "                 ('num_leaves', 400)]),\n",
       "    OrderedDict([('bagging_fraction', 0.991501942286271),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.04483446385807818),\n",
       "                 ('max_depth', 11),\n",
       "                 ('min_child_samples', 62),\n",
       "                 ('n_estimators', 833),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.6249500138684704),\n",
       "                 ('feature_fraction', 0.8399968249028467),\n",
       "                 ('learning_rate', 0.16861600003402072),\n",
       "                 ('max_depth', 5),\n",
       "                 ('min_child_samples', 100),\n",
       "                 ('n_estimators', 831),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.9091900732331768),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.04017325250077454),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 32),\n",
       "                 ('n_estimators', 490),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.7199533731256063),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.04128478135331031),\n",
       "                 ('max_depth', 7),\n",
       "                 ('min_child_samples', 12),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 269)]),\n",
       "    OrderedDict([('bagging_fraction', 0.7728216607363545),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.06854283431859318),\n",
       "                 ('max_depth', 7),\n",
       "                 ('min_child_samples', 8),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.6437844134547452),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.09499580635601686),\n",
       "                 ('max_depth', 3),\n",
       "                 ('min_child_samples', 5),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5899544838425143),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 3),\n",
       "                 ('min_child_samples', 35),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 400)]),\n",
       "    OrderedDict([('bagging_fraction', 1.0),\n",
       "                 ('feature_fraction', 0.7276147634418255),\n",
       "                 ('learning_rate', 0.07578805476646036),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 5),\n",
       "                 ('n_estimators', 763),\n",
       "                 ('num_leaves', 110)]),\n",
       "    OrderedDict([('bagging_fraction', 0.7382668290280634),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.12517666943119937),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 5),\n",
       "                 ('n_estimators', 973),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.9398644747208972),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 13),\n",
       "                 ('n_estimators', 239),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5345692040165404),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 16),\n",
       "                 ('min_child_samples', 76),\n",
       "                 ('n_estimators', 708),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 1.0),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.034329663047473015),\n",
       "                 ('max_depth', 12),\n",
       "                 ('min_child_samples', 33),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 184)]),\n",
       "    OrderedDict([('bagging_fraction', 0.9698399160129514),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 3),\n",
       "                 ('min_child_samples', 95),\n",
       "                 ('n_estimators', 567),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.9856124647994302),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.054190067328569486),\n",
       "                 ('max_depth', 3),\n",
       "                 ('min_child_samples', 94),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 400)]),\n",
       "    OrderedDict([('bagging_fraction', 0.6389064676271512),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.08809122298423301),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 5),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 400)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 1.0),\n",
       "                 ('learning_rate', 0.061285600915627174),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 21),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.8118929555283037),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.01),\n",
       "                 ('max_depth', 19),\n",
       "                 ('min_child_samples', 5),\n",
       "                 ('n_estimators', 900),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.09926418039739486),\n",
       "                 ('max_depth', 12),\n",
       "                 ('min_child_samples', 100),\n",
       "                 ('n_estimators', 776),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.7082843226968932),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.01878940876591552),\n",
       "                 ('max_depth', 3),\n",
       "                 ('min_child_samples', 39),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 235)]),\n",
       "    OrderedDict([('bagging_fraction', 1.0),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.01),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 5),\n",
       "                 ('n_estimators', 100),\n",
       "                 ('num_leaves', 400)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 1.0),\n",
       "                 ('learning_rate', 0.03462588413383409),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 5),\n",
       "                 ('n_estimators', 431),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.05023714292247402),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 5),\n",
       "                 ('n_estimators', 867),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.057845313391782574),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 5),\n",
       "                 ('n_estimators', 371),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 1.0),\n",
       "                 ('feature_fraction', 1.0),\n",
       "                 ('learning_rate', 0.03127269531404244),\n",
       "                 ('max_depth', 17),\n",
       "                 ('min_child_samples', 81),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.032735071660325944),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 10),\n",
       "                 ('n_estimators', 571),\n",
       "                 ('num_leaves', 400)]),\n",
       "    OrderedDict([('bagging_fraction', 1.0),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.033052817131465566),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 5),\n",
       "                 ('n_estimators', 690),\n",
       "                 ('num_leaves', 400)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.1904418246210875),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 5),\n",
       "                 ('n_estimators', 320),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 1.0),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 100),\n",
       "                 ('n_estimators', 100),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.028522587898938412),\n",
       "                 ('max_depth', 3),\n",
       "                 ('min_child_samples', 100),\n",
       "                 ('n_estimators', 699),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.7065451482709622),\n",
       "                 ('feature_fraction', 0.9426618146192435),\n",
       "                 ('learning_rate', 0.03787707350211597),\n",
       "                 ('max_depth', 12),\n",
       "                 ('min_child_samples', 43),\n",
       "                 ('n_estimators', 424),\n",
       "                 ('num_leaves', 398)]),\n",
       "    OrderedDict([('bagging_fraction', 0.7388928029926499),\n",
       "                 ('feature_fraction', 1.0),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 15),\n",
       "                 ('n_estimators', 944),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5276954526883374),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 3),\n",
       "                 ('min_child_samples', 69),\n",
       "                 ('n_estimators', 100),\n",
       "                 ('num_leaves', 400)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 1.0),\n",
       "                 ('learning_rate', 0.04157440064482507),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 5),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 400)]),\n",
       "    OrderedDict([('bagging_fraction', 0.6189633097648055),\n",
       "                 ('feature_fraction', 1.0),\n",
       "                 ('learning_rate', 0.01),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 14),\n",
       "                 ('n_estimators', 801),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.8778014457239963),\n",
       "                 ('feature_fraction', 0.7327978832817351),\n",
       "                 ('learning_rate', 0.047313058629263494),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 5),\n",
       "                 ('n_estimators', 929),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.9756908253050366),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.08859351030996918),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 52),\n",
       "                 ('n_estimators', 783),\n",
       "                 ('num_leaves', 400)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.05639550304354074),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 49),\n",
       "                 ('n_estimators', 474),\n",
       "                 ('num_leaves', 400)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5602471751326271),\n",
       "                 ('feature_fraction', 0.7272057454468276),\n",
       "                 ('learning_rate', 0.06584901735758429),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 100),\n",
       "                 ('n_estimators', 900),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.9829546076664571),\n",
       "                 ('feature_fraction', 1.0),\n",
       "                 ('learning_rate', 0.06316197356512364),\n",
       "                 ('max_depth', 16),\n",
       "                 ('min_child_samples', 43),\n",
       "                 ('n_estimators', 813),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 1.0),\n",
       "                 ('feature_fraction', 1.0),\n",
       "                 ('learning_rate', 0.01),\n",
       "                 ('max_depth', 3),\n",
       "                 ('min_child_samples', 74),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.04458958559333021),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 100),\n",
       "                 ('n_estimators', 837),\n",
       "                 ('num_leaves', 400)]),\n",
       "    OrderedDict([('bagging_fraction', 0.9457936447726392),\n",
       "                 ('feature_fraction', 0.722172192797577),\n",
       "                 ('learning_rate', 0.1197776089601163),\n",
       "                 ('max_depth', 12),\n",
       "                 ('min_child_samples', 54),\n",
       "                 ('n_estimators', 362),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5251181027794909),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.04714049770462612),\n",
       "                 ('max_depth', 8),\n",
       "                 ('min_child_samples', 100),\n",
       "                 ('n_estimators', 538),\n",
       "                 ('num_leaves', 400)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 0.7467555456720641),\n",
       "                 ('learning_rate', 0.07012921659161192),\n",
       "                 ('max_depth', 11),\n",
       "                 ('min_child_samples', 5),\n",
       "                 ('n_estimators', 891),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 1.0),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.07005267705003174),\n",
       "                 ('max_depth', 11),\n",
       "                 ('min_child_samples', 100),\n",
       "                 ('n_estimators', 887),\n",
       "                 ('num_leaves', 253)]),\n",
       "    OrderedDict([('bagging_fraction', 1.0),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.01),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 100),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 400)]),\n",
       "    OrderedDict([('bagging_fraction', 0.8795321843941388),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 65),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 1.0),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.05355348349794165),\n",
       "                 ('max_depth', 11),\n",
       "                 ('min_child_samples', 78),\n",
       "                 ('n_estimators', 436),\n",
       "                 ('num_leaves', 175)]),\n",
       "    OrderedDict([('bagging_fraction', 0.515401886946663),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.01),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 63),\n",
       "                 ('n_estimators', 825),\n",
       "                 ('num_leaves', 400)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.027466335147272206),\n",
       "                 ('max_depth', 12),\n",
       "                 ('min_child_samples', 5),\n",
       "                 ('n_estimators', 857),\n",
       "                 ('num_leaves', 400)]),\n",
       "    OrderedDict([('bagging_fraction', 0.7702835112979058),\n",
       "                 ('feature_fraction', 0.7634355677431282),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 85),\n",
       "                 ('n_estimators', 762),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 1.0),\n",
       "                 ('learning_rate', 0.052174562007203946),\n",
       "                 ('max_depth', 3),\n",
       "                 ('min_child_samples', 100),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 100),\n",
       "                 ('n_estimators', 100),\n",
       "                 ('num_leaves', 400)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 0.7213088905100546),\n",
       "                 ('learning_rate', 0.11793423693158603),\n",
       "                 ('max_depth', 15),\n",
       "                 ('min_child_samples', 100),\n",
       "                 ('n_estimators', 867),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 20),\n",
       "                 ('min_child_samples', 18),\n",
       "                 ('n_estimators', 812),\n",
       "                 ('num_leaves', 400)]),\n",
       "    OrderedDict([('bagging_fraction', 0.7602844043654979),\n",
       "                 ('feature_fraction', 0.5097466354757849),\n",
       "                 ('learning_rate', 0.07296690094920716),\n",
       "                 ('max_depth', 5),\n",
       "                 ('min_child_samples', 23),\n",
       "                 ('n_estimators', 336),\n",
       "                 ('num_leaves', 385)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5540885426228469),\n",
       "                 ('feature_fraction', 0.5020694803375102),\n",
       "                 ('learning_rate', 0.28823019205862344),\n",
       "                 ('max_depth', 3),\n",
       "                 ('min_child_samples', 99),\n",
       "                 ('n_estimators', 443),\n",
       "                 ('num_leaves', 389)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 1.0),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 3),\n",
       "                 ('min_child_samples', 100),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.8350281884426594),\n",
       "                 ('feature_fraction', 1.0),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 3),\n",
       "                 ('min_child_samples', 72),\n",
       "                 ('n_estimators', 100),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.01),\n",
       "                 ('max_depth', 14),\n",
       "                 ('min_child_samples', 23),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 400)]),\n",
       "    OrderedDict([('bagging_fraction', 0.629442121161646),\n",
       "                 ('feature_fraction', 0.5140598674041665),\n",
       "                 ('learning_rate', 0.08872895944943734),\n",
       "                 ('max_depth', 3),\n",
       "                 ('min_child_samples', 17),\n",
       "                 ('n_estimators', 487),\n",
       "                 ('num_leaves', 353)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 1.0),\n",
       "                 ('learning_rate', 0.29999999999999993),\n",
       "                 ('max_depth', 10),\n",
       "                 ('min_child_samples', 6),\n",
       "                 ('n_estimators', 712),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 0.7392350355401398),\n",
       "                 ('learning_rate', 0.12582795184170764),\n",
       "                 ('max_depth', 15),\n",
       "                 ('min_child_samples', 100),\n",
       "                 ('n_estimators', 848),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 1.0),\n",
       "                 ('feature_fraction', 0.6938839605264809),\n",
       "                 ('learning_rate', 0.10594291719692726),\n",
       "                 ('max_depth', 15),\n",
       "                 ('min_child_samples', 100),\n",
       "                 ('n_estimators', 874),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 0.6587109527343454),\n",
       "                 ('learning_rate', 0.07108124772843037),\n",
       "                 ('max_depth', 13),\n",
       "                 ('min_child_samples', 100),\n",
       "                 ('n_estimators', 1000),\n",
       "                 ('num_leaves', 10)]),\n",
       "    OrderedDict([('bagging_fraction', 0.530056102176457),\n",
       "                 ('feature_fraction', 0.5588232543804782),\n",
       "                 ('learning_rate', 0.010221696757043843),\n",
       "                 ('max_depth', 19),\n",
       "                 ('min_child_samples', 12),\n",
       "                 ('n_estimators', 532),\n",
       "                 ('num_leaves', 366)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5879342643769147),\n",
       "                 ('feature_fraction', 0.5),\n",
       "                 ('learning_rate', 0.024702773864231718),\n",
       "                 ('max_depth', 13),\n",
       "                 ('min_child_samples', 100),\n",
       "                 ('n_estimators', 475),\n",
       "                 ('num_leaves', 400)]),\n",
       "    OrderedDict([('bagging_fraction', 0.5),\n",
       "                 ('feature_fraction', 0.8941674821965382),\n",
       "                 ('learning_rate', 0.10912752207504794),\n",
       "                 ('max_depth', 15),\n",
       "                 ('min_child_samples', 100),\n",
       "                 ('n_estimators', 834),\n",
       "                 ('num_leaves', 10)])],\n",
       "   'split0_test_score': array([-0.35532838, -0.3681756 , -0.35831521, -0.36301749, -0.36095552,\n",
       "          -0.38736123, -0.35997487, -0.37474423, -0.3582998 , -0.349813  ,\n",
       "          -0.37500879, -0.38197534, -0.33626783, -0.35351797, -0.47724451,\n",
       "          -0.3748064 , -0.36189092, -0.39943533, -0.40335918, -0.39877536,\n",
       "          -0.33555127, -0.37205106, -0.34782651, -0.34256261, -0.37922444,\n",
       "          -0.43286884, -0.36759988, -0.37474134, -0.36588181, -0.37117577,\n",
       "          -0.35585185, -0.35431979, -0.35273943, -0.36652607, -0.37118801,\n",
       "          -0.34871541, -0.33488706, -0.37380436, -0.3326123 , -0.37046204,\n",
       "          -0.36231398, -0.35331845, -0.38061595, -0.34086921, -0.4069896 ,\n",
       "          -0.34968775, -0.33915194, -0.36268576, -0.39237823, -0.33674124,\n",
       "          -0.37231321, -0.50183129, -0.37728265, -0.34885369, -0.35848408,\n",
       "          -0.3709272 , -0.3366049 , -0.3457307 , -0.34999604, -0.3571833 ,\n",
       "          -0.37898597, -0.37359267, -0.39716653, -0.34298833, -0.36859961,\n",
       "          -0.401793  , -0.37852538, -0.34164072, -0.35935313, -0.37085571,\n",
       "          -0.36589317, -0.39096816, -0.35728795, -0.37231693, -0.36605414,\n",
       "          -0.38817508, -0.35467953, -0.34433389, -0.37571846, -0.35499503,\n",
       "          -0.34163649, -0.3427016 , -0.35006093, -0.33719894, -0.36098801,\n",
       "          -0.37331637, -0.39485288, -0.35788514, -0.37905551, -0.38443306,\n",
       "          -0.35506163, -0.34102938, -0.36873041, -0.37993644, -0.33922917,\n",
       "          -0.37962836, -0.36697027, -0.3497327 , -0.34708251, -0.35664852]),\n",
       "   'split1_test_score': array([-0.44308944, -0.52891692, -0.34768191, -0.46450386, -0.34832866,\n",
       "          -0.52304833, -0.37721367, -0.37239325, -0.48644358, -0.42720814,\n",
       "          -0.38046227, -0.48371658, -0.38746187, -0.41638312, -0.44966015,\n",
       "          -0.3428926 , -0.36622006, -0.38113729, -0.39878767, -0.34107703,\n",
       "          -0.3480775 , -0.48890406, -0.3478489 , -0.37602703, -0.36816628,\n",
       "          -0.4106399 , -0.34548897, -0.34777674, -0.35066468, -0.3079667 ,\n",
       "          -0.35668599, -0.38763567, -0.36219042, -0.36824078, -0.35612919,\n",
       "          -0.35275733, -0.33576748, -0.36412142, -0.42928839, -0.41483284,\n",
       "          -0.33261503, -0.3330305 , -0.33033991, -0.38620252, -0.32030915,\n",
       "          -0.33318101, -0.3774472 , -0.37878162, -0.36987117, -0.35750539,\n",
       "          -0.36473125, -0.50513905, -0.38328386, -0.34646656, -0.35651709,\n",
       "          -0.36481956, -0.38016927, -0.36330032, -0.34837563, -0.36356858,\n",
       "          -0.34948896, -0.49486689, -0.37136704, -0.38781193, -0.55586501,\n",
       "          -0.39534137, -0.33740158, -0.40225537, -0.39165224, -0.32882194,\n",
       "          -0.37000641, -0.39248402, -0.38358457, -0.36178447, -0.38230373,\n",
       "          -0.3528462 , -0.37729763, -0.37011177, -0.37946782, -0.43077099,\n",
       "          -0.36994215, -0.37820568, -0.38145657, -0.33719237, -0.3995702 ,\n",
       "          -0.32537163, -0.38614229, -0.34061701, -0.35039574, -0.35215136,\n",
       "          -0.33669204, -0.36938598, -0.33898936, -0.35826142, -0.33966013,\n",
       "          -0.32489627, -0.32777011, -0.39505258, -0.37232779, -0.35272737]),\n",
       "   'split2_test_score': array([-0.24823103, -0.30606331, -0.25820568, -0.24003719, -0.28141598,\n",
       "          -0.3037215 , -0.25942344, -0.29616481, -0.28332783, -0.26918341,\n",
       "          -0.27642281, -0.25289815, -0.25894375, -0.28234558, -0.39728814,\n",
       "          -0.28385945, -0.26981466, -0.32148652, -0.34060092, -0.26523025,\n",
       "          -0.28279568, -0.29045151, -0.28037648, -0.25753959, -0.30460536,\n",
       "          -0.36321721, -0.25902711, -0.25843326, -0.28448242, -0.29467018,\n",
       "          -0.26344064, -0.26375719, -0.27203952, -0.27423578, -0.30476158,\n",
       "          -0.24906107, -0.2693731 , -0.29712499, -0.29519295, -0.25586219,\n",
       "          -0.25762556, -0.28144684, -0.26746843, -0.25358156, -0.27514257,\n",
       "          -0.29654248, -0.25738692, -0.26687038, -0.31251321, -0.25216375,\n",
       "          -0.32655699, -0.46413515, -0.29939941, -0.28481832, -0.28624327,\n",
       "          -0.27274615, -0.26086341, -0.25457759, -0.26682763, -0.30748314,\n",
       "          -0.32135378, -0.2828626 , -0.25431329, -0.31485733, -0.31928005,\n",
       "          -0.32624866, -0.28499079, -0.25977795, -0.25905651, -0.26403784,\n",
       "          -0.26480417, -0.33020334, -0.26528229, -0.27103209, -0.24700618,\n",
       "          -0.25915853, -0.26250825, -0.25570542, -0.26050882, -0.25972473,\n",
       "          -0.25549346, -0.25553185, -0.28083665, -0.27997372, -0.27939989,\n",
       "          -0.23713293, -0.28660978, -0.29229324, -0.2766423 , -0.28314415,\n",
       "          -0.30398701, -0.25212176, -0.31963646, -0.25706092, -0.26323442,\n",
       "          -0.26298584, -0.25610351, -0.2658483 , -0.25423319, -0.26008496]),\n",
       "   'split3_test_score': array([-0.28636794, -0.32034147, -0.30048374, -0.3318817 , -0.29334026,\n",
       "          -0.33889319, -0.29830789, -0.34156561, -0.34171487, -0.2867381 ,\n",
       "          -0.35161078, -0.32826917, -0.30291357, -0.30460036, -0.40690327,\n",
       "          -0.30054076, -0.31468608, -0.3588677 , -0.36775174, -0.33308357,\n",
       "          -0.33540482, -0.3311783 , -0.31905973, -0.28988907, -0.34453234,\n",
       "          -0.37267614, -0.3243193 , -0.32492989, -0.32769511, -0.31566121,\n",
       "          -0.31638386, -0.28166561, -0.32311438, -0.32019665, -0.33070028,\n",
       "          -0.29907591, -0.33866589, -0.34129165, -0.34915985, -0.29899644,\n",
       "          -0.32461204, -0.29641728, -0.29977233, -0.2870806 , -0.35165403,\n",
       "          -0.33412121, -0.29885007, -0.30311481, -0.34459235, -0.31833429,\n",
       "          -0.35562603, -0.41992744, -0.32251275, -0.32627899, -0.33907502,\n",
       "          -0.31776792, -0.28783626, -0.29209231, -0.35591773, -0.33920637,\n",
       "          -0.35119555, -0.32693031, -0.3200613 , -0.3583213 , -0.35857234,\n",
       "          -0.33335428, -0.310199  , -0.31032734, -0.30181185, -0.31911435,\n",
       "          -0.30804662, -0.36246542, -0.3064397 , -0.32061223, -0.31579637,\n",
       "          -0.30443907, -0.3185171 , -0.28893819, -0.35364344, -0.29188381,\n",
       "          -0.2956838 , -0.29146442, -0.30247799, -0.35123181, -0.31100343,\n",
       "          -0.308307  , -0.35498023, -0.29493122, -0.35936042, -0.34623773,\n",
       "          -0.33991087, -0.29677314, -0.34287741, -0.33490991, -0.3038909 ,\n",
       "          -0.32045448, -0.31852552, -0.2844471 , -0.30102268, -0.31481645]),\n",
       "   'split4_test_score': array([-0.30585179, -0.38718014, -0.36032238, -0.33934031, -0.3201711 ,\n",
       "          -0.3890419 , -0.32641907, -0.39492905, -0.36308352, -0.35930606,\n",
       "          -0.32268176, -0.34209588, -0.34171744, -0.34749418, -0.49397272,\n",
       "          -0.36396539, -0.333763  , -0.36857619, -0.38686058, -0.35021772,\n",
       "          -0.3573635 , -0.36426197, -0.34574027, -0.373857  , -0.40323412,\n",
       "          -0.42916801, -0.34555872, -0.33214102, -0.34451667, -0.35612015,\n",
       "          -0.32088163, -0.34766927, -0.34548892, -0.36556012, -0.35434364,\n",
       "          -0.37569784, -0.3360961 , -0.36078084, -0.38998256, -0.3510538 ,\n",
       "          -0.36570148, -0.43591938, -0.3419213 , -0.36076091, -0.41057765,\n",
       "          -0.38044205, -0.39921775, -0.33819397, -0.37070091, -0.34537743,\n",
       "          -0.37673839, -0.61338363, -0.35254877, -0.35779778, -0.3590151 ,\n",
       "          -0.34247062, -0.38698398, -0.38646904, -0.34718244, -0.33184926,\n",
       "          -0.38971597, -0.37544765, -0.34405931, -0.39922176, -0.41167403,\n",
       "          -0.36337976, -0.34073909, -0.35755129, -0.37779055, -0.34017063,\n",
       "          -0.33654338, -0.38244613, -0.36951812, -0.34918443, -0.36397005,\n",
       "          -0.34617488, -0.37351269, -0.36529467, -0.36278163, -0.34703696,\n",
       "          -0.37676364, -0.38694402, -0.36500641, -0.36904581, -0.4426455 ,\n",
       "          -0.32751228, -0.43552733, -0.34251578, -0.39263444, -0.34410043,\n",
       "          -0.36542656, -0.36919755, -0.37292303, -0.34073237, -0.34868032,\n",
       "          -0.3340592 , -0.33137854, -0.38696664, -0.36943975, -0.34298865]),\n",
       "   'split5_test_score': array([-0.32622822, -0.31035113, -0.30969512, -0.32496381, -0.32967402,\n",
       "          -0.31532506, -0.31759008, -0.35640209, -0.31983007, -0.31368464,\n",
       "          -0.31684088, -0.31108584, -0.31336386, -0.34055418, -0.471225  ,\n",
       "          -0.31485925, -0.32802104, -0.35886669, -0.37428165, -0.32763668,\n",
       "          -0.31836926, -0.29404286, -0.34791644, -0.31579101, -0.34008593,\n",
       "          -0.40312701, -0.33191556, -0.32882814, -0.31548088, -0.32677459,\n",
       "          -0.33115328, -0.32879327, -0.30397288, -0.32882355, -0.3282915 ,\n",
       "          -0.32700448, -0.34514572, -0.3305583 , -0.32573476, -0.30953174,\n",
       "          -0.32120966, -0.32371666, -0.31820652, -0.32081197, -0.32067661,\n",
       "          -0.32633761, -0.33492198, -0.32135039, -0.34519241, -0.31656077,\n",
       "          -0.33065714, -0.56128416, -0.34492833, -0.34078521, -0.3449452 ,\n",
       "          -0.32757877, -0.32460586, -0.32561029, -0.36341595, -0.33638246,\n",
       "          -0.32812512, -0.30405467, -0.32824288, -0.34609506, -0.28803499,\n",
       "          -0.36346912, -0.32354291, -0.32538311, -0.31539268, -0.32760669,\n",
       "          -0.32364913, -0.37877445, -0.31995771, -0.32127188, -0.32688021,\n",
       "          -0.32574265, -0.32924395, -0.31435   , -0.35274586, -0.31593517,\n",
       "          -0.31657484, -0.32314597, -0.32483904, -0.34489763, -0.3700901 ,\n",
       "          -0.31116082, -0.33870372, -0.30523103, -0.30955986, -0.3402723 ,\n",
       "          -0.37721401, -0.31623475, -0.33024604, -0.33830149, -0.30436526,\n",
       "          -0.30799345, -0.31252506, -0.32402478, -0.31468599, -0.31380977]),\n",
       "   'split6_test_score': array([-0.40744595, -0.44981122, -0.39340609, -0.41709584, -0.34253173,\n",
       "          -0.44537646, -0.4076733 , -0.41182024, -0.41180483, -0.40159817,\n",
       "          -0.4138695 , -0.44391064, -0.42948884, -0.47441473, -0.46599758,\n",
       "          -0.36564281, -0.39804206, -0.41524157, -0.41377559, -0.4188103 ,\n",
       "          -0.40709302, -0.46069238, -0.38608928, -0.37105611, -0.37720792,\n",
       "          -0.43366374, -0.4235916 , -0.40378072, -0.39794156, -0.42662037,\n",
       "          -0.35728535, -0.35224846, -0.41452412, -0.39528527, -0.40805944,\n",
       "          -0.37579199, -0.37057802, -0.41879521, -0.41040974, -0.40640161,\n",
       "          -0.41335994, -0.33278874, -0.42378064, -0.40282101, -0.37689122,\n",
       "          -0.41759753, -0.42784341, -0.37904632, -0.41161558, -0.37145931,\n",
       "          -0.42251266, -0.51443499, -0.40776576, -0.39476756, -0.40479477,\n",
       "          -0.41647257, -0.36361792, -0.41269112, -0.46322239, -0.4163025 ,\n",
       "          -0.42103324, -0.44818956, -0.39090654, -0.4078571 , -0.4866778 ,\n",
       "          -0.41983502, -0.40370152, -0.37907711, -0.3996234 , -0.40965863,\n",
       "          -0.39535252, -0.40962018, -0.37525916, -0.40084303, -0.39808598,\n",
       "          -0.39272593, -0.37492204, -0.37671127, -0.36825313, -0.39575339,\n",
       "          -0.40573749, -0.40024265, -0.36502935, -0.39733962, -0.45752186,\n",
       "          -0.37931879, -0.39985855, -0.38783579, -0.3887067 , -0.38013975,\n",
       "          -0.43619213, -0.3861882 , -0.42719347, -0.38852495, -0.39790728,\n",
       "          -0.39127128, -0.39957624, -0.38513323, -0.37653185, -0.38107046]),\n",
       "   'split7_test_score': array([-0.3636468 , -0.45021265, -0.33044954, -0.388057  , -0.33100621,\n",
       "          -0.47804533, -0.38082154, -0.34676924, -0.42708829, -0.36431535,\n",
       "          -0.31234996, -0.43014436, -0.35204368, -0.37778451, -0.42775962,\n",
       "          -0.36985134, -0.34119018, -0.34112214, -0.34006602, -0.31136609,\n",
       "          -0.33692443, -0.43098251, -0.32838629, -0.31781901, -0.35288378,\n",
       "          -0.35274547, -0.31413024, -0.35615308, -0.33162159, -0.3351535 ,\n",
       "          -0.34260857, -0.36957814, -0.32518025, -0.35477378, -0.33998008,\n",
       "          -0.32904748, -0.32956666, -0.32757422, -0.36648386, -0.36934265,\n",
       "          -0.33807973, -0.347696  , -0.33511768, -0.31600598, -0.3203594 ,\n",
       "          -0.33181517, -0.3140403 , -0.35553766, -0.33390945, -0.3377014 ,\n",
       "          -0.33479231, -0.49139344, -0.33971488, -0.32820205, -0.34437904,\n",
       "          -0.34123087, -0.34021608, -0.3355207 , -0.33650426, -0.38187838,\n",
       "          -0.33653549, -0.45346047, -0.3659332 , -0.34991223, -0.51512354,\n",
       "          -0.35858642, -0.3425637 , -0.33307969, -0.31632014, -0.33897846,\n",
       "          -0.34345392, -0.34455248, -0.3209014 , -0.32411677, -0.31916738,\n",
       "          -0.34791905, -0.31217991, -0.31543649, -0.34948629, -0.32321244,\n",
       "          -0.31430967, -0.33533139, -0.32322543, -0.32191898, -0.34754617,\n",
       "          -0.32601659, -0.34685415, -0.32866508, -0.35454161, -0.35306875,\n",
       "          -0.33188466, -0.31466759, -0.33192298, -0.37569761, -0.35453453,\n",
       "          -0.33314072, -0.34264866, -0.33131227, -0.30876692, -0.33751061]),\n",
       "   'split8_test_score': array([-0.16265436, -0.21097551, -0.1943732 , -0.17770856, -0.20634511,\n",
       "          -0.20760506, -0.17530347, -0.22821667, -0.19267369, -0.18066057,\n",
       "          -0.20986627, -0.18044695, -0.20629547, -0.23720207, -0.36500743,\n",
       "          -0.22052938, -0.20591847, -0.23535411, -0.24262722, -0.20952285,\n",
       "          -0.20718546, -0.1870232 , -0.18816102, -0.20631595, -0.2243852 ,\n",
       "          -0.2857083 , -0.19442212, -0.19532085, -0.19978467, -0.18468695,\n",
       "          -0.19731765, -0.2036212 , -0.19582796, -0.2086791 , -0.20629201,\n",
       "          -0.18552572, -0.19627658, -0.21501111, -0.25228348, -0.1807758 ,\n",
       "          -0.19160818, -0.24655351, -0.20329227, -0.19477318, -0.23563173,\n",
       "          -0.22102449, -0.21290468, -0.20404785, -0.22508438, -0.2097988 ,\n",
       "          -0.21358774, -0.40849827, -0.21481822, -0.19300579, -0.21938199,\n",
       "          -0.20403328, -0.1922831 , -0.19720892, -0.20130898, -0.20894308,\n",
       "          -0.21782158, -0.19197536, -0.21716978, -0.23238998, -0.20901233,\n",
       "          -0.22146526, -0.19309091, -0.21081787, -0.20101081, -0.18064819,\n",
       "          -0.18325196, -0.2410854 , -0.18851334, -0.1973148 , -0.19162474,\n",
       "          -0.18818279, -0.18817164, -0.18872448, -0.20810052, -0.18791585,\n",
       "          -0.18837846, -0.19283821, -0.22163845, -0.22299012, -0.21882721,\n",
       "          -0.18599211, -0.27105325, -0.1964833 , -0.21474036, -0.23317182,\n",
       "          -0.22323122, -0.19764478, -0.21350692, -0.20147006, -0.1856729 ,\n",
       "          -0.18614258, -0.1870572 , -0.190826  , -0.18968311, -0.19714376]),\n",
       "   'split9_test_score': array([-0.26602977, -0.30068951, -0.29627191, -0.2705895 , -0.27923193,\n",
       "          -0.30483231, -0.27933852, -0.30438585, -0.29386386, -0.30250009,\n",
       "          -0.27192188, -0.26619983, -0.3173608 , -0.35476243, -0.38817419,\n",
       "          -0.26651977, -0.29787462, -0.33407884, -0.31999999, -0.30450635,\n",
       "          -0.29799768, -0.28209952, -0.2920925 , -0.33098552, -0.30169822,\n",
       "          -0.3682437 , -0.2767962 , -0.29245116, -0.28771602, -0.28884877,\n",
       "          -0.25441756, -0.29351076, -0.29360467, -0.28773367, -0.29660083,\n",
       "          -0.28029055, -0.26755154, -0.28890025, -0.27809225, -0.28331106,\n",
       "          -0.28993546, -0.27286922, -0.25176957, -0.32557367, -0.30834698,\n",
       "          -0.29750223, -0.28829658, -0.30487507, -0.32140504, -0.30178574,\n",
       "          -0.31491757, -0.46488964, -0.31407732, -0.28985263, -0.30176697,\n",
       "          -0.29478941, -0.29732031, -0.29182926, -0.27275014, -0.27377506,\n",
       "          -0.31637579, -0.29777021, -0.26986651, -0.35005823, -0.29800938,\n",
       "          -0.32457548, -0.28060522, -0.31958407, -0.32726124, -0.26544314,\n",
       "          -0.27403033, -0.30957804, -0.29589644, -0.2799216 , -0.28521108,\n",
       "          -0.26555954, -0.29562052, -0.28539629, -0.337673  , -0.28531174,\n",
       "          -0.29495073, -0.29274208, -0.28982823, -0.29204876, -0.31110811,\n",
       "          -0.27249706, -0.31335809, -0.31110551, -0.33498815, -0.30607254,\n",
       "          -0.30941045, -0.30947676, -0.31885886, -0.27841526, -0.26034095,\n",
       "          -0.31018244, -0.2602941 , -0.29298468, -0.28913037, -0.29500853]),\n",
       "   'mean_test_score': array([-0.31648737, -0.36327175, -0.31492048, -0.33171953, -0.30930005,\n",
       "          -0.36932504, -0.31820658, -0.3427391 , -0.34781303, -0.32550075,\n",
       "          -0.32310349, -0.34207427, -0.32458571, -0.34890591, -0.43432326,\n",
       "          -0.32034672, -0.32174211, -0.35141664, -0.35881106, -0.32602262,\n",
       "          -0.32267626, -0.35016874, -0.31834974, -0.31818429, -0.33960236,\n",
       "          -0.38520583, -0.31828497, -0.32145562, -0.32057854, -0.32076782,\n",
       "          -0.30960264, -0.31827994, -0.31886825, -0.32700548, -0.32963466,\n",
       "          -0.31229678, -0.31239082, -0.33179624, -0.34292401, -0.32405702,\n",
       "          -0.31970611, -0.32237566, -0.31522846, -0.31884806, -0.33265789,\n",
       "          -0.32882515, -0.32500608, -0.32145038, -0.34272627, -0.31474281,\n",
       "          -0.34124333, -0.49449171, -0.33563319, -0.32108286, -0.33146025,\n",
       "          -0.32528364, -0.31705011, -0.32050302, -0.33055012, -0.33165721,\n",
       "          -0.34106315, -0.35491504, -0.32590864, -0.34895132, -0.38108491,\n",
       "          -0.35080484, -0.31953601, -0.32394945, -0.32492725, -0.31453356,\n",
       "          -0.31650316, -0.35421776, -0.31826407, -0.31983982, -0.31960999,\n",
       "          -0.31709237, -0.31866533, -0.31050025, -0.3348379 , -0.31925401,\n",
       "          -0.31594707, -0.31991479, -0.3204399 , -0.32538378, -0.34987005,\n",
       "          -0.30466256, -0.35279403, -0.31575631, -0.33606251, -0.33227919,\n",
       "          -0.33790106, -0.31527199, -0.33648849, -0.32533104, -0.30975159,\n",
       "          -0.31507546, -0.31028492, -0.32063283, -0.31229042, -0.31518091]),\n",
       "   'std_test_score': array([0.07747184, 0.08837922, 0.05454411, 0.08064733, 0.04340086,\n",
       "          0.08967018, 0.06557638, 0.05134151, 0.07867554, 0.06759969,\n",
       "          0.05728147, 0.08986946, 0.05923787, 0.06335451, 0.04135393,\n",
       "          0.04949117, 0.05167695, 0.04737204, 0.04837126, 0.05719501,\n",
       "          0.05006154, 0.08774854, 0.05209022, 0.05195924, 0.04897594,\n",
       "          0.04404805, 0.05984952, 0.05693607, 0.05166067, 0.05970461,\n",
       "          0.05112801, 0.05379795, 0.0557966 , 0.05344119, 0.0512083 ,\n",
       "          0.05725422, 0.04939849, 0.05292351, 0.05469964, 0.06901682,\n",
       "          0.05863614, 0.05026271, 0.06039956, 0.05877953, 0.05260659,\n",
       "          0.04968553, 0.06198584, 0.05207695, 0.04901512, 0.04701955,\n",
       "          0.05191036, 0.05824397, 0.05113073, 0.05230011, 0.04836309,\n",
       "          0.05564624, 0.05655612, 0.06061912, 0.06666202, 0.05516316,\n",
       "          0.05171887, 0.08783202, 0.05781928, 0.04731782, 0.10500063,\n",
       "          0.05296391, 0.05537434, 0.05274439, 0.05866038, 0.06062739,\n",
       "          0.05916277, 0.04776397, 0.05653081, 0.05562806, 0.06092313,\n",
       "          0.06059057, 0.0563694 , 0.05572316, 0.05295716, 0.06561924,\n",
       "          0.06009933, 0.06078821, 0.04603454, 0.0469912 , 0.06953814,\n",
       "          0.05605972, 0.04979621, 0.0487993 , 0.05278567, 0.04377163,\n",
       "          0.05235602, 0.05452526, 0.05140093, 0.0577036 , 0.05754995,\n",
       "          0.05495099, 0.05803185, 0.06082444, 0.05593986, 0.05110762]),\n",
       "   'rank_test_score': array([ 19,  95,  12,  68,   2,  96,  24,  82,  84,  59,  50,  80,  53,\n",
       "           85,  99,  38,  47,  90,  94,  61,  49,  88,  28,  23,  77,  98,\n",
       "           27,  46,  41,  43,   3,  26,  31,  62,  64,   8,   9,  69,  83,\n",
       "           52,  35,  48,  15,  30,  71,  63,  55,  45,  81,  11,  79, 100,\n",
       "           73,  44,  66,  56,  21,  40,  65,  67,  78,  93,  60,  86,  97,\n",
       "           89,  33,  51,  54,  10,  20,  92,  25,  36,  34,  22,  29,   6,\n",
       "           72,  32,  18,  37,  39,  58,  87,   1,  91,  17,  74,  70,  76,\n",
       "           16,  75,  57,   4,  13,   5,  42,   7,  14], dtype=int32)}},\n",
       " 'MLR': {'best_estimator': LinearRegression(fit_intercept=False, positive=True),\n",
       "  'best_params': OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "  'best_score': -15803796307.458841,\n",
       "  'optimization_history': {'mean_fit_time': array([3.04927187, 2.99651062, 0.75703049, 2.95144615, 0.69410763,\n",
       "          2.87194271, 2.89310102, 2.84506257, 2.92391198, 0.64473803,\n",
       "          2.93301299, 3.04360445, 3.00055602, 2.97423184, 2.97726638,\n",
       "          3.08419397, 2.99857922, 2.98402429, 3.02365885, 2.92054536,\n",
       "          2.93109219, 2.96548007, 2.93924031, 2.90556307, 2.94971621,\n",
       "          2.92314034, 2.93214405, 2.94280381, 2.92921882, 2.9468164 ,\n",
       "          2.93968916, 2.94812162, 2.91439648, 2.92202828, 2.92949674,\n",
       "          2.94070058, 3.06934283, 2.99335358, 2.9269851 , 2.9130702 ,\n",
       "          2.95460012, 2.96553445, 2.96004322, 2.99991832, 2.95858622,\n",
       "          2.93897712, 2.93079753, 2.94600677, 2.9998064 , 3.03097208,\n",
       "          3.02276778, 2.99618351, 2.96429548, 2.98604054, 3.00061512,\n",
       "          2.95025952, 2.93957603, 2.90706754, 2.92734716, 2.93537538,\n",
       "          2.93279297, 2.92962377, 2.96835735, 2.93701851, 2.9309454 ,\n",
       "          2.90780475, 2.94319243, 2.91903226, 0.67034066, 2.97354691,\n",
       "          2.91663852, 2.98473277, 2.97746933, 2.93795459, 2.96031082,\n",
       "          2.98690228, 2.91742363, 2.92450116, 2.96970251, 2.96261382,\n",
       "          2.95955882, 2.93739378, 2.94926507, 2.92856889, 2.94209754,\n",
       "          2.92776685, 2.94562268, 3.00958354, 3.03355076, 2.96341465,\n",
       "          3.05250258, 2.95208335, 3.02148595, 2.94573555, 3.02486467,\n",
       "          2.93865595, 2.94630313, 2.96102037, 2.94770532, 2.94887273]),\n",
       "   'std_fit_time': array([0.36310667, 0.27908969, 0.13500743, 0.28777818, 0.12267755,\n",
       "          0.2565827 , 0.26940356, 0.27535619, 0.25274711, 0.10484659,\n",
       "          0.26653652, 0.32390714, 0.31681719, 0.31141714, 0.27668306,\n",
       "          0.35077502, 0.30155582, 0.2646136 , 0.32173556, 0.26201102,\n",
       "          0.2674243 , 0.28299473, 0.25739179, 0.25974545, 0.28755208,\n",
       "          0.26857851, 0.25709548, 0.28414461, 0.28429166, 0.27475823,\n",
       "          0.26634453, 0.27284324, 0.26402465, 0.2775693 , 0.27455804,\n",
       "          0.27649429, 0.34759303, 0.30447879, 0.24413008, 0.26948462,\n",
       "          0.28855511, 0.27132262, 0.30571393, 0.32378944, 0.28880647,\n",
       "          0.28183079, 0.28878778, 0.27722004, 0.26432061, 0.31424813,\n",
       "          0.32455158, 0.30980394, 0.26594804, 0.28837463, 0.3251962 ,\n",
       "          0.28258696, 0.27068127, 0.26968891, 0.28160661, 0.25846074,\n",
       "          0.25797184, 0.27636421, 0.29238477, 0.2494832 , 0.28044964,\n",
       "          0.26508917, 0.28207724, 0.25411737, 0.11224903, 0.27500118,\n",
       "          0.25775825, 0.27796981, 0.30456895, 0.2661275 , 0.28615707,\n",
       "          0.30484356, 0.25856813, 0.27956901, 0.283697  , 0.29810278,\n",
       "          0.29866073, 0.28344402, 0.28357973, 0.26781791, 0.27762929,\n",
       "          0.26405644, 0.27705044, 0.31497873, 0.33589244, 0.2754873 ,\n",
       "          0.35126319, 0.27175333, 0.33231903, 0.2800157 , 0.30075542,\n",
       "          0.28475389, 0.28104392, 0.2769394 , 0.28042151, 0.28567638]),\n",
       "   'mean_score_time': array([0.01125619, 0.00898452, 0.01527481, 0.00536165, 0.00493701,\n",
       "          0.00856979, 0.00684993, 0.00549343, 0.00592942, 0.00587077,\n",
       "          0.00701478, 0.00717294, 0.00883272, 0.00802448, 0.00773132,\n",
       "          0.00741029, 0.00845342, 0.00969312, 0.00808282, 0.00684805,\n",
       "          0.00524168, 0.00512054, 0.0061377 , 0.00449388, 0.00473995,\n",
       "          0.00685482, 0.00434713, 0.00525036, 0.00525494, 0.00662909,\n",
       "          0.00601821, 0.00762312, 0.00506294, 0.0060035 , 0.00496905,\n",
       "          0.00660338, 0.01035752, 0.00560639, 0.00649123, 0.00511408,\n",
       "          0.00721478, 0.00738914, 0.00801179, 0.01026351, 0.00647066,\n",
       "          0.00476632, 0.00463831, 0.00685711, 0.01286676, 0.00639474,\n",
       "          0.00703897, 0.00616212, 0.00533423, 0.00755539, 0.00644677,\n",
       "          0.00516791, 0.00600398, 0.00490501, 0.00585003, 0.00465825,\n",
       "          0.00561697, 0.005828  , 0.00776236, 0.00618331, 0.00499473,\n",
       "          0.00466008, 0.00732882, 0.00516453, 0.00470023, 0.00500524,\n",
       "          0.00495162, 0.00964301, 0.0070128 , 0.00553989, 0.00644188,\n",
       "          0.00543621, 0.00403352, 0.004774  , 0.00752718, 0.00779884,\n",
       "          0.00700057, 0.0058111 , 0.00565186, 0.00525441, 0.00570264,\n",
       "          0.00595939, 0.00589046, 0.00628831, 0.01206462, 0.00562243,\n",
       "          0.00847552, 0.0054709 , 0.00774765, 0.00546145, 0.01007359,\n",
       "          0.00583785, 0.00499291, 0.00485113, 0.0074482 , 0.00600355]),\n",
       "   'std_score_time': array([0.00720049, 0.00558871, 0.01141575, 0.00212046, 0.0013176 ,\n",
       "          0.00600452, 0.0027617 , 0.00234148, 0.00248231, 0.00239316,\n",
       "          0.00431255, 0.00395306, 0.0053763 , 0.00475393, 0.00476434,\n",
       "          0.00398603, 0.00638707, 0.0061454 , 0.00595781, 0.0041859 ,\n",
       "          0.00181104, 0.00158167, 0.00252152, 0.00137183, 0.00157652,\n",
       "          0.00538426, 0.00081742, 0.00258203, 0.00212117, 0.00319472,\n",
       "          0.00279433, 0.00433421, 0.0023572 , 0.00297616, 0.00179679,\n",
       "          0.00381598, 0.00585676, 0.00212891, 0.0044221 , 0.0022185 ,\n",
       "          0.00460205, 0.00495501, 0.00455931, 0.00715212, 0.00459426,\n",
       "          0.00113123, 0.00107979, 0.00412739, 0.00876718, 0.00256305,\n",
       "          0.00384199, 0.0032355 , 0.00149676, 0.00432724, 0.00305576,\n",
       "          0.00183907, 0.00256105, 0.00178801, 0.00281345, 0.00103499,\n",
       "          0.00251407, 0.00300045, 0.00618794, 0.00281323, 0.00163265,\n",
       "          0.00121671, 0.00523614, 0.0012201 , 0.00166863, 0.00146091,\n",
       "          0.00139333, 0.00571271, 0.00399619, 0.00240241, 0.00371092,\n",
       "          0.00231783, 0.00060088, 0.00149184, 0.00376747, 0.00589207,\n",
       "          0.0037077 , 0.00255446, 0.00240834, 0.00212326, 0.00262459,\n",
       "          0.0024589 , 0.00159858, 0.0027148 , 0.00892407, 0.00175882,\n",
       "          0.004348  , 0.00168557, 0.00394583, 0.00207831, 0.00841313,\n",
       "          0.00229112, 0.00107073, 0.00124115, 0.00349022, 0.00213579]),\n",
       "   'param_fit_intercept': masked_array(data=[True, False, True, False, False, True, True, True,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, True, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_positive': masked_array(data=[True, True, False, True, False, True, True, True, True,\n",
       "                      False, True, True, True, True, True, True, True, True,\n",
       "                      True, True, True, True, True, True, True, True, True,\n",
       "                      True, True, True, True, True, True, True, True, True,\n",
       "                      True, True, True, True, True, True, True, True, True,\n",
       "                      True, True, True, True, True, True, True, True, True,\n",
       "                      True, True, True, True, True, True, True, True, True,\n",
       "                      True, True, True, True, True, False, True, True, True,\n",
       "                      True, True, True, True, True, True, True, True, True,\n",
       "                      True, True, True, True, True, True, True, True, True,\n",
       "                      True, True, True, True, True, True, True, True, True,\n",
       "                      True],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [OrderedDict([('fit_intercept', True), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', True), ('positive', False)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', False)]),\n",
       "    OrderedDict([('fit_intercept', True), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', True), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', True), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', False)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', True), ('positive', False)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)]),\n",
       "    OrderedDict([('fit_intercept', False), ('positive', True)])],\n",
       "   'split0_test_score': array([-4.96859932e+10, -2.28812072e+00, -1.99646348e+11, -2.28812072e+00,\n",
       "          -1.72278522e+11, -4.96859932e+10, -4.96859932e+10, -4.96859932e+10,\n",
       "          -2.28812072e+00, -1.72278522e+11, -2.28812072e+00, -2.28812072e+00,\n",
       "          -2.28812072e+00, -2.28812072e+00, -2.28812072e+00, -2.28812072e+00,\n",
       "          -2.28812072e+00, -2.28812072e+00, -2.28812072e+00, -2.28812072e+00,\n",
       "          -2.28812072e+00, -2.28812072e+00, -2.28812072e+00, -2.28812072e+00,\n",
       "          -2.28812072e+00, -2.28812072e+00, -2.28812072e+00, -2.28812072e+00,\n",
       "          -2.28812072e+00, -2.28812072e+00, -2.28812072e+00, -2.28812072e+00,\n",
       "          -2.28812072e+00, -2.28812072e+00, -2.28812072e+00, -2.28812072e+00,\n",
       "          -2.28812072e+00, -2.28812072e+00, -2.28812072e+00, -2.28812072e+00,\n",
       "          -2.28812072e+00, -2.28812072e+00, -2.28812072e+00, -2.28812072e+00,\n",
       "          -2.28812072e+00, -2.28812072e+00, -2.28812072e+00, -2.28812072e+00,\n",
       "          -2.28812072e+00, -2.28812072e+00, -2.28812072e+00, -2.28812072e+00,\n",
       "          -2.28812072e+00, -2.28812072e+00, -2.28812072e+00, -2.28812072e+00,\n",
       "          -2.28812072e+00, -2.28812072e+00, -2.28812072e+00, -2.28812072e+00,\n",
       "          -2.28812072e+00, -2.28812072e+00, -2.28812072e+00, -2.28812072e+00,\n",
       "          -2.28812072e+00, -2.28812072e+00, -2.28812072e+00, -2.28812072e+00,\n",
       "          -1.99646348e+11, -2.28812072e+00, -2.28812072e+00, -2.28812072e+00,\n",
       "          -2.28812072e+00, -2.28812072e+00, -2.28812072e+00, -2.28812072e+00,\n",
       "          -2.28812072e+00, -2.28812072e+00, -2.28812072e+00, -2.28812072e+00,\n",
       "          -2.28812072e+00, -2.28812072e+00, -2.28812072e+00, -2.28812072e+00,\n",
       "          -2.28812072e+00, -2.28812072e+00, -2.28812072e+00, -2.28812072e+00,\n",
       "          -2.28812072e+00, -2.28812072e+00, -2.28812072e+00, -2.28812072e+00,\n",
       "          -2.28812072e+00, -2.28812072e+00, -2.28812072e+00, -2.28812072e+00,\n",
       "          -2.28812072e+00, -2.28812072e+00, -2.28812072e+00, -2.28812072e+00]),\n",
       "   'split1_test_score': array([-5.53070745e-01, -6.75706924e-01, -4.58685593e+11, -6.75706924e-01,\n",
       "          -1.83275270e+11, -5.53070745e-01, -5.53070745e-01, -5.53070745e-01,\n",
       "          -6.75706924e-01, -1.83275270e+11, -6.75706924e-01, -6.75706924e-01,\n",
       "          -6.75706924e-01, -6.75706924e-01, -6.75706924e-01, -6.75706924e-01,\n",
       "          -6.75706924e-01, -6.75706924e-01, -6.75706924e-01, -6.75706924e-01,\n",
       "          -6.75706924e-01, -6.75706924e-01, -6.75706924e-01, -6.75706924e-01,\n",
       "          -6.75706924e-01, -6.75706924e-01, -6.75706924e-01, -6.75706924e-01,\n",
       "          -6.75706924e-01, -6.75706924e-01, -6.75706924e-01, -6.75706924e-01,\n",
       "          -6.75706924e-01, -6.75706924e-01, -6.75706924e-01, -6.75706924e-01,\n",
       "          -6.75706924e-01, -6.75706924e-01, -6.75706924e-01, -6.75706924e-01,\n",
       "          -6.75706924e-01, -6.75706924e-01, -6.75706924e-01, -6.75706924e-01,\n",
       "          -6.75706924e-01, -6.75706924e-01, -6.75706924e-01, -6.75706924e-01,\n",
       "          -6.75706924e-01, -6.75706924e-01, -6.75706924e-01, -6.75706924e-01,\n",
       "          -6.75706924e-01, -6.75706924e-01, -6.75706924e-01, -6.75706924e-01,\n",
       "          -6.75706924e-01, -6.75706924e-01, -6.75706924e-01, -6.75706924e-01,\n",
       "          -6.75706924e-01, -6.75706924e-01, -6.75706924e-01, -6.75706924e-01,\n",
       "          -6.75706924e-01, -6.75706924e-01, -6.75706924e-01, -6.75706924e-01,\n",
       "          -4.58685593e+11, -6.75706924e-01, -6.75706924e-01, -6.75706924e-01,\n",
       "          -6.75706924e-01, -6.75706924e-01, -6.75706924e-01, -6.75706924e-01,\n",
       "          -6.75706924e-01, -6.75706924e-01, -6.75706924e-01, -6.75706924e-01,\n",
       "          -6.75706924e-01, -6.75706924e-01, -6.75706924e-01, -6.75706924e-01,\n",
       "          -6.75706924e-01, -6.75706924e-01, -6.75706924e-01, -6.75706924e-01,\n",
       "          -6.75706924e-01, -6.75706924e-01, -6.75706924e-01, -6.75706924e-01,\n",
       "          -6.75706924e-01, -6.75706924e-01, -6.75706924e-01, -6.75706924e-01,\n",
       "          -6.75706924e-01, -6.75706924e-01, -6.75706924e-01, -6.75706924e-01]),\n",
       "   'split2_test_score': array([-2.11149628e+09, -2.61696957e+00, -2.18648755e+11, -2.61696957e+00,\n",
       "          -3.82688513e+11, -2.11149628e+09, -2.11149628e+09, -2.11149628e+09,\n",
       "          -2.61696957e+00, -3.82688513e+11, -2.61696957e+00, -2.61696957e+00,\n",
       "          -2.61696957e+00, -2.61696957e+00, -2.61696957e+00, -2.61696957e+00,\n",
       "          -2.61696957e+00, -2.61696957e+00, -2.61696957e+00, -2.61696957e+00,\n",
       "          -2.61696957e+00, -2.61696957e+00, -2.61696957e+00, -2.61696957e+00,\n",
       "          -2.61696957e+00, -2.61696957e+00, -2.61696957e+00, -2.61696957e+00,\n",
       "          -2.61696957e+00, -2.61696957e+00, -2.61696957e+00, -2.61696957e+00,\n",
       "          -2.61696957e+00, -2.61696957e+00, -2.61696957e+00, -2.61696957e+00,\n",
       "          -2.61696957e+00, -2.61696957e+00, -2.61696957e+00, -2.61696957e+00,\n",
       "          -2.61696957e+00, -2.61696957e+00, -2.61696957e+00, -2.61696957e+00,\n",
       "          -2.61696957e+00, -2.61696957e+00, -2.61696957e+00, -2.61696957e+00,\n",
       "          -2.61696957e+00, -2.61696957e+00, -2.61696957e+00, -2.61696957e+00,\n",
       "          -2.61696957e+00, -2.61696957e+00, -2.61696957e+00, -2.61696957e+00,\n",
       "          -2.61696957e+00, -2.61696957e+00, -2.61696957e+00, -2.61696957e+00,\n",
       "          -2.61696957e+00, -2.61696957e+00, -2.61696957e+00, -2.61696957e+00,\n",
       "          -2.61696957e+00, -2.61696957e+00, -2.61696957e+00, -2.61696957e+00,\n",
       "          -2.18648755e+11, -2.61696957e+00, -2.61696957e+00, -2.61696957e+00,\n",
       "          -2.61696957e+00, -2.61696957e+00, -2.61696957e+00, -2.61696957e+00,\n",
       "          -2.61696957e+00, -2.61696957e+00, -2.61696957e+00, -2.61696957e+00,\n",
       "          -2.61696957e+00, -2.61696957e+00, -2.61696957e+00, -2.61696957e+00,\n",
       "          -2.61696957e+00, -2.61696957e+00, -2.61696957e+00, -2.61696957e+00,\n",
       "          -2.61696957e+00, -2.61696957e+00, -2.61696957e+00, -2.61696957e+00,\n",
       "          -2.61696957e+00, -2.61696957e+00, -2.61696957e+00, -2.61696957e+00,\n",
       "          -2.61696957e+00, -2.61696957e+00, -2.61696957e+00, -2.61696957e+00]),\n",
       "   'split3_test_score': array([-5.84296235e+10, -2.37315589e+00, -6.84855752e+11, -2.37315589e+00,\n",
       "          -3.66731348e+11, -5.84296235e+10, -5.84296235e+10, -5.84296235e+10,\n",
       "          -2.37315589e+00, -3.66731348e+11, -2.37315589e+00, -2.37315589e+00,\n",
       "          -2.37315589e+00, -2.37315589e+00, -2.37315589e+00, -2.37315589e+00,\n",
       "          -2.37315589e+00, -2.37315589e+00, -2.37315589e+00, -2.37315589e+00,\n",
       "          -2.37315589e+00, -2.37315589e+00, -2.37315589e+00, -2.37315589e+00,\n",
       "          -2.37315589e+00, -2.37315589e+00, -2.37315589e+00, -2.37315589e+00,\n",
       "          -2.37315589e+00, -2.37315589e+00, -2.37315589e+00, -2.37315589e+00,\n",
       "          -2.37315589e+00, -2.37315589e+00, -2.37315589e+00, -2.37315589e+00,\n",
       "          -2.37315589e+00, -2.37315589e+00, -2.37315589e+00, -2.37315589e+00,\n",
       "          -2.37315589e+00, -2.37315589e+00, -2.37315589e+00, -2.37315589e+00,\n",
       "          -2.37315589e+00, -2.37315589e+00, -2.37315589e+00, -2.37315589e+00,\n",
       "          -2.37315589e+00, -2.37315589e+00, -2.37315589e+00, -2.37315589e+00,\n",
       "          -2.37315589e+00, -2.37315589e+00, -2.37315589e+00, -2.37315589e+00,\n",
       "          -2.37315589e+00, -2.37315589e+00, -2.37315589e+00, -2.37315589e+00,\n",
       "          -2.37315589e+00, -2.37315589e+00, -2.37315589e+00, -2.37315589e+00,\n",
       "          -2.37315589e+00, -2.37315589e+00, -2.37315589e+00, -2.37315589e+00,\n",
       "          -6.84855752e+11, -2.37315589e+00, -2.37315589e+00, -2.37315589e+00,\n",
       "          -2.37315589e+00, -2.37315589e+00, -2.37315589e+00, -2.37315589e+00,\n",
       "          -2.37315589e+00, -2.37315589e+00, -2.37315589e+00, -2.37315589e+00,\n",
       "          -2.37315589e+00, -2.37315589e+00, -2.37315589e+00, -2.37315589e+00,\n",
       "          -2.37315589e+00, -2.37315589e+00, -2.37315589e+00, -2.37315589e+00,\n",
       "          -2.37315589e+00, -2.37315589e+00, -2.37315589e+00, -2.37315589e+00,\n",
       "          -2.37315589e+00, -2.37315589e+00, -2.37315589e+00, -2.37315589e+00,\n",
       "          -2.37315589e+00, -2.37315589e+00, -2.37315589e+00, -2.37315589e+00]),\n",
       "   'split4_test_score': array([-2.40773300e+02, -8.07467500e-01, -9.77355897e+11, -8.07467500e-01,\n",
       "          -3.29947441e+11, -2.40773300e+02, -2.40773300e+02, -2.40773300e+02,\n",
       "          -8.07467500e-01, -3.29947441e+11, -8.07467500e-01, -8.07467500e-01,\n",
       "          -8.07467500e-01, -8.07467500e-01, -8.07467500e-01, -8.07467500e-01,\n",
       "          -8.07467500e-01, -8.07467500e-01, -8.07467500e-01, -8.07467500e-01,\n",
       "          -8.07467500e-01, -8.07467500e-01, -8.07467500e-01, -8.07467500e-01,\n",
       "          -8.07467500e-01, -8.07467500e-01, -8.07467500e-01, -8.07467500e-01,\n",
       "          -8.07467500e-01, -8.07467500e-01, -8.07467500e-01, -8.07467500e-01,\n",
       "          -8.07467500e-01, -8.07467500e-01, -8.07467500e-01, -8.07467500e-01,\n",
       "          -8.07467500e-01, -8.07467500e-01, -8.07467500e-01, -8.07467500e-01,\n",
       "          -8.07467500e-01, -8.07467500e-01, -8.07467500e-01, -8.07467500e-01,\n",
       "          -8.07467500e-01, -8.07467500e-01, -8.07467500e-01, -8.07467500e-01,\n",
       "          -8.07467500e-01, -8.07467500e-01, -8.07467500e-01, -8.07467500e-01,\n",
       "          -8.07467500e-01, -8.07467500e-01, -8.07467500e-01, -8.07467500e-01,\n",
       "          -8.07467500e-01, -8.07467500e-01, -8.07467500e-01, -8.07467500e-01,\n",
       "          -8.07467500e-01, -8.07467500e-01, -8.07467500e-01, -8.07467500e-01,\n",
       "          -8.07467500e-01, -8.07467500e-01, -8.07467500e-01, -8.07467500e-01,\n",
       "          -9.77355897e+11, -8.07467500e-01, -8.07467500e-01, -8.07467500e-01,\n",
       "          -8.07467500e-01, -8.07467500e-01, -8.07467500e-01, -8.07467500e-01,\n",
       "          -8.07467500e-01, -8.07467500e-01, -8.07467500e-01, -8.07467500e-01,\n",
       "          -8.07467500e-01, -8.07467500e-01, -8.07467500e-01, -8.07467500e-01,\n",
       "          -8.07467500e-01, -8.07467500e-01, -8.07467500e-01, -8.07467500e-01,\n",
       "          -8.07467500e-01, -8.07467500e-01, -8.07467500e-01, -8.07467500e-01,\n",
       "          -8.07467500e-01, -8.07467500e-01, -8.07467500e-01, -8.07467500e-01,\n",
       "          -8.07467500e-01, -8.07467500e-01, -8.07467500e-01, -8.07467500e-01]),\n",
       "   'split5_test_score': array([-5.12124734e+10, -1.30519956e+11, -3.18426736e+11, -1.30519956e+11,\n",
       "          -3.49027339e+11, -5.12124734e+10, -5.12124734e+10, -5.12124734e+10,\n",
       "          -1.30519956e+11, -3.49027339e+11, -1.30519956e+11, -1.30519956e+11,\n",
       "          -1.30519956e+11, -1.30519956e+11, -1.30519956e+11, -1.30519956e+11,\n",
       "          -1.30519956e+11, -1.30519956e+11, -1.30519956e+11, -1.30519956e+11,\n",
       "          -1.30519956e+11, -1.30519956e+11, -1.30519956e+11, -1.30519956e+11,\n",
       "          -1.30519956e+11, -1.30519956e+11, -1.30519956e+11, -1.30519956e+11,\n",
       "          -1.30519956e+11, -1.30519956e+11, -1.30519956e+11, -1.30519956e+11,\n",
       "          -1.30519956e+11, -1.30519956e+11, -1.30519956e+11, -1.30519956e+11,\n",
       "          -1.30519956e+11, -1.30519956e+11, -1.30519956e+11, -1.30519956e+11,\n",
       "          -1.30519956e+11, -1.30519956e+11, -1.30519956e+11, -1.30519956e+11,\n",
       "          -1.30519956e+11, -1.30519956e+11, -1.30519956e+11, -1.30519956e+11,\n",
       "          -1.30519956e+11, -1.30519956e+11, -1.30519956e+11, -1.30519956e+11,\n",
       "          -1.30519956e+11, -1.30519956e+11, -1.30519956e+11, -1.30519956e+11,\n",
       "          -1.30519956e+11, -1.30519956e+11, -1.30519956e+11, -1.30519956e+11,\n",
       "          -1.30519956e+11, -1.30519956e+11, -1.30519956e+11, -1.30519956e+11,\n",
       "          -1.30519956e+11, -1.30519956e+11, -1.30519956e+11, -1.30519956e+11,\n",
       "          -3.18426736e+11, -1.30519956e+11, -1.30519956e+11, -1.30519956e+11,\n",
       "          -1.30519956e+11, -1.30519956e+11, -1.30519956e+11, -1.30519956e+11,\n",
       "          -1.30519956e+11, -1.30519956e+11, -1.30519956e+11, -1.30519956e+11,\n",
       "          -1.30519956e+11, -1.30519956e+11, -1.30519956e+11, -1.30519956e+11,\n",
       "          -1.30519956e+11, -1.30519956e+11, -1.30519956e+11, -1.30519956e+11,\n",
       "          -1.30519956e+11, -1.30519956e+11, -1.30519956e+11, -1.30519956e+11,\n",
       "          -1.30519956e+11, -1.30519956e+11, -1.30519956e+11, -1.30519956e+11,\n",
       "          -1.30519956e+11, -1.30519956e+11, -1.30519956e+11, -1.30519956e+11]),\n",
       "   'split6_test_score': array([-2.55988639e+12, -2.75180073e+10, -1.45012378e+12, -2.75180073e+10,\n",
       "          -1.33292478e+12, -2.55988639e+12, -2.55988639e+12, -2.55988639e+12,\n",
       "          -2.75180073e+10, -1.33292478e+12, -2.75180073e+10, -2.75180073e+10,\n",
       "          -2.75180073e+10, -2.75180073e+10, -2.75180073e+10, -2.75180073e+10,\n",
       "          -2.75180073e+10, -2.75180073e+10, -2.75180073e+10, -2.75180073e+10,\n",
       "          -2.75180073e+10, -2.75180073e+10, -2.75180073e+10, -2.75180073e+10,\n",
       "          -2.75180073e+10, -2.75180073e+10, -2.75180073e+10, -2.75180073e+10,\n",
       "          -2.75180073e+10, -2.75180073e+10, -2.75180073e+10, -2.75180073e+10,\n",
       "          -2.75180073e+10, -2.75180073e+10, -2.75180073e+10, -2.75180073e+10,\n",
       "          -2.75180073e+10, -2.75180073e+10, -2.75180073e+10, -2.75180073e+10,\n",
       "          -2.75180073e+10, -2.75180073e+10, -2.75180073e+10, -2.75180073e+10,\n",
       "          -2.75180073e+10, -2.75180073e+10, -2.75180073e+10, -2.75180073e+10,\n",
       "          -2.75180073e+10, -2.75180073e+10, -2.75180073e+10, -2.75180073e+10,\n",
       "          -2.75180073e+10, -2.75180073e+10, -2.75180073e+10, -2.75180073e+10,\n",
       "          -2.75180073e+10, -2.75180073e+10, -2.75180073e+10, -2.75180073e+10,\n",
       "          -2.75180073e+10, -2.75180073e+10, -2.75180073e+10, -2.75180073e+10,\n",
       "          -2.75180073e+10, -2.75180073e+10, -2.75180073e+10, -2.75180073e+10,\n",
       "          -1.45012378e+12, -2.75180073e+10, -2.75180073e+10, -2.75180073e+10,\n",
       "          -2.75180073e+10, -2.75180073e+10, -2.75180073e+10, -2.75180073e+10,\n",
       "          -2.75180073e+10, -2.75180073e+10, -2.75180073e+10, -2.75180073e+10,\n",
       "          -2.75180073e+10, -2.75180073e+10, -2.75180073e+10, -2.75180073e+10,\n",
       "          -2.75180073e+10, -2.75180073e+10, -2.75180073e+10, -2.75180073e+10,\n",
       "          -2.75180073e+10, -2.75180073e+10, -2.75180073e+10, -2.75180073e+10,\n",
       "          -2.75180073e+10, -2.75180073e+10, -2.75180073e+10, -2.75180073e+10,\n",
       "          -2.75180073e+10, -2.75180073e+10, -2.75180073e+10, -2.75180073e+10]),\n",
       "   'split7_test_score': array([-2.88205681e+10, -2.63977170e+00, -2.14206769e+11, -2.63977170e+00,\n",
       "          -1.67670150e+11, -2.88205681e+10, -2.88205681e+10, -2.88205681e+10,\n",
       "          -2.63977170e+00, -1.67670150e+11, -2.63977170e+00, -2.63977170e+00,\n",
       "          -2.63977170e+00, -2.63977170e+00, -2.63977170e+00, -2.63977170e+00,\n",
       "          -2.63977170e+00, -2.63977170e+00, -2.63977170e+00, -2.63977170e+00,\n",
       "          -2.63977170e+00, -2.63977170e+00, -2.63977170e+00, -2.63977170e+00,\n",
       "          -2.63977170e+00, -2.63977170e+00, -2.63977170e+00, -2.63977170e+00,\n",
       "          -2.63977170e+00, -2.63977170e+00, -2.63977170e+00, -2.63977170e+00,\n",
       "          -2.63977170e+00, -2.63977170e+00, -2.63977170e+00, -2.63977170e+00,\n",
       "          -2.63977170e+00, -2.63977170e+00, -2.63977170e+00, -2.63977170e+00,\n",
       "          -2.63977170e+00, -2.63977170e+00, -2.63977170e+00, -2.63977170e+00,\n",
       "          -2.63977170e+00, -2.63977170e+00, -2.63977170e+00, -2.63977170e+00,\n",
       "          -2.63977170e+00, -2.63977170e+00, -2.63977170e+00, -2.63977170e+00,\n",
       "          -2.63977170e+00, -2.63977170e+00, -2.63977170e+00, -2.63977170e+00,\n",
       "          -2.63977170e+00, -2.63977170e+00, -2.63977170e+00, -2.63977170e+00,\n",
       "          -2.63977170e+00, -2.63977170e+00, -2.63977170e+00, -2.63977170e+00,\n",
       "          -2.63977170e+00, -2.63977170e+00, -2.63977170e+00, -2.63977170e+00,\n",
       "          -2.14206769e+11, -2.63977170e+00, -2.63977170e+00, -2.63977170e+00,\n",
       "          -2.63977170e+00, -2.63977170e+00, -2.63977170e+00, -2.63977170e+00,\n",
       "          -2.63977170e+00, -2.63977170e+00, -2.63977170e+00, -2.63977170e+00,\n",
       "          -2.63977170e+00, -2.63977170e+00, -2.63977170e+00, -2.63977170e+00,\n",
       "          -2.63977170e+00, -2.63977170e+00, -2.63977170e+00, -2.63977170e+00,\n",
       "          -2.63977170e+00, -2.63977170e+00, -2.63977170e+00, -2.63977170e+00,\n",
       "          -2.63977170e+00, -2.63977170e+00, -2.63977170e+00, -2.63977170e+00,\n",
       "          -2.63977170e+00, -2.63977170e+00, -2.63977170e+00, -2.63977170e+00]),\n",
       "   'split8_test_score': array([-7.89674237e+00, -2.50951946e+00, -4.10521609e+11, -2.50951946e+00,\n",
       "          -1.98284502e+11, -7.89674237e+00, -7.89674237e+00, -7.89674237e+00,\n",
       "          -2.50951946e+00, -1.98284502e+11, -2.50951946e+00, -2.50951946e+00,\n",
       "          -2.50951946e+00, -2.50951946e+00, -2.50951946e+00, -2.50951946e+00,\n",
       "          -2.50951946e+00, -2.50951946e+00, -2.50951946e+00, -2.50951946e+00,\n",
       "          -2.50951946e+00, -2.50951946e+00, -2.50951946e+00, -2.50951946e+00,\n",
       "          -2.50951946e+00, -2.50951946e+00, -2.50951946e+00, -2.50951946e+00,\n",
       "          -2.50951946e+00, -2.50951946e+00, -2.50951946e+00, -2.50951946e+00,\n",
       "          -2.50951946e+00, -2.50951946e+00, -2.50951946e+00, -2.50951946e+00,\n",
       "          -2.50951946e+00, -2.50951946e+00, -2.50951946e+00, -2.50951946e+00,\n",
       "          -2.50951946e+00, -2.50951946e+00, -2.50951946e+00, -2.50951946e+00,\n",
       "          -2.50951946e+00, -2.50951946e+00, -2.50951946e+00, -2.50951946e+00,\n",
       "          -2.50951946e+00, -2.50951946e+00, -2.50951946e+00, -2.50951946e+00,\n",
       "          -2.50951946e+00, -2.50951946e+00, -2.50951946e+00, -2.50951946e+00,\n",
       "          -2.50951946e+00, -2.50951946e+00, -2.50951946e+00, -2.50951946e+00,\n",
       "          -2.50951946e+00, -2.50951946e+00, -2.50951946e+00, -2.50951946e+00,\n",
       "          -2.50951946e+00, -2.50951946e+00, -2.50951946e+00, -2.50951946e+00,\n",
       "          -4.10521609e+11, -2.50951946e+00, -2.50951946e+00, -2.50951946e+00,\n",
       "          -2.50951946e+00, -2.50951946e+00, -2.50951946e+00, -2.50951946e+00,\n",
       "          -2.50951946e+00, -2.50951946e+00, -2.50951946e+00, -2.50951946e+00,\n",
       "          -2.50951946e+00, -2.50951946e+00, -2.50951946e+00, -2.50951946e+00,\n",
       "          -2.50951946e+00, -2.50951946e+00, -2.50951946e+00, -2.50951946e+00,\n",
       "          -2.50951946e+00, -2.50951946e+00, -2.50951946e+00, -2.50951946e+00,\n",
       "          -2.50951946e+00, -2.50951946e+00, -2.50951946e+00, -2.50951946e+00,\n",
       "          -2.50951946e+00, -2.50951946e+00, -2.50951946e+00, -2.50951946e+00]),\n",
       "   'split9_test_score': array([-1.85825496e+02, -6.79934988e-01, -3.71484410e+11, -6.79934988e-01,\n",
       "          -2.86332074e+11, -1.85825496e+02, -1.85825496e+02, -1.85825496e+02,\n",
       "          -6.79934988e-01, -2.86332074e+11, -6.79934988e-01, -6.79934988e-01,\n",
       "          -6.79934988e-01, -6.79934988e-01, -6.79934988e-01, -6.79934988e-01,\n",
       "          -6.79934988e-01, -6.79934988e-01, -6.79934988e-01, -6.79934988e-01,\n",
       "          -6.79934988e-01, -6.79934988e-01, -6.79934988e-01, -6.79934988e-01,\n",
       "          -6.79934988e-01, -6.79934988e-01, -6.79934988e-01, -6.79934988e-01,\n",
       "          -6.79934988e-01, -6.79934988e-01, -6.79934988e-01, -6.79934988e-01,\n",
       "          -6.79934988e-01, -6.79934988e-01, -6.79934988e-01, -6.79934988e-01,\n",
       "          -6.79934988e-01, -6.79934988e-01, -6.79934988e-01, -6.79934988e-01,\n",
       "          -6.79934988e-01, -6.79934988e-01, -6.79934988e-01, -6.79934988e-01,\n",
       "          -6.79934988e-01, -6.79934988e-01, -6.79934988e-01, -6.79934988e-01,\n",
       "          -6.79934988e-01, -6.79934988e-01, -6.79934988e-01, -6.79934988e-01,\n",
       "          -6.79934988e-01, -6.79934988e-01, -6.79934988e-01, -6.79934988e-01,\n",
       "          -6.79934988e-01, -6.79934988e-01, -6.79934988e-01, -6.79934988e-01,\n",
       "          -6.79934988e-01, -6.79934988e-01, -6.79934988e-01, -6.79934988e-01,\n",
       "          -6.79934988e-01, -6.79934988e-01, -6.79934988e-01, -6.79934988e-01,\n",
       "          -3.71484410e+11, -6.79934988e-01, -6.79934988e-01, -6.79934988e-01,\n",
       "          -6.79934988e-01, -6.79934988e-01, -6.79934988e-01, -6.79934988e-01,\n",
       "          -6.79934988e-01, -6.79934988e-01, -6.79934988e-01, -6.79934988e-01,\n",
       "          -6.79934988e-01, -6.79934988e-01, -6.79934988e-01, -6.79934988e-01,\n",
       "          -6.79934988e-01, -6.79934988e-01, -6.79934988e-01, -6.79934988e-01,\n",
       "          -6.79934988e-01, -6.79934988e-01, -6.79934988e-01, -6.79934988e-01,\n",
       "          -6.79934988e-01, -6.79934988e-01, -6.79934988e-01, -6.79934988e-01,\n",
       "          -6.79934988e-01, -6.79934988e-01, -6.79934988e-01, -6.79934988e-01]),\n",
       "   'mean_test_score': array([-2.75014654e+11, -1.58037963e+10, -5.30395565e+11, -1.58037963e+10,\n",
       "          -3.76915994e+11, -2.75014654e+11, -2.75014654e+11, -2.75014654e+11,\n",
       "          -1.58037963e+10, -3.76915994e+11, -1.58037963e+10, -1.58037963e+10,\n",
       "          -1.58037963e+10, -1.58037963e+10, -1.58037963e+10, -1.58037963e+10,\n",
       "          -1.58037963e+10, -1.58037963e+10, -1.58037963e+10, -1.58037963e+10,\n",
       "          -1.58037963e+10, -1.58037963e+10, -1.58037963e+10, -1.58037963e+10,\n",
       "          -1.58037963e+10, -1.58037963e+10, -1.58037963e+10, -1.58037963e+10,\n",
       "          -1.58037963e+10, -1.58037963e+10, -1.58037963e+10, -1.58037963e+10,\n",
       "          -1.58037963e+10, -1.58037963e+10, -1.58037963e+10, -1.58037963e+10,\n",
       "          -1.58037963e+10, -1.58037963e+10, -1.58037963e+10, -1.58037963e+10,\n",
       "          -1.58037963e+10, -1.58037963e+10, -1.58037963e+10, -1.58037963e+10,\n",
       "          -1.58037963e+10, -1.58037963e+10, -1.58037963e+10, -1.58037963e+10,\n",
       "          -1.58037963e+10, -1.58037963e+10, -1.58037963e+10, -1.58037963e+10,\n",
       "          -1.58037963e+10, -1.58037963e+10, -1.58037963e+10, -1.58037963e+10,\n",
       "          -1.58037963e+10, -1.58037963e+10, -1.58037963e+10, -1.58037963e+10,\n",
       "          -1.58037963e+10, -1.58037963e+10, -1.58037963e+10, -1.58037963e+10,\n",
       "          -1.58037963e+10, -1.58037963e+10, -1.58037963e+10, -1.58037963e+10,\n",
       "          -5.30395565e+11, -1.58037963e+10, -1.58037963e+10, -1.58037963e+10,\n",
       "          -1.58037963e+10, -1.58037963e+10, -1.58037963e+10, -1.58037963e+10,\n",
       "          -1.58037963e+10, -1.58037963e+10, -1.58037963e+10, -1.58037963e+10,\n",
       "          -1.58037963e+10, -1.58037963e+10, -1.58037963e+10, -1.58037963e+10,\n",
       "          -1.58037963e+10, -1.58037963e+10, -1.58037963e+10, -1.58037963e+10,\n",
       "          -1.58037963e+10, -1.58037963e+10, -1.58037963e+10, -1.58037963e+10,\n",
       "          -1.58037963e+10, -1.58037963e+10, -1.58037963e+10, -1.58037963e+10,\n",
       "          -1.58037963e+10, -1.58037963e+10, -1.58037963e+10, -1.58037963e+10]),\n",
       "   'std_test_score': array([7.61972981e+11, 3.91089501e+10, 3.82855531e+11, 3.91089501e+10,\n",
       "          3.28686077e+11, 7.61972981e+11, 7.61972981e+11, 7.61972981e+11,\n",
       "          3.91089501e+10, 3.28686077e+11, 3.91089501e+10, 3.91089501e+10,\n",
       "          3.91089501e+10, 3.91089501e+10, 3.91089501e+10, 3.91089501e+10,\n",
       "          3.91089501e+10, 3.91089501e+10, 3.91089501e+10, 3.91089501e+10,\n",
       "          3.91089501e+10, 3.91089501e+10, 3.91089501e+10, 3.91089501e+10,\n",
       "          3.91089501e+10, 3.91089501e+10, 3.91089501e+10, 3.91089501e+10,\n",
       "          3.91089501e+10, 3.91089501e+10, 3.91089501e+10, 3.91089501e+10,\n",
       "          3.91089501e+10, 3.91089501e+10, 3.91089501e+10, 3.91089501e+10,\n",
       "          3.91089501e+10, 3.91089501e+10, 3.91089501e+10, 3.91089501e+10,\n",
       "          3.91089501e+10, 3.91089501e+10, 3.91089501e+10, 3.91089501e+10,\n",
       "          3.91089501e+10, 3.91089501e+10, 3.91089501e+10, 3.91089501e+10,\n",
       "          3.91089501e+10, 3.91089501e+10, 3.91089501e+10, 3.91089501e+10,\n",
       "          3.91089501e+10, 3.91089501e+10, 3.91089501e+10, 3.91089501e+10,\n",
       "          3.91089501e+10, 3.91089501e+10, 3.91089501e+10, 3.91089501e+10,\n",
       "          3.91089501e+10, 3.91089501e+10, 3.91089501e+10, 3.91089501e+10,\n",
       "          3.91089501e+10, 3.91089501e+10, 3.91089501e+10, 3.91089501e+10,\n",
       "          3.82855531e+11, 3.91089501e+10, 3.91089501e+10, 3.91089501e+10,\n",
       "          3.91089501e+10, 3.91089501e+10, 3.91089501e+10, 3.91089501e+10,\n",
       "          3.91089501e+10, 3.91089501e+10, 3.91089501e+10, 3.91089501e+10,\n",
       "          3.91089501e+10, 3.91089501e+10, 3.91089501e+10, 3.91089501e+10,\n",
       "          3.91089501e+10, 3.91089501e+10, 3.91089501e+10, 3.91089501e+10,\n",
       "          3.91089501e+10, 3.91089501e+10, 3.91089501e+10, 3.91089501e+10,\n",
       "          3.91089501e+10, 3.91089501e+10, 3.91089501e+10, 3.91089501e+10,\n",
       "          3.91089501e+10, 3.91089501e+10, 3.91089501e+10, 3.91089501e+10]),\n",
       "   'rank_test_score': array([93,  1, 99,  1, 97, 93, 93, 93,  1, 97,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          99,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "         dtype=int32)}},\n",
       " 'Lasso': {'best_estimator': Lasso(alpha=0.004516385464055256),\n",
       "  'best_params': OrderedDict([('alpha', 0.004516385464055256),\n",
       "               ('selection', 'cyclic')]),\n",
       "  'best_score': -0.4207208105250144,\n",
       "  'optimization_history': {'mean_fit_time': array([1.21127563, 5.8274318 , 0.78652804, 6.11050653, 5.6017041 ,\n",
       "          0.18650851, 0.11309879, 1.40092103, 6.34453788, 5.10763249,\n",
       "          3.01037061, 2.75814443, 6.40835922, 4.01885231, 0.31142471,\n",
       "          5.82533393, 1.72618773, 6.57130995, 0.33137956, 5.93727543,\n",
       "          5.8329947 , 3.49259751, 0.75262825, 6.15110028, 3.33727994,\n",
       "          3.28162184, 4.75747943, 2.67696633, 5.72333372, 5.92547171,\n",
       "          2.26485226, 6.70393047, 2.71758103, 5.56167297, 0.15737593,\n",
       "          3.82746665, 2.70700796, 2.70073256, 2.68259091, 2.67564299,\n",
       "          5.62365553, 2.67784383, 2.69302876, 2.69600992, 0.09971464,\n",
       "          2.71251605, 2.71036887, 2.70997436, 0.18343763, 2.70886297,\n",
       "          3.59615917, 2.73988295, 2.76206181, 0.38675845, 2.70270748,\n",
       "          2.69961221, 2.69372339, 0.22770839, 2.68834906, 2.6708164 ,\n",
       "          2.67207558, 2.67879429, 2.68771474, 2.68619943, 2.69278686,\n",
       "          2.68486099, 2.69961874, 4.39887283, 3.95943792, 2.67529752,\n",
       "          2.68079696, 2.74814754, 2.67506278, 2.66646035, 2.70814896,\n",
       "          2.67209396, 2.7426378 , 2.71438043, 2.69077032, 2.70790229,\n",
       "          2.71900446, 2.69938023, 2.7323554 , 0.21553121, 2.74563637,\n",
       "          2.68205469, 2.69709845, 2.72552915, 2.6851218 , 2.69201553,\n",
       "          2.7214081 , 2.82072241, 2.82513993, 2.77747571, 2.8557657 ,\n",
       "          2.83245554, 2.7948189 , 2.80310009, 2.76630499, 2.83169715]),\n",
       "   'std_fit_time': array([0.2401615 , 0.79161736, 0.18113842, 0.75788057, 0.76264532,\n",
       "          0.04916723, 0.02629884, 0.23899418, 0.75526846, 0.82373702,\n",
       "          0.71642467, 0.57711321, 0.73398039, 0.73710835, 0.08384205,\n",
       "          0.967973  , 0.26966212, 0.74034282, 0.0754512 , 0.77733342,\n",
       "          0.80936526, 0.8723942 , 0.21436474, 0.74399536, 0.93681995,\n",
       "          0.50954104, 1.10593055, 0.53873574, 0.75860884, 0.7387696 ,\n",
       "          0.42158288, 0.75214968, 0.62249946, 0.83213486, 0.02079895,\n",
       "          0.92674211, 0.57561965, 0.60546516, 0.56972816, 0.57002608,\n",
       "          0.81777987, 0.5710517 , 0.55060373, 0.57003668, 0.01504886,\n",
       "          0.60278659, 0.60443856, 0.62167888, 0.0408461 , 0.61102545,\n",
       "          0.74369968, 0.59281336, 0.64932316, 0.05901503, 0.59526531,\n",
       "          0.59417981, 0.60972371, 0.04812057, 0.59933123, 0.58331483,\n",
       "          0.58929057, 0.56775212, 0.57691825, 0.58611952, 0.58677114,\n",
       "          0.57898104, 0.56993961, 1.26423349, 0.74167253, 0.5558013 ,\n",
       "          0.54987059, 0.60413723, 0.58806087, 0.52701738, 0.57273753,\n",
       "          0.56528868, 0.62471644, 0.55915429, 0.55828677, 0.59871045,\n",
       "          0.61318303, 0.5502626 , 0.59488034, 0.04835825, 0.56111656,\n",
       "          0.54278988, 0.5529967 , 0.5358479 , 0.53522579, 0.55189513,\n",
       "          0.59714863, 0.60336184, 0.62300932, 0.59441693, 0.66367639,\n",
       "          0.65567264, 0.57385385, 0.61281028, 0.58747788, 0.63314662]),\n",
       "   'mean_score_time': array([0.00539327, 0.00590475, 0.00601726, 0.00625432, 0.00538051,\n",
       "          0.00487385, 0.00623786, 0.00592294, 0.0050277 , 0.00537455,\n",
       "          0.00490878, 0.00501482, 0.00495553, 0.0052501 , 0.00524197,\n",
       "          0.00722678, 0.00435538, 0.00515945, 0.00575724, 0.00505517,\n",
       "          0.00447452, 0.00583491, 0.00549984, 0.00644245, 0.00473773,\n",
       "          0.0055896 , 0.00497963, 0.00610018, 0.00557477, 0.00505745,\n",
       "          0.00575452, 0.00503454, 0.00543494, 0.00492625, 0.00430083,\n",
       "          0.00536234, 0.00620587, 0.00610938, 0.00516031, 0.0052943 ,\n",
       "          0.00555692, 0.00597539, 0.00634301, 0.00470865, 0.00553436,\n",
       "          0.00534449, 0.00510228, 0.0051995 , 0.00623739, 0.00442963,\n",
       "          0.00613482, 0.00522108, 0.00627599, 0.00577645, 0.00582957,\n",
       "          0.00570354, 0.00534039, 0.00598519, 0.00518928, 0.00569017,\n",
       "          0.00514185, 0.00612772, 0.0052515 , 0.00548282, 0.00618913,\n",
       "          0.00561874, 0.00575905, 0.00594831, 0.005917  , 0.006038  ,\n",
       "          0.00611124, 0.00722828, 0.00567489, 0.00598044, 0.00448058,\n",
       "          0.00622261, 0.00636744, 0.00606279, 0.00569298, 0.00518429,\n",
       "          0.00665395, 0.00585082, 0.00532987, 0.00523858, 0.00707421,\n",
       "          0.00510433, 0.00531139, 0.00616739, 0.00497777, 0.00515163,\n",
       "          0.00488594, 0.00709071, 0.00703056, 0.00691214, 0.00682518,\n",
       "          0.00624478, 0.00535853, 0.006478  , 0.00552404, 0.00821493]),\n",
       "   'std_score_time': array([0.00201488, 0.00277239, 0.00328969, 0.00259168, 0.00120107,\n",
       "          0.00109874, 0.00287659, 0.00164984, 0.00181685, 0.00146082,\n",
       "          0.00152907, 0.00123893, 0.00157898, 0.00178105, 0.00178512,\n",
       "          0.00347831, 0.00062754, 0.00202023, 0.00263284, 0.00119445,\n",
       "          0.00098406, 0.00226193, 0.002235  , 0.00273823, 0.00145259,\n",
       "          0.00189082, 0.00157763, 0.00197792, 0.00211802, 0.00175878,\n",
       "          0.00243537, 0.0016186 , 0.0020368 , 0.00135362, 0.00089605,\n",
       "          0.00248063, 0.00277095, 0.00276837, 0.001859  , 0.00188922,\n",
       "          0.00229655, 0.00233712, 0.00246914, 0.00093933, 0.00247979,\n",
       "          0.00126591, 0.00145634, 0.00181679, 0.00230401, 0.00060185,\n",
       "          0.00221344, 0.00228156, 0.00236818, 0.00231912, 0.00229825,\n",
       "          0.00243671, 0.00216624, 0.00275178, 0.00208333, 0.00222881,\n",
       "          0.00182805, 0.00331588, 0.00171208, 0.00251573, 0.00239341,\n",
       "          0.0022815 , 0.00179433, 0.00248189, 0.00229841, 0.00215835,\n",
       "          0.00202117, 0.00368664, 0.00218419, 0.00220494, 0.00070518,\n",
       "          0.00411313, 0.00297516, 0.00214865, 0.00223417, 0.00153966,\n",
       "          0.00400971, 0.0021485 , 0.00251685, 0.0024679 , 0.00287038,\n",
       "          0.00184334, 0.00173306, 0.00190653, 0.00165648, 0.00115201,\n",
       "          0.00163921, 0.0053082 , 0.00414595, 0.00354126, 0.00332107,\n",
       "          0.0026823 , 0.00204084, 0.00231522, 0.00223923, 0.00616991]),\n",
       "   'param_alpha': masked_array(data=[0.013300153699806186, 0.0010801564116460836,\n",
       "                      0.01302467718894178, 0.000388757918194155,\n",
       "                      0.0008512480164062713, 0.2252503789114733,\n",
       "                      0.7387966194299759, 0.011014281850164074,\n",
       "                      0.00023346296006549204, 0.0030071002697548916,\n",
       "                      0.004365413887213729, 0.004516385464055256, 0.0001,\n",
       "                      0.004336876390279035, 0.038962380825267665,\n",
       "                      0.0018280297903347845, 0.006164333299785644,\n",
       "                      0.00013284018953331036, 0.0786747571429388,\n",
       "                      0.0006158230229357328, 0.002420226365462177,\n",
       "                      0.0041472294536595315, 0.022192080200221845,\n",
       "                      0.00017665450962805405, 0.005447305336364734,\n",
       "                      0.004532801553106048, 0.0034818929403765465,\n",
       "                      0.004650705112355945, 0.0004932552385103706,\n",
       "                      0.00029653748040013366, 0.007388458614891506,\n",
       "                      0.00010022193621068927, 0.00459372406961635,\n",
       "                      0.0013403893784711607, 0.11956085157406172,\n",
       "                      0.004639574652678545, 0.004604784388755607,\n",
       "                      0.004606452239418896, 0.004605459901505157,\n",
       "                      0.004605608328754226, 0.0015954587281245898,\n",
       "                      0.004622659491068295, 0.004622243376027286,\n",
       "                      0.004622701104988466, 0.9979104460090739,\n",
       "                      0.004580465817197059, 0.0045801523702229795,\n",
       "                      0.004579939079120088, 0.1976784320108798,\n",
       "                      0.00456228006574056, 0.0046253241447308776,\n",
       "                      0.004574016754415202, 0.004576310889388671,\n",
       "                      0.028237101656246936, 0.004588073293548496,\n",
       "                      0.004589400362031476, 0.004595485659167309,\n",
       "                      0.11951222119117569, 0.0045876286087066665,\n",
       "                      0.004590354109834008, 0.00459260398299531,\n",
       "                      0.004606527008159847, 0.004597001587103229,\n",
       "                      0.004589738505670578, 0.004600516174586941,\n",
       "                      0.004607084135093669, 0.004605003037315735,\n",
       "                      0.004637086738546316, 0.004638486570226198,\n",
       "                      0.004619005287373044, 0.00462596892028275,\n",
       "                      0.004618272951575234, 0.00460246730529319,\n",
       "                      0.004637423212802549, 0.004621776751031926,\n",
       "                      0.0046368953131263714, 0.004545708354118223,\n",
       "                      0.004635435592556104, 0.004650575346366738,\n",
       "                      0.0045326349267777325, 0.004576681637612917,\n",
       "                      0.004646639955111775, 0.0045357768958252925,\n",
       "                      0.14744994504640116, 0.004676807630053527,\n",
       "                      0.004681331465883523, 0.004676141476120605,\n",
       "                      0.004674002523232806, 0.00466771446684049,\n",
       "                      0.004654432494687596, 0.004537169253780901,\n",
       "                      0.004666708428509917, 0.0045306807847766755,\n",
       "                      0.004659152545322793, 0.0045362130892238756,\n",
       "                      0.0045470499847337, 0.004658538114967178,\n",
       "                      0.004525059886022698, 0.004672772315589658,\n",
       "                      0.004525902884665383],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_selection': masked_array(data=['random', 'random', 'cyclic', 'random', 'cyclic',\n",
       "                      'random', 'random', 'random', 'random', 'cyclic',\n",
       "                      'cyclic', 'cyclic', 'cyclic', 'random', 'cyclic',\n",
       "                      'cyclic', 'cyclic', 'random', 'random', 'random',\n",
       "                      'random', 'cyclic', 'random', 'cyclic', 'random',\n",
       "                      'random', 'random', 'cyclic', 'cyclic', 'cyclic',\n",
       "                      'random', 'random', 'cyclic', 'cyclic', 'cyclic',\n",
       "                      'random', 'cyclic', 'cyclic', 'cyclic', 'cyclic',\n",
       "                      'random', 'cyclic', 'cyclic', 'cyclic', 'cyclic',\n",
       "                      'cyclic', 'cyclic', 'cyclic', 'random', 'cyclic',\n",
       "                      'random', 'cyclic', 'cyclic', 'cyclic', 'cyclic',\n",
       "                      'cyclic', 'cyclic', 'random', 'cyclic', 'cyclic',\n",
       "                      'cyclic', 'cyclic', 'cyclic', 'cyclic', 'cyclic',\n",
       "                      'cyclic', 'cyclic', 'random', 'random', 'cyclic',\n",
       "                      'cyclic', 'cyclic', 'cyclic', 'cyclic', 'cyclic',\n",
       "                      'cyclic', 'cyclic', 'cyclic', 'cyclic', 'cyclic',\n",
       "                      'cyclic', 'cyclic', 'cyclic', 'random', 'cyclic',\n",
       "                      'cyclic', 'cyclic', 'cyclic', 'cyclic', 'cyclic',\n",
       "                      'cyclic', 'cyclic', 'cyclic', 'cyclic', 'cyclic',\n",
       "                      'cyclic', 'cyclic', 'cyclic', 'cyclic', 'cyclic'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [OrderedDict([('alpha', 0.013300153699806186),\n",
       "                 ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.0010801564116460836), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.01302467718894178), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.000388757918194155), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.0008512480164062713), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.2252503789114733), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.7387966194299759), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.011014281850164074), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.00023346296006549204), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.0030071002697548916), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004365413887213729), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004516385464055256), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.0001), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004336876390279035), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.038962380825267665), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.0018280297903347845), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.006164333299785644), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.00013284018953331036), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.0786747571429388), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.0006158230229357328), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.002420226365462177), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.0041472294536595315), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.022192080200221845), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.00017665450962805405), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.005447305336364734), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.004532801553106048), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.0034818929403765465), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.004650705112355945), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.0004932552385103706), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.00029653748040013366), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.007388458614891506), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.00010022193621068927), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.00459372406961635), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.0013403893784711607), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.11956085157406172), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004639574652678545), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.004604784388755607), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004606452239418896), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004605459901505157), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004605608328754226), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.0015954587281245898), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.004622659491068295), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004622243376027286), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004622701104988466), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.9979104460090739), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004580465817197059), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.0045801523702229795), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004579939079120088), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.1976784320108798), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.00456228006574056), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.0046253241447308776), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.004574016754415202), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004576310889388671), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.028237101656246936), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004588073293548496), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004589400362031476), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004595485659167309), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.11951222119117569), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.0045876286087066665), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004590354109834008), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.00459260398299531), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004606527008159847), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004597001587103229), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004589738505670578), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004600516174586941), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004607084135093669), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004605003037315735), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004637086738546316), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.004638486570226198), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.004619005287373044), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.00462596892028275), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004618272951575234), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.00460246730529319), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004637423212802549), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004621776751031926), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.0046368953131263714), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004545708354118223), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004635435592556104), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004650575346366738), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.0045326349267777325), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004576681637612917), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004646639955111775), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.0045357768958252925), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.14744994504640116), ('selection', 'random')]),\n",
       "    OrderedDict([('alpha', 0.004676807630053527), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004681331465883523), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004676141476120605), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004674002523232806), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.00466771446684049), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004654432494687596), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004537169253780901), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004666708428509917), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.0045306807847766755), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004659152545322793), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.0045362130892238756), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.0045470499847337), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004658538114967178), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004525059886022698), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004672772315589658), ('selection', 'cyclic')]),\n",
       "    OrderedDict([('alpha', 0.004525902884665383), ('selection', 'cyclic')])],\n",
       "   'split0_test_score': array([-0.52318811, -0.47709939, -0.5228408 , -0.47400213, -0.47816301,\n",
       "          -0.70331169, -0.84120679, -0.52204092, -0.47390028, -0.47647682,\n",
       "          -0.48167962, -0.48306832, -0.48855914, -0.48157297, -0.57236181,\n",
       "          -0.48574999, -0.50752776, -0.50884761, -0.5906184 , -0.47056704,\n",
       "          -0.47833846, -0.48048607, -0.54589985, -0.48140647, -0.49683126,\n",
       "          -0.4834812 , -0.47778895, -0.48437504, -0.47028029, -0.47327574,\n",
       "          -0.51990675, -0.49087973, -0.48385363, -0.48455638, -0.62999544,\n",
       "          -0.48442647, -0.48395771, -0.48397394, -0.48396428, -0.48396573,\n",
       "          -0.48434047, -0.48412638, -0.48412449, -0.48412679, -0.84120679,\n",
       "          -0.48373023, -0.48372696, -0.48372447, -0.68359822, -0.48352364,\n",
       "          -0.48458029, -0.48365624, -0.48368265, -0.56278261, -0.48380019,\n",
       "          -0.48381263, -0.48387045, -0.62994076, -0.48379602, -0.48382159,\n",
       "          -0.48384295, -0.48397467, -0.48388497, -0.4838158 , -0.48391656,\n",
       "          -0.4839801 , -0.48395984, -0.48453575, -0.48438356, -0.48409254,\n",
       "          -0.48415916, -0.48408532, -0.48393533, -0.48425954, -0.48411987,\n",
       "          -0.48425475, -0.48335356, -0.48424389, -0.48437383, -0.48322641,\n",
       "          -0.48368692, -0.48433957, -0.48325648, -0.64995173, -0.48463044,\n",
       "          -0.48468228, -0.48462329, -0.48460031, -0.48452602, -0.48440759,\n",
       "          -0.4832699 , -0.48451875, -0.48320789, -0.4844498 , -0.48326068,\n",
       "          -0.48336691, -0.48444399, -0.48315261, -0.48458709, -0.48316349]),\n",
       "   'split1_test_score': array([-0.41852464, -0.38512503, -0.41716412, -0.38942546, -0.38910517,\n",
       "          -0.62876706, -0.78487111, -0.40440884, -0.39592225, -0.40255384,\n",
       "          -0.40376844, -0.40276438, -0.41700773, -0.40397485, -0.46335017,\n",
       "          -0.39304836, -0.3934071 , -0.39167393, -0.48765469, -0.3855042 ,\n",
       "          -0.3979929 , -0.40560273, -0.43742744, -0.39938237, -0.39755689,\n",
       "          -0.40218966, -0.4047182 , -0.40202082, -0.38590782, -0.38908032,\n",
       "          -0.38937957, -0.41069098, -0.40231134, -0.38780077, -0.51932247,\n",
       "          -0.40169308, -0.40224506, -0.40223594, -0.40224136, -0.40224055,\n",
       "          -0.38544292, -0.40215294, -0.40215511, -0.40215272, -0.78487111,\n",
       "          -0.40239249, -0.40239446, -0.4023958 , -0.60326732, -0.40249866,\n",
       "          -0.40196961, -0.4024296 , -0.40241493, -0.45523992, -0.40234938,\n",
       "          -0.4023413 , -0.40230097, -0.51930795, -0.40235209, -0.40233551,\n",
       "          -0.40232567, -0.40223553, -0.4022886 , -0.40233925, -0.40226862,\n",
       "          -0.40223249, -0.40224386, -0.40166087, -0.40200044, -0.40217204,\n",
       "          -0.40213576, -0.40217588, -0.40225779, -0.40208042, -0.40215754,\n",
       "          -0.40208311, -0.40259116, -0.40209054, -0.40202146, -0.40266739,\n",
       "          -0.40241256, -0.40204089, -0.40264726, -0.54872998, -0.40191056,\n",
       "          -0.40189217, -0.40191382, -0.40192428, -0.40194781, -0.40200587,\n",
       "          -0.40263834, -0.40195274, -0.40267992, -0.40198621, -0.40264446,\n",
       "          -0.40258264, -0.40198921, -0.40271236, -0.40192676, -0.40270696]),\n",
       "   'split2_test_score': array([-0.41955034, -0.40453563, -0.41924842, -0.40188821, -0.38343966,\n",
       "          -0.68531013, -0.83150653, -0.41633623, -0.41480421, -0.40373963,\n",
       "          -0.40010667, -0.39903101, -0.38443978, -0.40036615, -0.46596695,\n",
       "          -0.40654734, -0.39530225, -0.4077588 , -0.49649942, -0.40869235,\n",
       "          -0.40696578, -0.40208026, -0.44358362, -0.38727009, -0.39677621,\n",
       "          -0.39889395, -0.40359148, -0.3988918 , -0.37220426, -0.3761157 ,\n",
       "          -0.39978595, -0.39535198, -0.3989477 , -0.40258973, -0.55431448,\n",
       "          -0.39876016, -0.39893676, -0.3989345 , -0.39893584, -0.39893564,\n",
       "          -0.41288403, -0.39891801, -0.39891858, -0.39891796, -0.83150653,\n",
       "          -0.39896188, -0.39896232, -0.39896261, -0.66244149, -0.39898211,\n",
       "          -0.39892665, -0.39896949, -0.39896633, -0.45684968, -0.39895401,\n",
       "          -0.39895222, -0.39894665, -0.55425313, -0.39895461, -0.39895093,\n",
       "          -0.39894921, -0.3989344 , -0.3989446 , -0.39895176, -0.39894119,\n",
       "          -0.39893364, -0.39893646, -0.39901406, -0.39863078, -0.39892157,\n",
       "          -0.39891493, -0.39892257, -0.39893855, -0.39890375, -0.39891921,\n",
       "          -0.39890446, -0.39900037, -0.39890643, -0.39889198, -0.39901394,\n",
       "          -0.39896582, -0.39889578, -0.39901064, -0.5930213 , -0.39887259,\n",
       "          -0.39886672, -0.3988737 , -0.39887543, -0.39887952, -0.3988898 ,\n",
       "          -0.39900989, -0.3988809 , -0.39901671, -0.3988865 , -0.39901004,\n",
       "          -0.3989985 , -0.39888579, -0.39902232, -0.39887722, -0.39902114]),\n",
       "   'split3_test_score': array([-0.43226452, -0.41901284, -0.43249133, -0.40893651, -0.41349133,\n",
       "          -0.63838464, -0.73479623, -0.43123378, -0.39636944, -0.41308029,\n",
       "          -0.40830427, -0.4074234 , -0.38358009, -0.40861739, -0.50520873,\n",
       "          -0.41823967, -0.40013917, -0.39285523, -0.55941021, -0.40972918,\n",
       "          -0.41566827, -0.40831355, -0.45748267, -0.39818539, -0.39840229,\n",
       "          -0.4071978 , -0.41342523, -0.40656998, -0.40337089, -0.39313764,\n",
       "          -0.40687106, -0.41545492, -0.40694004, -0.42115589, -0.57501168,\n",
       "          -0.40676694, -0.40687126, -0.40685913, -0.40686512, -0.40686423,\n",
       "          -0.42116997, -0.40674702, -0.40675096, -0.40674664, -0.73479623,\n",
       "          -0.40702277, -0.4070247 , -0.40702601, -0.62781081, -0.40713139,\n",
       "          -0.40702397, -0.40706054, -0.40704848, -0.47712625, -0.4069764 ,\n",
       "          -0.40696838, -0.40692943, -0.57500144, -0.40697909, -0.40696262,\n",
       "          -0.40694904, -0.40685868, -0.40692031, -0.40696634, -0.40689699,\n",
       "          -0.4068553 , -0.40686994, -0.40661543, -0.40705821, -0.40678117,\n",
       "          -0.406722  , -0.4067879 , -0.40688524, -0.40664834, -0.40675538,\n",
       "          -0.40665171, -0.4072327 , -0.40666024, -0.40656992, -0.40731609,\n",
       "          -0.40704615, -0.4065932 , -0.40729534, -0.59009822, -0.40636512,\n",
       "          -0.40630884, -0.40637344, -0.40640021, -0.40647374, -0.40654887,\n",
       "          -0.40728523, -0.40648181, -0.40732843, -0.40652426, -0.40729217,\n",
       "          -0.40722322, -0.40652748, -0.40736596, -0.40641565, -0.40735968]),\n",
       "   'split4_test_score': array([-0.47107882, -0.48390485, -0.47046304, -0.49450753, -0.49920821,\n",
       "          -0.78947284, -0.96401596, -0.46767272, -0.47146689, -0.44856672,\n",
       "          -0.43817279, -0.43839733, -0.47889783, -0.43969529, -0.50403451,\n",
       "          -0.47000256, -0.43874983, -0.48683989, -0.55151474, -0.48605043,\n",
       "          -0.45719818, -0.43922277, -0.48927745, -0.48049757, -0.43813372,\n",
       "          -0.44031867, -0.44352642, -0.43915936, -0.50489496, -0.49444597,\n",
       "          -0.44243847, -0.48899714, -0.43881257, -0.48718847, -0.63858079,\n",
       "          -0.44083754, -0.43883785, -0.43884697, -0.43884155, -0.43884236,\n",
       "          -0.47212454, -0.43894604, -0.43894359, -0.43894628, -0.96401596,\n",
       "          -0.4388087 , -0.43880708, -0.43880597, -0.75849816, -0.4387261 ,\n",
       "          -0.43990028, -0.43878853, -0.43881777, -0.49919693, -0.438808  ,\n",
       "          -0.43880662, -0.43881341, -0.63852844, -0.43880566, -0.43880321,\n",
       "          -0.43880661, -0.43884738, -0.43882176, -0.43880841, -0.43883232,\n",
       "          -0.43885041, -0.43883905, -0.43867251, -0.44057706, -0.43891598,\n",
       "          -0.43897488, -0.43891189, -0.43883413, -0.43905185, -0.43894085,\n",
       "          -0.43904873, -0.43863257, -0.43904011, -0.43915859, -0.4385145 ,\n",
       "          -0.43881212, -0.4391252 , -0.43853816, -0.68151597, -0.43941803,\n",
       "          -0.43946782, -0.4394042 , -0.43936165, -0.43926272, -0.43918148,\n",
       "          -0.43855665, -0.43925621, -0.4384944 , -0.43920981, -0.43854664,\n",
       "          -0.43864399, -0.4392061 , -0.4384569 , -0.43933444, -0.43845918]),\n",
       "   'split5_test_score': array([-0.40762231, -0.41841571, -0.4062891 , -0.42884913, -0.42667926,\n",
       "          -0.87127257, -1.00261767, -0.39663917, -0.4228141 , -0.38612124,\n",
       "          -0.37876477, -0.37860467, -0.44490845, -0.37886667, -0.58101323,\n",
       "          -0.41042464, -0.37632646, -0.42818992, -0.68514089, -0.42413343,\n",
       "          -0.39336705, -0.3791916 , -0.46790868, -0.44075651, -0.3770031 ,\n",
       "          -0.3783176 , -0.38273372, -0.37824534, -0.42850596, -0.4328373 ,\n",
       "          -0.37660938, -0.44292375, -0.37839923, -0.42162442, -0.75435771,\n",
       "          -0.37817699, -0.37837413, -0.37837109, -0.37837267, -0.37837235,\n",
       "          -0.41282325, -0.37832587, -0.37832666, -0.37832578, -1.00261767,\n",
       "          -0.37843019, -0.37843093, -0.37843142, -0.84867946, -0.37847524,\n",
       "          -0.37827121, -0.37844527, -0.3784399 , -0.51401445, -0.37841237,\n",
       "          -0.37840941, -0.37839531, -0.75425955, -0.37841336, -0.37840729,\n",
       "          -0.37840172, -0.37837102, -0.37839195, -0.37840866, -0.37838358,\n",
       "          -0.37836909, -0.37837366, -0.37823755, -0.37836306, -0.37833509,\n",
       "          -0.37831733, -0.37833725, -0.37837925, -0.37828731, -0.37832831,\n",
       "          -0.37828898, -0.37851994, -0.37829356, -0.37824576, -0.37855696,\n",
       "          -0.37843904, -0.37825814, -0.37854809, -0.79256928, -0.37815522,\n",
       "          -0.37813691, -0.3781586 , -0.37816728, -0.37819088, -0.37823321,\n",
       "          -0.37854417, -0.37819381, -0.37856252, -0.37821794, -0.37854686,\n",
       "          -0.37851623, -0.37821992, -0.37857903, -0.37817374, -0.37857659]),\n",
       "   'split6_test_score': array([-0.52348501, -0.50907341, -0.52369313, -0.52866316, -0.48182883,\n",
       "          -0.61965781, -0.73745063, -0.52872649, -0.5514144 , -0.50967623,\n",
       "          -0.50456379, -0.50461901, -0.49672359, -0.50423519, -0.47654283,\n",
       "          -0.50252383, -0.52386528, -0.57850569, -0.49529686, -0.4925515 ,\n",
       "          -0.51318167, -0.50458739, -0.50365665, -0.51261696, -0.51394587,\n",
       "          -0.50490055, -0.50959973, -0.50436358, -0.49546477, -0.50038423,\n",
       "          -0.52856846, -0.51947618, -0.50452495, -0.48338652, -0.52797099,\n",
       "          -0.50491846, -0.50449293, -0.50448818, -0.504491  , -0.50449058,\n",
       "          -0.50719947, -0.50444264, -0.50444379, -0.50444253, -0.73745063,\n",
       "          -0.5045615 , -0.50456243, -0.50456306, -0.59637321, -0.5046135 ,\n",
       "          -0.50381921, -0.50458069, -0.50457384, -0.48699159, -0.50453908,\n",
       "          -0.5045352 , -0.5045198 , -0.52791688, -0.50454039, -0.50453242,\n",
       "          -0.50452823, -0.50448796, -0.50451541, -0.50453421, -0.50450522,\n",
       "          -0.50448638, -0.50449231, -0.50435801, -0.50482759, -0.50445277,\n",
       "          -0.50443353, -0.50445479, -0.50449957, -0.50440142, -0.50444507,\n",
       "          -0.50440293, -0.50466263, -0.50440708, -0.50436395, -0.50467003,\n",
       "          -0.50457274, -0.50437517, -0.50466267, -0.54960897, -0.50428957,\n",
       "          -0.50427687, -0.50429139, -0.50429723, -0.50431506, -0.50435307,\n",
       "          -0.50466472, -0.50431782, -0.50466794, -0.50433971, -0.50466324,\n",
       "          -0.50465829, -0.50434143, -0.50466335, -0.5043012 , -0.50466393]),\n",
       "   'split7_test_score': array([-0.41346407, -0.36849105, -0.41302221, -0.37793115, -0.37292921,\n",
       "          -0.69716744, -0.77875473, -0.40853971, -0.3914882 , -0.38103307,\n",
       "          -0.38030007, -0.38026146, -0.40893945, -0.38038398, -0.44033909,\n",
       "          -0.37163479, -0.38574662, -0.39972331, -0.50171669, -0.37372333,\n",
       "          -0.37824278, -0.38080106, -0.4164381 , -0.40903037, -0.38322508,\n",
       "          -0.38027621, -0.37933292, -0.38042371, -0.38423757, -0.39507789,\n",
       "          -0.39309723, -0.39653923, -0.38032404, -0.37025945, -0.56644698,\n",
       "          -0.38035327, -0.38034345, -0.38034638, -0.38034464, -0.3803449 ,\n",
       "          -0.36835831, -0.380375  , -0.38037426, -0.38037507, -0.77875473,\n",
       "          -0.38030108, -0.38030055, -0.38030019, -0.66506533, -0.38028167,\n",
       "          -0.38033511, -0.38029038, -0.3802941 , -0.4303185 , -0.3803142 ,\n",
       "          -0.38031651, -0.38032712, -0.56635377, -0.38031343, -0.38031816,\n",
       "          -0.38032209, -0.38034652, -0.38032977, -0.38031709, -0.38033593,\n",
       "          -0.3803475 , -0.38034383, -0.38041976, -0.38048349, -0.38036854,\n",
       "          -0.38038084, -0.38036725, -0.38033937, -0.38040104, -0.38037344,\n",
       "          -0.38040011, -0.38027455, -0.38039754, -0.38042348, -0.38026906,\n",
       "          -0.38029472, -0.38041729, -0.38026988, -0.60644724, -0.38046833,\n",
       "          -0.38047531, -0.38046729, -0.38046395, -0.38045365, -0.38043027,\n",
       "          -0.38027053, -0.38045188, -0.38026814, -0.38043859, -0.38027008,\n",
       "          -0.38027518, -0.3804375 , -0.38026552, -0.38046178, -0.38026592]),\n",
       "   'split8_test_score': array([-0.44735377, -0.44241942, -0.44572843, -0.44280318, -0.45095996,\n",
       "          -0.74286991, -0.76809789, -0.43133293, -0.44337622, -0.39364636,\n",
       "          -0.38479005, -0.385271  , -0.38914428, -0.38498116, -0.50794073,\n",
       "          -0.41907167, -0.40296475, -0.41819246, -0.57480715, -0.44090316,\n",
       "          -0.40635552, -0.38408875, -0.46224495, -0.40775516, -0.39407032,\n",
       "          -0.38521898, -0.3877774 , -0.38624336, -0.44870031, -0.43755691,\n",
       "          -0.41118835, -0.39405473, -0.38574591, -0.43195123, -0.62502579,\n",
       "          -0.38626655, -0.38582452, -0.38583446, -0.38582855, -0.38582943,\n",
       "          -0.42233977, -0.38595067, -0.38594782, -0.38595096, -0.76809789,\n",
       "          -0.38564686, -0.38564494, -0.38564364, -0.72325075, -0.38552782,\n",
       "          -0.38632777, -0.38559823, -0.38561559, -0.4785015 , -0.3857054 ,\n",
       "          -0.38571354, -0.38575662, -0.62495218, -0.3856968 , -0.38571938,\n",
       "          -0.38573315, -0.38583491, -0.3857658 , -0.38571561, -0.38579293,\n",
       "          -0.38583823, -0.38582582, -0.38661168, -0.38606185, -0.38592085,\n",
       "          -0.3859799 , -0.38591633, -0.38580467, -0.38609917, -0.38593885,\n",
       "          -0.38608827, -0.38543493, -0.38608083, -0.38624211, -0.38536005,\n",
       "          -0.38561787, -0.3861985 , -0.38537964, -0.66087632, -0.38653858,\n",
       "          -0.38659402, -0.38653211, -0.38650522, -0.38643183, -0.38628522,\n",
       "          -0.38538582, -0.38642204, -0.38534578, -0.3863368 , -0.38538158,\n",
       "          -0.38544082, -0.38633084, -0.3853152 , -0.3864932 , -0.3853245 ]),\n",
       "   'split9_test_score': array([-0.44598771, -0.50575465, -0.44623021, -0.53365521, -0.52821298,\n",
       "          -0.74878473, -0.86970326, -0.44379375, -0.54893431, -0.43591892,\n",
       "          -0.42870193, -0.42776752, -0.56930145, -0.42866048, -0.49800118,\n",
       "          -0.48295785, -0.43264175, -0.56238747, -0.54574227, -0.54194078,\n",
       "          -0.45380877, -0.43026266, -0.4604065 , -0.57227138, -0.42820097,\n",
       "          -0.4277635 , -0.43302805, -0.42715926, -0.55655843, -0.57143303,\n",
       "          -0.43825275, -0.5680728 , -0.42739198, -0.5041122 , -0.61122113,\n",
       "          -0.42711397, -0.42734641, -0.42733955, -0.42734363, -0.42734302,\n",
       "          -0.47933253, -0.42727337, -0.42727507, -0.4272732 , -0.86970326,\n",
       "          -0.4274471 , -0.42744842, -0.42744931, -0.72165743, -0.42752393,\n",
       "          -0.42727994, -0.42747443, -0.42746468, -0.47471544, -0.42741553,\n",
       "          -0.42740999, -0.42738466, -0.61112844, -0.42741739, -0.42740601,\n",
       "          -0.42739664, -0.42733924, -0.42737858, -0.42740858, -0.42736403,\n",
       "          -0.42733695, -0.42734551, -0.42726045, -0.42703775, -0.42728832,\n",
       "          -0.42725985, -0.42729122, -0.42735597, -0.42721323, -0.42727698,\n",
       "          -0.42721537, -0.42759916, -0.42722131, -0.42715979, -0.42767374,\n",
       "          -0.42746311, -0.42717578, -0.42765597, -0.65855612, -0.42709018,\n",
       "          -0.4270868 , -0.42709076, -0.42709246, -0.42709655, -0.42714368,\n",
       "          -0.4276481 , -0.42709812, -0.42768481, -0.42712361, -0.4276535 ,\n",
       "          -0.42759163, -0.42712622, -0.42771781, -0.42709329, -0.42771301]),\n",
       "   'mean_test_score': array([-0.45025193, -0.4413832 , -0.44971708, -0.44806617, -0.44240176,\n",
       "          -0.71249988, -0.83130208, -0.44507246, -0.45104903, -0.42508131,\n",
       "          -0.42091524, -0.42072081, -0.44615018, -0.42113541, -0.50147592,\n",
       "          -0.43602007, -0.4256671 , -0.45749743, -0.54884013, -0.44337954,\n",
       "          -0.43011194, -0.42146368, -0.46843259, -0.44891723, -0.42241457,\n",
       "          -0.42085581, -0.42355221, -0.42074522, -0.44501253, -0.44633447,\n",
       "          -0.4306098 , -0.45224415, -0.42072514, -0.43946251, -0.60022474,\n",
       "          -0.42093134, -0.42072301, -0.42072301, -0.42072287, -0.42072288,\n",
       "          -0.43660153, -0.42072579, -0.42072603, -0.42072579, -0.83130208,\n",
       "          -0.42073028, -0.42073028, -0.42073025, -0.68906422, -0.42072841,\n",
       "          -0.42084341, -0.42072934, -0.42073183, -0.48357369, -0.42072746,\n",
       "          -0.42072658, -0.42072444, -0.60016425, -0.42072688, -0.42072571,\n",
       "          -0.42072553, -0.42072303, -0.42072417, -0.42072657, -0.42072374,\n",
       "          -0.42072301, -0.42072303, -0.42073861, -0.42094238, -0.42072489,\n",
       "          -0.42072782, -0.42072504, -0.42072299, -0.42073461, -0.42072555,\n",
       "          -0.42073384, -0.42073016, -0.42073415, -0.42074509, -0.42072682,\n",
       "          -0.4207311 , -0.42074195, -0.42072641, -0.63313751, -0.42077386,\n",
       "          -0.42077877, -0.42077286, -0.4207688 , -0.42075778, -0.42074791,\n",
       "          -0.42072734, -0.42075741, -0.42072565, -0.42075132, -0.42072693,\n",
       "          -0.42072974, -0.42075085, -0.42072511, -0.42076644, -0.42072544]),\n",
       "   'std_test_score': array([0.04072653, 0.04761763, 0.04098202, 0.05391569, 0.05071848,\n",
       "          0.07453538, 0.08692991, 0.04469291, 0.05686817, 0.0400251 ,\n",
       "          0.040823  , 0.04114044, 0.05814048, 0.04073864, 0.04301066,\n",
       "          0.0428637 , 0.04870503, 0.06772716, 0.05718111, 0.05060217,\n",
       "          0.0411127 , 0.04052589, 0.03490203, 0.05788474, 0.04522127,\n",
       "          0.04141914, 0.04073279, 0.04131895, 0.05806925, 0.05961262,\n",
       "          0.05067759, 0.05802815, 0.04126724, 0.0446626 , 0.06519251,\n",
       "          0.04154325, 0.04127691, 0.04127884, 0.04127775, 0.04127793,\n",
       "          0.04381175, 0.04129671, 0.04129654, 0.04129676, 0.08692991,\n",
       "          0.04125689, 0.0412565 , 0.04125619, 0.0731768 , 0.04123166,\n",
       "          0.04126033, 0.0412494 , 0.04125308, 0.03457646, 0.04126192,\n",
       "          0.041263  , 0.04126875, 0.06517671, 0.04126194, 0.04126367,\n",
       "          0.04126608, 0.04127892, 0.04127062, 0.04126337, 0.04127343,\n",
       "          0.04127963, 0.04127716, 0.04130184, 0.04147304, 0.04129247,\n",
       "          0.04130058, 0.04129147, 0.04127524, 0.04130886, 0.04129637,\n",
       "          0.04130888, 0.04120865, 0.04130744, 0.04131886, 0.04118337,\n",
       "          0.04125328, 0.04131572, 0.04118803, 0.06908903, 0.04134741,\n",
       "          0.04135478, 0.04134584, 0.04134174, 0.04133033, 0.04132121,\n",
       "          0.04119173, 0.04132961, 0.0411791 , 0.04132434, 0.04118931,\n",
       "          0.04121077, 0.04132386, 0.04116698, 0.04133909, 0.04116868]),\n",
       "   'rank_test_score': array([86, 76, 85, 83, 77, 98, 99, 80, 87, 69, 62,  1, 81, 65, 92, 73, 70,\n",
       "          89, 93, 78, 71, 66, 90, 84, 67, 61, 68, 49, 79, 82, 72, 88, 16, 75,\n",
       "          95, 63,  5,  7,  2,  3, 74, 23, 24, 22, 99, 40, 39, 38, 97, 34, 60,\n",
       "          35, 42, 91, 32, 27, 12, 94, 29, 21, 18,  9, 11, 26, 10,  6,  8, 46,\n",
       "          64, 13, 33, 14,  4, 45, 19, 43, 37, 44, 48, 28, 41, 47, 25, 96, 58,\n",
       "          59, 57, 56, 54, 50, 31, 53, 20, 52, 30, 36, 51, 15, 55, 17],\n",
       "         dtype=int32)}},\n",
       " 'PLS': {'best_estimator': PLSRegression(max_iter=444, n_components=6),\n",
       "  'best_params': OrderedDict([('max_iter', 444), ('n_components', 6)]),\n",
       "  'best_score': -0.5170449073295226,\n",
       "  'optimization_history': {'mean_fit_time': array([0.45245473, 0.42990756, 0.26136572, 0.39762516, 0.26950545,\n",
       "          0.44480503, 0.38700888, 0.35200849, 0.45417209, 0.32772191,\n",
       "          0.46528342, 0.44679854, 0.43673067, 0.28911767, 0.28196256,\n",
       "          0.223557  , 0.32863145, 0.44058628, 0.36817617, 0.28640354,\n",
       "          0.23538063, 0.42196555, 0.26854544, 0.30018718, 0.2593581 ,\n",
       "          0.42990367, 0.29509735, 0.41422122, 0.31950748, 0.39121668,\n",
       "          0.41093278, 0.34486907, 0.43333738, 0.32558918, 0.4729583 ,\n",
       "          0.45906844, 0.45023344, 0.46066079, 0.46140597, 0.44316814,\n",
       "          0.38142581, 0.44105666, 0.4515708 , 0.43225768, 0.26861129,\n",
       "          0.43209281, 0.43981879, 0.42568536, 0.43031712, 0.42784526,\n",
       "          0.4421164 , 0.43145328, 0.42151322, 0.22760091, 0.4405026 ,\n",
       "          0.43011439, 0.45707004, 0.38857353, 0.42594321, 0.41943665,\n",
       "          0.42304072, 0.46578729, 0.41300895, 0.41627622, 0.4380115 ,\n",
       "          0.42760172, 0.45926511, 0.32070794, 0.54038639, 0.44114749,\n",
       "          0.41969087, 0.47909865, 0.43355644, 0.42469449, 0.42404804,\n",
       "          0.42537587, 0.42995937, 0.43776159, 0.44311221, 0.41071579,\n",
       "          0.4465122 , 0.27518709, 0.3291173 , 0.41660917, 0.43348343,\n",
       "          0.4387542 , 0.41597993, 0.43431029, 0.44277813, 0.44028962,\n",
       "          0.41647291, 0.41804934, 0.42963567, 0.42510846, 0.44205661,\n",
       "          0.44207196, 0.44773214, 0.47256327, 0.4286108 , 0.48458624]),\n",
       "   'std_fit_time': array([0.11303935, 0.07708499, 0.06627247, 0.07151583, 0.04721153,\n",
       "          0.09882212, 0.0783577 , 0.07511573, 0.07934089, 0.07558192,\n",
       "          0.09956973, 0.07520624, 0.08170739, 0.05839162, 0.05513426,\n",
       "          0.04021238, 0.0639259 , 0.07781487, 0.06530123, 0.0644451 ,\n",
       "          0.05178728, 0.07120518, 0.08067499, 0.05723876, 0.03026252,\n",
       "          0.08779052, 0.07218755, 0.06201165, 0.06333066, 0.06835566,\n",
       "          0.09918935, 0.05944287, 0.07319647, 0.09566651, 0.07288999,\n",
       "          0.09515243, 0.09454094, 0.10494032, 0.10153427, 0.09072211,\n",
       "          0.07434226, 0.07933705, 0.10143152, 0.06742083, 0.04407817,\n",
       "          0.07604663, 0.0740284 , 0.08067845, 0.07605691, 0.06591917,\n",
       "          0.08601793, 0.07656941, 0.06837241, 0.03375792, 0.09750846,\n",
       "          0.08543431, 0.09251144, 0.07956735, 0.07302249, 0.05945331,\n",
       "          0.06669266, 0.09282918, 0.08022879, 0.06856295, 0.08676872,\n",
       "          0.07318648, 0.12352692, 0.04494921, 0.16755123, 0.08517259,\n",
       "          0.07453558, 0.10236144, 0.0764807 , 0.06913671, 0.07662566,\n",
       "          0.06528406, 0.08798325, 0.07532894, 0.06990351, 0.05384089,\n",
       "          0.09455623, 0.05664006, 0.06366443, 0.05879022, 0.08497917,\n",
       "          0.08649029, 0.0779881 , 0.06121114, 0.09387508, 0.0811545 ,\n",
       "          0.07170249, 0.07265165, 0.07202554, 0.07065439, 0.09041276,\n",
       "          0.07901833, 0.10113211, 0.11864515, 0.08464195, 0.13187145]),\n",
       "   'mean_score_time': array([0.01497529, 0.01424725, 0.01226957, 0.0135092 , 0.00955408,\n",
       "          0.01378641, 0.01358416, 0.00934734, 0.01069314, 0.00924718,\n",
       "          0.01294546, 0.01441624, 0.00926905, 0.00680816, 0.00912366,\n",
       "          0.00757976, 0.0162148 , 0.00907183, 0.01093616, 0.00896871,\n",
       "          0.0084132 , 0.01015239, 0.01037347, 0.0108418 , 0.00898731,\n",
       "          0.0073245 , 0.01382222, 0.01335185, 0.01085734, 0.00737207,\n",
       "          0.01034646, 0.01262164, 0.00927629, 0.01085029, 0.01700199,\n",
       "          0.00995982, 0.01303217, 0.01327231, 0.01028504, 0.00979805,\n",
       "          0.00868003, 0.01290762, 0.00990977, 0.00856402, 0.01193562,\n",
       "          0.009045  , 0.01130607, 0.00691352, 0.00971169, 0.01021509,\n",
       "          0.00950384, 0.00970533, 0.01394489, 0.00928769, 0.00946681,\n",
       "          0.00764828, 0.01228883, 0.00926704, 0.01076984, 0.00922227,\n",
       "          0.0068193 , 0.01241581, 0.00967333, 0.00697558, 0.01164143,\n",
       "          0.00885749, 0.01188226, 0.01127856, 0.00842328, 0.00936906,\n",
       "          0.00881226, 0.01165404, 0.00970881, 0.0092319 , 0.00965388,\n",
       "          0.00856397, 0.01101835, 0.01002119, 0.00793793, 0.00958853,\n",
       "          0.01083572, 0.00968423, 0.00841539, 0.01009381, 0.00997446,\n",
       "          0.00702879, 0.01365685, 0.01294229, 0.00937667, 0.01081908,\n",
       "          0.00724447, 0.00764205, 0.01001945, 0.01131766, 0.01057057,\n",
       "          0.00931177, 0.00908444, 0.00887969, 0.01385498, 0.01220784]),\n",
       "   'std_score_time': array([0.00970706, 0.00650755, 0.00774156, 0.00869699, 0.00503507,\n",
       "          0.00715752, 0.00811189, 0.00364132, 0.00513704, 0.00409223,\n",
       "          0.0045674 , 0.00606004, 0.00212179, 0.00201267, 0.00327611,\n",
       "          0.00318541, 0.00793642, 0.00456033, 0.00519012, 0.00336791,\n",
       "          0.00275531, 0.00349661, 0.00572414, 0.00489904, 0.00657875,\n",
       "          0.00211751, 0.00438364, 0.00530089, 0.00827992, 0.00467496,\n",
       "          0.00642072, 0.006103  , 0.00356641, 0.0053904 , 0.00922699,\n",
       "          0.00453087, 0.0062896 , 0.00639555, 0.00417296, 0.00608745,\n",
       "          0.00360677, 0.00733228, 0.003844  , 0.00336866, 0.00900625,\n",
       "          0.00442977, 0.00924575, 0.00164485, 0.00736287, 0.00362476,\n",
       "          0.00338902, 0.00749161, 0.0098206 , 0.00530499, 0.00519173,\n",
       "          0.00403891, 0.00590141, 0.00420316, 0.00648941, 0.00351679,\n",
       "          0.00188654, 0.00490908, 0.00411005, 0.00282996, 0.00466331,\n",
       "          0.00380194, 0.00523392, 0.00660511, 0.00384668, 0.00373508,\n",
       "          0.00459512, 0.00656187, 0.00468066, 0.00532375, 0.00502769,\n",
       "          0.00347103, 0.00860589, 0.00724151, 0.00314428, 0.00470051,\n",
       "          0.00698911, 0.00476958, 0.00364546, 0.00556586, 0.00302156,\n",
       "          0.00222268, 0.00936719, 0.00557747, 0.00378855, 0.00584864,\n",
       "          0.00212034, 0.00378451, 0.00741198, 0.00730191, 0.00530056,\n",
       "          0.00439742, 0.00355192, 0.00334202, 0.00735082, 0.00373881]),\n",
       "   'param_max_iter': masked_array(data=[648, 444, 647, 361, 424, 879, 975, 633, 319, 527, 1000,\n",
       "                      250, 732, 889, 444, 529, 892, 799, 428, 660, 630, 250,\n",
       "                      936, 326, 838, 1000, 519, 250, 522, 907, 463, 436,\n",
       "                      1000, 599, 356, 1000, 250, 1000, 250, 1000, 609, 250,\n",
       "                      1000, 250, 398, 1000, 250, 1000, 868, 250, 250, 1000,\n",
       "                      250, 710, 1000, 250, 1000, 827, 250, 1000, 250, 1000,\n",
       "                      250, 1000, 250, 1000, 250, 569, 1000, 250, 1000, 250,\n",
       "                      1000, 250, 1000, 999, 252, 250, 1000, 250, 1000, 781,\n",
       "                      372, 250, 999, 252, 997, 250, 993, 999, 252, 1000, 252,\n",
       "                      252, 999, 997, 251, 251, 999, 999],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_n_components': masked_array(data=[5, 6, 2, 5, 3, 6, 5, 4, 6, 4, 6, 6, 6, 3, 3, 2, 4, 6,\n",
       "                      5, 3, 2, 6, 2, 3, 3, 6, 3, 6, 4, 5, 5, 4, 6, 3, 6, 6,\n",
       "                      6, 6, 6, 6, 5, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 2,\n",
       "                      6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 6, 6, 6, 6,\n",
       "                      6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 4, 6, 6, 6, 6, 6, 6, 6,\n",
       "                      6, 6, 6, 6, 6, 6, 6, 6, 6, 6],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [OrderedDict([('max_iter', 648), ('n_components', 5)]),\n",
       "    OrderedDict([('max_iter', 444), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 647), ('n_components', 2)]),\n",
       "    OrderedDict([('max_iter', 361), ('n_components', 5)]),\n",
       "    OrderedDict([('max_iter', 424), ('n_components', 3)]),\n",
       "    OrderedDict([('max_iter', 879), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 975), ('n_components', 5)]),\n",
       "    OrderedDict([('max_iter', 633), ('n_components', 4)]),\n",
       "    OrderedDict([('max_iter', 319), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 527), ('n_components', 4)]),\n",
       "    OrderedDict([('max_iter', 1000), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 732), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 889), ('n_components', 3)]),\n",
       "    OrderedDict([('max_iter', 444), ('n_components', 3)]),\n",
       "    OrderedDict([('max_iter', 529), ('n_components', 2)]),\n",
       "    OrderedDict([('max_iter', 892), ('n_components', 4)]),\n",
       "    OrderedDict([('max_iter', 799), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 428), ('n_components', 5)]),\n",
       "    OrderedDict([('max_iter', 660), ('n_components', 3)]),\n",
       "    OrderedDict([('max_iter', 630), ('n_components', 2)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 936), ('n_components', 2)]),\n",
       "    OrderedDict([('max_iter', 326), ('n_components', 3)]),\n",
       "    OrderedDict([('max_iter', 838), ('n_components', 3)]),\n",
       "    OrderedDict([('max_iter', 1000), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 519), ('n_components', 3)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 522), ('n_components', 4)]),\n",
       "    OrderedDict([('max_iter', 907), ('n_components', 5)]),\n",
       "    OrderedDict([('max_iter', 463), ('n_components', 5)]),\n",
       "    OrderedDict([('max_iter', 436), ('n_components', 4)]),\n",
       "    OrderedDict([('max_iter', 1000), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 599), ('n_components', 3)]),\n",
       "    OrderedDict([('max_iter', 356), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 1000), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 1000), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 1000), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 609), ('n_components', 5)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 1000), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 398), ('n_components', 3)]),\n",
       "    OrderedDict([('max_iter', 1000), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 1000), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 868), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 1000), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 710), ('n_components', 2)]),\n",
       "    OrderedDict([('max_iter', 1000), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 1000), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 827), ('n_components', 5)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 1000), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 1000), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 1000), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 1000), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 569), ('n_components', 4)]),\n",
       "    OrderedDict([('max_iter', 1000), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 1000), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 1000), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 1000), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 999), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 252), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 1000), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 1000), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 781), ('n_components', 3)]),\n",
       "    OrderedDict([('max_iter', 372), ('n_components', 4)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 999), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 252), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 997), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 250), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 993), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 999), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 252), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 1000), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 252), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 252), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 999), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 997), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 251), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 251), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 999), ('n_components', 6)]),\n",
       "    OrderedDict([('max_iter', 999), ('n_components', 6)])],\n",
       "   'split0_test_score': array([-0.63390606, -0.63111249, -0.73900259, -0.63390606, -0.68958628,\n",
       "          -0.63111249, -0.63390606, -0.64969122, -0.63111249, -0.64969122,\n",
       "          -0.63111249, -0.63111249, -0.63111249, -0.68958628, -0.68958628,\n",
       "          -0.73900259, -0.64969122, -0.63111249, -0.63390606, -0.68958628,\n",
       "          -0.73900259, -0.63111249, -0.73900259, -0.68958628, -0.68958628,\n",
       "          -0.63111249, -0.68958628, -0.63111249, -0.64969122, -0.63390606,\n",
       "          -0.63390606, -0.64969122, -0.63111249, -0.68958628, -0.63111249,\n",
       "          -0.63111249, -0.63111249, -0.63111249, -0.63111249, -0.63111249,\n",
       "          -0.63390606, -0.63111249, -0.63111249, -0.63111249, -0.68958628,\n",
       "          -0.63111249, -0.63111249, -0.63111249, -0.63111249, -0.63111249,\n",
       "          -0.63111249, -0.63111249, -0.63111249, -0.73900259, -0.63111249,\n",
       "          -0.63111249, -0.63111249, -0.63390606, -0.63111249, -0.63111249,\n",
       "          -0.63111249, -0.63111249, -0.63111249, -0.63111249, -0.63111249,\n",
       "          -0.63111249, -0.63111249, -0.64969122, -0.63111249, -0.63111249,\n",
       "          -0.63111249, -0.63111249, -0.63111249, -0.63111249, -0.63111249,\n",
       "          -0.63111249, -0.63111249, -0.63111249, -0.63111249, -0.63111249,\n",
       "          -0.63111249, -0.68958628, -0.64969122, -0.63111249, -0.63111249,\n",
       "          -0.63111249, -0.63111249, -0.63111249, -0.63111249, -0.63111249,\n",
       "          -0.63111249, -0.63111249, -0.63111249, -0.63111249, -0.63111249,\n",
       "          -0.63111249, -0.63111249, -0.63111249, -0.63111249, -0.63111249]),\n",
       "   'split1_test_score': array([-0.55327454, -0.5102869 , -0.62952947, -0.55327454, -0.58346215,\n",
       "          -0.5102869 , -0.55327454, -0.59427657, -0.5102869 , -0.59427657,\n",
       "          -0.5102869 , -0.5102869 , -0.5102869 , -0.58346215, -0.58346215,\n",
       "          -0.62952947, -0.59427657, -0.5102869 , -0.55327454, -0.58346215,\n",
       "          -0.62952947, -0.5102869 , -0.62952947, -0.58346215, -0.58346215,\n",
       "          -0.5102869 , -0.58346215, -0.5102869 , -0.59427657, -0.55327454,\n",
       "          -0.55327454, -0.59427657, -0.5102869 , -0.58346215, -0.5102869 ,\n",
       "          -0.5102869 , -0.5102869 , -0.5102869 , -0.5102869 , -0.5102869 ,\n",
       "          -0.55327454, -0.5102869 , -0.5102869 , -0.5102869 , -0.58346215,\n",
       "          -0.5102869 , -0.5102869 , -0.5102869 , -0.5102869 , -0.5102869 ,\n",
       "          -0.5102869 , -0.5102869 , -0.5102869 , -0.62952947, -0.5102869 ,\n",
       "          -0.5102869 , -0.5102869 , -0.55327454, -0.5102869 , -0.5102869 ,\n",
       "          -0.5102869 , -0.5102869 , -0.5102869 , -0.5102869 , -0.5102869 ,\n",
       "          -0.5102869 , -0.5102869 , -0.59427657, -0.5102869 , -0.5102869 ,\n",
       "          -0.5102869 , -0.5102869 , -0.5102869 , -0.5102869 , -0.5102869 ,\n",
       "          -0.5102869 , -0.5102869 , -0.5102869 , -0.5102869 , -0.5102869 ,\n",
       "          -0.5102869 , -0.58346215, -0.59427657, -0.5102869 , -0.5102869 ,\n",
       "          -0.5102869 , -0.5102869 , -0.5102869 , -0.5102869 , -0.5102869 ,\n",
       "          -0.5102869 , -0.5102869 , -0.5102869 , -0.5102869 , -0.5102869 ,\n",
       "          -0.5102869 , -0.5102869 , -0.5102869 , -0.5102869 , -0.5102869 ]),\n",
       "   'split2_test_score': array([-0.57047159, -0.53109455, -0.66770026, -0.57047159, -0.61710152,\n",
       "          -0.53109455, -0.57047159, -0.59314275, -0.53109455, -0.59314275,\n",
       "          -0.53109455, -0.53109455, -0.53109455, -0.61710152, -0.61710152,\n",
       "          -0.66770026, -0.59314275, -0.53109455, -0.57047159, -0.61710152,\n",
       "          -0.66770026, -0.53109455, -0.66770026, -0.61710152, -0.61710152,\n",
       "          -0.53109455, -0.61710152, -0.53109455, -0.59314275, -0.57047159,\n",
       "          -0.57047159, -0.59314275, -0.53109455, -0.61710152, -0.53109455,\n",
       "          -0.53109455, -0.53109455, -0.53109455, -0.53109455, -0.53109455,\n",
       "          -0.57047159, -0.53109455, -0.53109455, -0.53109455, -0.61710152,\n",
       "          -0.53109455, -0.53109455, -0.53109455, -0.53109455, -0.53109455,\n",
       "          -0.53109455, -0.53109455, -0.53109455, -0.66770026, -0.53109455,\n",
       "          -0.53109455, -0.53109455, -0.57047159, -0.53109455, -0.53109455,\n",
       "          -0.53109455, -0.53109455, -0.53109455, -0.53109455, -0.53109455,\n",
       "          -0.53109455, -0.53109455, -0.59314275, -0.53109455, -0.53109455,\n",
       "          -0.53109455, -0.53109455, -0.53109455, -0.53109455, -0.53109455,\n",
       "          -0.53109455, -0.53109455, -0.53109455, -0.53109455, -0.53109455,\n",
       "          -0.53109455, -0.61710152, -0.59314275, -0.53109455, -0.53109455,\n",
       "          -0.53109455, -0.53109455, -0.53109455, -0.53109455, -0.53109455,\n",
       "          -0.53109455, -0.53109455, -0.53109455, -0.53109455, -0.53109455,\n",
       "          -0.53109455, -0.53109455, -0.53109455, -0.53109455, -0.53109455]),\n",
       "   'split3_test_score': array([-0.5376094 , -0.47849393, -0.58375876, -0.5376094 , -0.53784345,\n",
       "          -0.47849393, -0.5376094 , -0.5279762 , -0.47849393, -0.5279762 ,\n",
       "          -0.47849393, -0.47849393, -0.47849393, -0.53784345, -0.53784345,\n",
       "          -0.58375876, -0.5279762 , -0.47849393, -0.5376094 , -0.53784345,\n",
       "          -0.58375876, -0.47849393, -0.58375876, -0.53784345, -0.53784345,\n",
       "          -0.47849393, -0.53784345, -0.47849393, -0.5279762 , -0.5376094 ,\n",
       "          -0.5376094 , -0.5279762 , -0.47849393, -0.53784345, -0.47849393,\n",
       "          -0.47849393, -0.47849393, -0.47849393, -0.47849393, -0.47849393,\n",
       "          -0.5376094 , -0.47849393, -0.47849393, -0.47849393, -0.53784345,\n",
       "          -0.47849393, -0.47849393, -0.47849393, -0.47849393, -0.47849393,\n",
       "          -0.47849393, -0.47849393, -0.47849393, -0.58375876, -0.47849393,\n",
       "          -0.47849393, -0.47849393, -0.5376094 , -0.47849393, -0.47849393,\n",
       "          -0.47849393, -0.47849393, -0.47849393, -0.47849393, -0.47849393,\n",
       "          -0.47849393, -0.47849393, -0.5279762 , -0.47849393, -0.47849393,\n",
       "          -0.47849393, -0.47849393, -0.47849393, -0.47849393, -0.47849393,\n",
       "          -0.47849393, -0.47849393, -0.47849393, -0.47849393, -0.47849393,\n",
       "          -0.47849393, -0.53784345, -0.5279762 , -0.47849393, -0.47849393,\n",
       "          -0.47849393, -0.47849393, -0.47849393, -0.47849393, -0.47849393,\n",
       "          -0.47849393, -0.47849393, -0.47849393, -0.47849393, -0.47849393,\n",
       "          -0.47849393, -0.47849393, -0.47849393, -0.47849393, -0.47849393]),\n",
       "   'split4_test_score': array([-0.53741635, -0.56852979, -0.68866719, -0.53741635, -0.64196742,\n",
       "          -0.56852979, -0.53741635, -0.57797091, -0.56852979, -0.57797091,\n",
       "          -0.56852979, -0.56852979, -0.56852979, -0.64196742, -0.64196742,\n",
       "          -0.68866719, -0.57797091, -0.56852979, -0.53741635, -0.64196742,\n",
       "          -0.68866719, -0.56852979, -0.68866719, -0.64196742, -0.64196742,\n",
       "          -0.56852979, -0.64196742, -0.56852979, -0.57797091, -0.53741635,\n",
       "          -0.53741635, -0.57797091, -0.56852979, -0.64196742, -0.56852979,\n",
       "          -0.56852979, -0.56852979, -0.56852979, -0.56852979, -0.56852979,\n",
       "          -0.53741635, -0.56852979, -0.56852979, -0.56852979, -0.64196742,\n",
       "          -0.56852979, -0.56852979, -0.56852979, -0.56852979, -0.56852979,\n",
       "          -0.56852979, -0.56852979, -0.56852979, -0.68866719, -0.56852979,\n",
       "          -0.56852979, -0.56852979, -0.53741635, -0.56852979, -0.56852979,\n",
       "          -0.56852979, -0.56852979, -0.56852979, -0.56852979, -0.56852979,\n",
       "          -0.56852979, -0.56852979, -0.57797091, -0.56852979, -0.56852979,\n",
       "          -0.56852979, -0.56852979, -0.56852979, -0.56852979, -0.56852979,\n",
       "          -0.56852979, -0.56852979, -0.56852979, -0.56852979, -0.56852979,\n",
       "          -0.56852979, -0.64196742, -0.57797091, -0.56852979, -0.56852979,\n",
       "          -0.56852979, -0.56852979, -0.56852979, -0.56852979, -0.56852979,\n",
       "          -0.56852979, -0.56852979, -0.56852979, -0.56852979, -0.56852979,\n",
       "          -0.56852979, -0.56852979, -0.56852979, -0.56852979, -0.56852979]),\n",
       "   'split5_test_score': array([-0.49697225, -0.41370062, -0.65487695, -0.49697225, -0.65103423,\n",
       "          -0.41370062, -0.49697225, -0.55369779, -0.41370062, -0.55369779,\n",
       "          -0.41370062, -0.41370062, -0.41370062, -0.65103423, -0.65103423,\n",
       "          -0.65487695, -0.55369779, -0.41370062, -0.49697225, -0.65103423,\n",
       "          -0.65487695, -0.41370062, -0.65487695, -0.65103423, -0.65103423,\n",
       "          -0.41370062, -0.65103423, -0.41370062, -0.55369779, -0.49697225,\n",
       "          -0.49697225, -0.55369779, -0.41370062, -0.65103423, -0.41370062,\n",
       "          -0.41370062, -0.41370062, -0.41370062, -0.41370062, -0.41370062,\n",
       "          -0.49697225, -0.41370062, -0.41370062, -0.41370062, -0.65103423,\n",
       "          -0.41370062, -0.41370062, -0.41370062, -0.41370062, -0.41370062,\n",
       "          -0.41370062, -0.41370062, -0.41370062, -0.65487695, -0.41370062,\n",
       "          -0.41370062, -0.41370062, -0.49697225, -0.41370062, -0.41370062,\n",
       "          -0.41370062, -0.41370062, -0.41370062, -0.41370062, -0.41370062,\n",
       "          -0.41370062, -0.41370062, -0.55369779, -0.41370062, -0.41370062,\n",
       "          -0.41370062, -0.41370062, -0.41370062, -0.41370062, -0.41370062,\n",
       "          -0.41370062, -0.41370062, -0.41370062, -0.41370062, -0.41370062,\n",
       "          -0.41370062, -0.65103423, -0.55369779, -0.41370062, -0.41370062,\n",
       "          -0.41370062, -0.41370062, -0.41370062, -0.41370062, -0.41370062,\n",
       "          -0.41370062, -0.41370062, -0.41370062, -0.41370062, -0.41370062,\n",
       "          -0.41370062, -0.41370062, -0.41370062, -0.41370062, -0.41370062]),\n",
       "   'split6_test_score': array([-0.64162039, -0.59984703, -0.64418283, -0.64162039, -0.55278941,\n",
       "          -0.59984703, -0.64162039, -0.53167381, -0.59984703, -0.53167381,\n",
       "          -0.59984703, -0.59984703, -0.59984703, -0.55278941, -0.55278941,\n",
       "          -0.64418283, -0.53167381, -0.59984703, -0.64162039, -0.55278941,\n",
       "          -0.64418283, -0.59984703, -0.64418283, -0.55278941, -0.55278941,\n",
       "          -0.59984703, -0.55278941, -0.59984703, -0.53167381, -0.64162039,\n",
       "          -0.64162039, -0.53167381, -0.59984703, -0.55278941, -0.59984703,\n",
       "          -0.59984703, -0.59984703, -0.59984703, -0.59984703, -0.59984703,\n",
       "          -0.64162039, -0.59984703, -0.59984703, -0.59984703, -0.55278941,\n",
       "          -0.59984703, -0.59984703, -0.59984703, -0.59984703, -0.59984703,\n",
       "          -0.59984703, -0.59984703, -0.59984703, -0.64418283, -0.59984703,\n",
       "          -0.59984703, -0.59984703, -0.64162039, -0.59984703, -0.59984703,\n",
       "          -0.59984703, -0.59984703, -0.59984703, -0.59984703, -0.59984703,\n",
       "          -0.59984703, -0.59984703, -0.53167381, -0.59984703, -0.59984703,\n",
       "          -0.59984703, -0.59984703, -0.59984703, -0.59984703, -0.59984703,\n",
       "          -0.59984703, -0.59984703, -0.59984703, -0.59984703, -0.59984703,\n",
       "          -0.59984703, -0.55278941, -0.53167381, -0.59984703, -0.59984703,\n",
       "          -0.59984703, -0.59984703, -0.59984703, -0.59984703, -0.59984703,\n",
       "          -0.59984703, -0.59984703, -0.59984703, -0.59984703, -0.59984703,\n",
       "          -0.59984703, -0.59984703, -0.59984703, -0.59984703, -0.59984703]),\n",
       "   'split7_test_score': array([-0.4980348 , -0.45681714, -0.5560678 , -0.4980348 , -0.49661705,\n",
       "          -0.45681714, -0.4980348 , -0.53051475, -0.45681714, -0.53051475,\n",
       "          -0.45681714, -0.45681714, -0.45681714, -0.49661705, -0.49661705,\n",
       "          -0.5560678 , -0.53051475, -0.45681714, -0.4980348 , -0.49661705,\n",
       "          -0.5560678 , -0.45681714, -0.5560678 , -0.49661705, -0.49661705,\n",
       "          -0.45681714, -0.49661705, -0.45681714, -0.53051475, -0.4980348 ,\n",
       "          -0.4980348 , -0.53051475, -0.45681714, -0.49661705, -0.45681714,\n",
       "          -0.45681714, -0.45681714, -0.45681714, -0.45681714, -0.45681714,\n",
       "          -0.4980348 , -0.45681714, -0.45681714, -0.45681714, -0.49661705,\n",
       "          -0.45681714, -0.45681714, -0.45681714, -0.45681714, -0.45681714,\n",
       "          -0.45681714, -0.45681714, -0.45681714, -0.5560678 , -0.45681714,\n",
       "          -0.45681714, -0.45681714, -0.4980348 , -0.45681714, -0.45681714,\n",
       "          -0.45681714, -0.45681714, -0.45681714, -0.45681714, -0.45681714,\n",
       "          -0.45681714, -0.45681714, -0.53051475, -0.45681714, -0.45681714,\n",
       "          -0.45681714, -0.45681714, -0.45681714, -0.45681714, -0.45681714,\n",
       "          -0.45681714, -0.45681714, -0.45681714, -0.45681714, -0.45681714,\n",
       "          -0.45681714, -0.49661705, -0.53051475, -0.45681714, -0.45681714,\n",
       "          -0.45681714, -0.45681714, -0.45681714, -0.45681714, -0.45681714,\n",
       "          -0.45681714, -0.45681714, -0.45681714, -0.45681714, -0.45681714,\n",
       "          -0.45681714, -0.45681714, -0.45681714, -0.45681714, -0.45681714]),\n",
       "   'split8_test_score': array([-0.48989206, -0.48595007, -0.55525008, -0.48989206, -0.54431725,\n",
       "          -0.48595007, -0.48989206, -0.47168394, -0.48595007, -0.47168394,\n",
       "          -0.48595007, -0.48595007, -0.48595007, -0.54431725, -0.54431725,\n",
       "          -0.55525008, -0.47168394, -0.48595007, -0.48989206, -0.54431725,\n",
       "          -0.55525008, -0.48595007, -0.55525008, -0.54431725, -0.54431725,\n",
       "          -0.48595007, -0.54431725, -0.48595007, -0.47168394, -0.48989206,\n",
       "          -0.48989206, -0.47168394, -0.48595007, -0.54431725, -0.48595007,\n",
       "          -0.48595007, -0.48595007, -0.48595007, -0.48595007, -0.48595007,\n",
       "          -0.48989206, -0.48595007, -0.48595007, -0.48595007, -0.54431725,\n",
       "          -0.48595007, -0.48595007, -0.48595007, -0.48595007, -0.48595007,\n",
       "          -0.48595007, -0.48595007, -0.48595007, -0.55525008, -0.48595007,\n",
       "          -0.48595007, -0.48595007, -0.48989206, -0.48595007, -0.48595007,\n",
       "          -0.48595007, -0.48595007, -0.48595007, -0.48595007, -0.48595007,\n",
       "          -0.48595007, -0.48595007, -0.47168394, -0.48595007, -0.48595007,\n",
       "          -0.48595007, -0.48595007, -0.48595007, -0.48595007, -0.48595007,\n",
       "          -0.48595007, -0.48595007, -0.48595007, -0.48595007, -0.48595007,\n",
       "          -0.48595007, -0.54431725, -0.47168394, -0.48595007, -0.48595007,\n",
       "          -0.48595007, -0.48595007, -0.48595007, -0.48595007, -0.48595007,\n",
       "          -0.48595007, -0.48595007, -0.48595007, -0.48595007, -0.48595007,\n",
       "          -0.48595007, -0.48595007, -0.48595007, -0.48595007, -0.48595007]),\n",
       "   'split9_test_score': array([-0.53945429, -0.49461655, -0.54514204, -0.53945429, -0.50418798,\n",
       "          -0.49461655, -0.53945429, -0.57767111, -0.49461655, -0.57767111,\n",
       "          -0.49461655, -0.49461655, -0.49461655, -0.50418798, -0.50418798,\n",
       "          -0.54514204, -0.57767111, -0.49461655, -0.53945429, -0.50418798,\n",
       "          -0.54514204, -0.49461655, -0.54514204, -0.50418798, -0.50418798,\n",
       "          -0.49461655, -0.50418798, -0.49461655, -0.57767111, -0.53945429,\n",
       "          -0.53945429, -0.57767111, -0.49461655, -0.50418798, -0.49461655,\n",
       "          -0.49461655, -0.49461655, -0.49461655, -0.49461655, -0.49461655,\n",
       "          -0.53945429, -0.49461655, -0.49461655, -0.49461655, -0.50418798,\n",
       "          -0.49461655, -0.49461655, -0.49461655, -0.49461655, -0.49461655,\n",
       "          -0.49461655, -0.49461655, -0.49461655, -0.54514204, -0.49461655,\n",
       "          -0.49461655, -0.49461655, -0.53945429, -0.49461655, -0.49461655,\n",
       "          -0.49461655, -0.49461655, -0.49461655, -0.49461655, -0.49461655,\n",
       "          -0.49461655, -0.49461655, -0.57767111, -0.49461655, -0.49461655,\n",
       "          -0.49461655, -0.49461655, -0.49461655, -0.49461655, -0.49461655,\n",
       "          -0.49461655, -0.49461655, -0.49461655, -0.49461655, -0.49461655,\n",
       "          -0.49461655, -0.50418798, -0.57767111, -0.49461655, -0.49461655,\n",
       "          -0.49461655, -0.49461655, -0.49461655, -0.49461655, -0.49461655,\n",
       "          -0.49461655, -0.49461655, -0.49461655, -0.49461655, -0.49461655,\n",
       "          -0.49461655, -0.49461655, -0.49461655, -0.49461655, -0.49461655]),\n",
       "   'mean_test_score': array([-0.54986517, -0.51704491, -0.6264178 , -0.54986517, -0.58189067,\n",
       "          -0.51704491, -0.54986517, -0.56082991, -0.51704491, -0.56082991,\n",
       "          -0.51704491, -0.51704491, -0.51704491, -0.58189067, -0.58189067,\n",
       "          -0.6264178 , -0.56082991, -0.51704491, -0.54986517, -0.58189067,\n",
       "          -0.6264178 , -0.51704491, -0.6264178 , -0.58189067, -0.58189067,\n",
       "          -0.51704491, -0.58189067, -0.51704491, -0.56082991, -0.54986517,\n",
       "          -0.54986517, -0.56082991, -0.51704491, -0.58189067, -0.51704491,\n",
       "          -0.51704491, -0.51704491, -0.51704491, -0.51704491, -0.51704491,\n",
       "          -0.54986517, -0.51704491, -0.51704491, -0.51704491, -0.58189067,\n",
       "          -0.51704491, -0.51704491, -0.51704491, -0.51704491, -0.51704491,\n",
       "          -0.51704491, -0.51704491, -0.51704491, -0.6264178 , -0.51704491,\n",
       "          -0.51704491, -0.51704491, -0.54986517, -0.51704491, -0.51704491,\n",
       "          -0.51704491, -0.51704491, -0.51704491, -0.51704491, -0.51704491,\n",
       "          -0.51704491, -0.51704491, -0.56082991, -0.51704491, -0.51704491,\n",
       "          -0.51704491, -0.51704491, -0.51704491, -0.51704491, -0.51704491,\n",
       "          -0.51704491, -0.51704491, -0.51704491, -0.51704491, -0.51704491,\n",
       "          -0.51704491, -0.58189067, -0.56082991, -0.51704491, -0.51704491,\n",
       "          -0.51704491, -0.51704491, -0.51704491, -0.51704491, -0.51704491,\n",
       "          -0.51704491, -0.51704491, -0.51704491, -0.51704491, -0.51704491,\n",
       "          -0.51704491, -0.51704491, -0.51704491, -0.51704491, -0.51704491]),\n",
       "   'std_test_score': array([0.05041084, 0.06326522, 0.06150551, 0.05041084, 0.06224048,\n",
       "          0.06326522, 0.05041084, 0.04634964, 0.06326522, 0.04634964,\n",
       "          0.06326522, 0.06326522, 0.06326522, 0.06224048, 0.06224048,\n",
       "          0.06150551, 0.04634964, 0.06326522, 0.05041084, 0.06224048,\n",
       "          0.06150551, 0.06326522, 0.06150551, 0.06224048, 0.06224048,\n",
       "          0.06326522, 0.06224048, 0.06326522, 0.04634964, 0.05041084,\n",
       "          0.05041084, 0.04634964, 0.06326522, 0.06224048, 0.06326522,\n",
       "          0.06326522, 0.06326522, 0.06326522, 0.06326522, 0.06326522,\n",
       "          0.05041084, 0.06326522, 0.06326522, 0.06326522, 0.06224048,\n",
       "          0.06326522, 0.06326522, 0.06326522, 0.06326522, 0.06326522,\n",
       "          0.06326522, 0.06326522, 0.06326522, 0.06150551, 0.06326522,\n",
       "          0.06326522, 0.06326522, 0.05041084, 0.06326522, 0.06326522,\n",
       "          0.06326522, 0.06326522, 0.06326522, 0.06326522, 0.06326522,\n",
       "          0.06326522, 0.06326522, 0.04634964, 0.06326522, 0.06326522,\n",
       "          0.06326522, 0.06326522, 0.06326522, 0.06326522, 0.06326522,\n",
       "          0.06326522, 0.06326522, 0.06326522, 0.06326522, 0.06326522,\n",
       "          0.06326522, 0.06224048, 0.04634964, 0.06326522, 0.06326522,\n",
       "          0.06326522, 0.06326522, 0.06326522, 0.06326522, 0.06326522,\n",
       "          0.06326522, 0.06326522, 0.06326522, 0.06326522, 0.06326522,\n",
       "          0.06326522, 0.06326522, 0.06326522, 0.06326522, 0.06326522]),\n",
       "   'rank_test_score': array([71,  1, 96, 71, 86,  1, 71, 79,  1, 79,  1,  1,  1, 86, 86, 96, 79,\n",
       "           1, 71, 86, 96,  1, 96, 86, 86,  1, 86,  1, 79, 71, 71, 79,  1, 86,\n",
       "           1,  1,  1,  1,  1,  1, 71,  1,  1,  1, 86,  1,  1,  1,  1,  1,  1,\n",
       "           1,  1, 96,  1,  1,  1, 71,  1,  1,  1,  1,  1,  1,  1,  1,  1, 79,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 86, 79,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "         dtype=int32)}},\n",
       " 'kNN': {'best_estimator': KNeighborsRegressor(algorithm='brute', leaf_size=17, n_jobs=6, n_neighbors=2,\n",
       "                      p=1),\n",
       "  'best_params': OrderedDict([('algorithm', 'brute'),\n",
       "               ('leaf_size', 17),\n",
       "               ('n_neighbors', 2),\n",
       "               ('p', 1),\n",
       "               ('weights', 'uniform')]),\n",
       "  'best_score': -0.3725528754750275,\n",
       "  'optimization_history': {'mean_fit_time': array([0.11175699, 0.54381981, 0.08098652, 0.12049408, 0.6394944 ,\n",
       "          0.72205627, 0.70063169, 0.10937884, 0.09267061, 0.61319709,\n",
       "          0.11869876, 0.80701861, 0.59129696, 0.08080654, 0.6693342 ,\n",
       "          0.09265044, 0.73533795, 0.11409647, 0.09544113, 0.11344011,\n",
       "          0.56270564, 0.09101174, 0.70984142, 0.12909119, 0.7847084 ,\n",
       "          0.11487596, 0.09117117, 0.11071208, 0.07384465, 0.09845512,\n",
       "          0.63544939, 0.67466011, 0.09615095, 0.09581339, 0.08852921,\n",
       "          0.82583473, 0.13547528, 0.68061361, 0.12673702, 0.84128525,\n",
       "          0.07797809, 0.14630847, 0.13023095, 0.11329145, 0.06997461,\n",
       "          0.11212747, 0.11360288, 0.07072389, 0.105773  , 0.09525545,\n",
       "          0.09220023, 0.0965874 , 0.59205003, 0.65939512, 0.08773801,\n",
       "          0.16815414, 0.13689871, 0.1178719 , 0.10749075, 0.09584904,\n",
       "          0.12505383, 0.15946496, 0.12366667, 0.11221278, 0.09774499,\n",
       "          0.07865524, 0.11667516, 0.12297618, 0.06463742, 0.085061  ,\n",
       "          0.08422723, 0.10632846, 0.12952688, 0.17716758, 0.06348271,\n",
       "          0.08179634, 0.10104177, 0.11349177, 0.07616849, 0.10584228,\n",
       "          0.11775887, 0.10509164, 0.1188699 , 0.1395256 , 0.1048213 ,\n",
       "          0.08749864, 0.08631742, 0.15409632, 0.10640652, 0.10419965,\n",
       "          0.11819603, 0.06598954, 0.11701455, 0.13132622, 0.09770577,\n",
       "          0.08653033, 0.07727754, 0.0853014 , 0.08278763, 0.0921073 ]),\n",
       "   'std_fit_time': array([0.037802  , 0.06035765, 0.04132548, 0.08047488, 0.03383884,\n",
       "          0.20335909, 0.21463474, 0.09138403, 0.03825328, 0.0516719 ,\n",
       "          0.06844691, 0.1336902 , 0.17189751, 0.03215378, 0.14315222,\n",
       "          0.04675826, 0.11740223, 0.03175517, 0.03882702, 0.05514726,\n",
       "          0.09388435, 0.03836186, 0.11335463, 0.05377003, 0.15478552,\n",
       "          0.05363383, 0.03731479, 0.06257298, 0.03012641, 0.04526287,\n",
       "          0.05700246, 0.1229469 , 0.04827261, 0.03604109, 0.03411541,\n",
       "          0.19603532, 0.06664695, 0.16868986, 0.03941303, 0.2252142 ,\n",
       "          0.02421831, 0.06135882, 0.03623732, 0.04446223, 0.02101015,\n",
       "          0.05091238, 0.054093  , 0.02550881, 0.04247963, 0.03664691,\n",
       "          0.02657831, 0.05554211, 0.07746253, 0.14818932, 0.0433428 ,\n",
       "          0.09380207, 0.08343293, 0.06512557, 0.03855675, 0.03852552,\n",
       "          0.04470984, 0.06518821, 0.04591714, 0.04893748, 0.06498075,\n",
       "          0.03100676, 0.04729447, 0.05273018, 0.02386814, 0.03307037,\n",
       "          0.04481456, 0.04767295, 0.0466996 , 0.09767334, 0.01607269,\n",
       "          0.02870732, 0.03329337, 0.04490848, 0.02029563, 0.05582504,\n",
       "          0.04481221, 0.03603318, 0.05807268, 0.06700564, 0.02647576,\n",
       "          0.03702361, 0.04803307, 0.05568567, 0.05665021, 0.04486367,\n",
       "          0.05067096, 0.04572432, 0.06295091, 0.05577678, 0.06532024,\n",
       "          0.03379447, 0.04515245, 0.0397931 , 0.03428481, 0.04371832]),\n",
       "   'mean_score_time': array([ 1.75176086, 12.3378643 , 10.8388273 , 10.79114349,  5.75444875,\n",
       "           5.9486274 ,  5.85476582, 10.83835273,  1.73025079, 10.64878263,\n",
       "          10.66487262,  5.0332649 , 10.58935175, 10.69901514,  5.62402594,\n",
       "          10.80892165,  4.52750034, 10.72894695, 10.74003963, 10.70143518,\n",
       "          10.72540176, 10.73515663,  4.47822928, 10.7250381 ,  5.3504034 ,\n",
       "          10.7690685 , 10.80300891,  1.66736374,  1.70854681, 10.80988426,\n",
       "           5.6280266 ,  5.65645103, 10.70122192, 10.68470306, 10.9617101 ,\n",
       "           5.66071143, 10.67891781,  5.47548399, 10.68876803,  5.11570716,\n",
       "          10.71188009,  1.6982841 , 10.69453452, 10.61967068,  1.77054923,\n",
       "          10.63871975,  1.61683035, 10.62597444, 10.67962878, 10.77640433,\n",
       "          10.55359297, 10.63767974, 11.99151912, 11.78144183, 10.83084362,\n",
       "          10.62637815, 10.60408833, 10.63578041, 10.65137012, 10.67682509,\n",
       "          10.65458241, 10.67992387, 10.64033644, 10.66884003,  1.7268441 ,\n",
       "          10.64330003, 10.70105662, 10.75102923, 10.61391606, 10.64633248,\n",
       "          10.60403135, 10.9024488 , 10.65636935, 10.69135287, 10.76304264,\n",
       "          10.61071274, 10.71701026, 10.71352043, 10.74097764, 10.7469347 ,\n",
       "          10.67347634, 10.92486081, 10.70274725, 10.75081587, 10.91928468,\n",
       "          10.66035192, 10.74432373, 10.71276479, 10.57423458, 11.14017985,\n",
       "          10.71153302, 10.77055516, 10.9035785 , 10.73479099, 10.51943035,\n",
       "          10.72599301, 10.57950301, 10.71653106, 10.47404041, 10.69899499]),\n",
       "   'std_score_time': array([0.38334324, 2.22857787, 2.25083234, 2.14910096, 0.99266635,\n",
       "          1.31600727, 1.27666949, 2.04129767, 0.3492871 , 2.04326087,\n",
       "          2.09878044, 1.07084504, 1.72374703, 2.03735382, 1.16652237,\n",
       "          2.08724404, 0.90425818, 2.16881829, 2.08177506, 2.11995718,\n",
       "          1.85060459, 2.10456418, 0.89619327, 2.05304268, 1.09565402,\n",
       "          2.08954782, 2.07230612, 0.32741334, 0.33217805, 2.0837405 ,\n",
       "          0.94966432, 1.08335361, 2.01714294, 2.09858404, 2.1860394 ,\n",
       "          0.99442678, 2.09876389, 1.17258152, 2.15558189, 1.08705443,\n",
       "          2.08701689, 0.42983147, 2.18715336, 2.17818124, 0.34250289,\n",
       "          2.1871295 , 0.35356597, 2.13599114, 2.0843667 , 2.14445524,\n",
       "          2.03086144, 2.09689025, 2.24658985, 2.28441474, 2.22403991,\n",
       "          2.17672515, 2.15448589, 2.12398471, 2.17674709, 1.97276627,\n",
       "          2.17508493, 2.13666067, 2.18401031, 2.21785955, 0.29860556,\n",
       "          2.03538901, 2.10654008, 2.13363691, 2.01567515, 2.16491739,\n",
       "          1.99144366, 2.20135809, 2.26846155, 2.22880347, 2.06092739,\n",
       "          2.10260948, 2.09955193, 2.18403248, 2.17771377, 2.1274563 ,\n",
       "          2.00348247, 2.15654697, 2.03999046, 2.10634501, 2.22107023,\n",
       "          2.19617897, 2.1517501 , 2.22733617, 2.13421323, 2.49295251,\n",
       "          2.21131522, 2.0427963 , 2.22932094, 2.29640535, 1.96515209,\n",
       "          2.23333672, 2.17939354, 2.17900145, 2.10143572, 2.04238814]),\n",
       "   'param_algorithm': masked_array(data=['brute', 'ball_tree', 'brute', 'auto', 'ball_tree',\n",
       "                      'kd_tree', 'kd_tree', 'brute', 'auto', 'ball_tree',\n",
       "                      'brute', 'kd_tree', 'ball_tree', 'auto', 'kd_tree',\n",
       "                      'auto', 'kd_tree', 'brute', 'auto', 'auto',\n",
       "                      'ball_tree', 'auto', 'kd_tree', 'auto', 'kd_tree',\n",
       "                      'auto', 'auto', 'auto', 'brute', 'auto', 'ball_tree',\n",
       "                      'kd_tree', 'auto', 'auto', 'brute', 'ball_tree',\n",
       "                      'auto', 'kd_tree', 'auto', 'kd_tree', 'auto', 'auto',\n",
       "                      'auto', 'auto', 'brute', 'auto', 'auto', 'auto',\n",
       "                      'auto', 'auto', 'auto', 'auto', 'ball_tree',\n",
       "                      'ball_tree', 'brute', 'auto', 'auto', 'auto', 'auto',\n",
       "                      'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                      'auto', 'brute', 'auto', 'auto', 'auto', 'auto',\n",
       "                      'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                      'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                      'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                      'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_leaf_size': masked_array(data=[71, 98, 15, 80, 32, 99, 78, 57, 91, 50, 17, 11, 99, 98,\n",
       "                      100, 89, 14, 67, 10, 10, 79, 100, 32, 10, 14, 100, 10,\n",
       "                      97, 70, 30, 28, 82, 100, 100, 13, 26, 100, 100, 10, 17,\n",
       "                      12, 84, 10, 10, 17, 10, 79, 10, 10, 74, 100, 97, 79,\n",
       "                      81, 80, 10, 10, 10, 100, 100, 10, 10, 100, 10, 71, 100,\n",
       "                      10, 33, 100, 10, 100, 26, 10, 100, 91, 100, 100, 10,\n",
       "                      10, 24, 10, 100, 10, 10, 98, 10, 10, 99, 100, 10, 100,\n",
       "                      100, 10, 10, 10, 100, 10, 10, 10, 100],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_n_neighbors': masked_array(data=[32, 46, 18, 25, 37, 37, 22, 37, 40, 15, 2, 2, 6, 2, 2,\n",
       "                      50, 2, 7, 2, 2, 7, 2, 8, 2, 22, 12, 2, 27, 35, 23, 9,\n",
       "                      21, 2, 2, 15, 31, 2, 2, 2, 44, 4, 5, 2, 2, 50, 2, 11,\n",
       "                      2, 2, 44, 2, 2, 15, 30, 24, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                      50, 2, 2, 35, 2, 2, 2, 2, 2, 2, 33, 2, 2, 2, 2, 2, 2,\n",
       "                      2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "                      2],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_p': masked_array(data=[2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1,\n",
       "                      1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1,\n",
       "                      1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2,\n",
       "                      1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1,\n",
       "                      1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                      1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_weights': masked_array(data=['uniform', 'distance', 'distance', 'uniform',\n",
       "                      'distance', 'distance', 'distance', 'distance',\n",
       "                      'distance', 'distance', 'uniform', 'uniform',\n",
       "                      'distance', 'distance', 'uniform', 'uniform',\n",
       "                      'distance', 'distance', 'uniform', 'uniform',\n",
       "                      'distance', 'uniform', 'uniform', 'uniform', 'uniform',\n",
       "                      'uniform', 'uniform', 'distance', 'distance',\n",
       "                      'uniform', 'distance', 'distance', 'uniform',\n",
       "                      'uniform', 'distance', 'uniform', 'uniform', 'uniform',\n",
       "                      'uniform', 'uniform', 'uniform', 'distance', 'uniform',\n",
       "                      'uniform', 'uniform', 'uniform', 'distance', 'uniform',\n",
       "                      'uniform', 'uniform', 'uniform', 'uniform', 'distance',\n",
       "                      'uniform', 'uniform', 'uniform', 'uniform', 'uniform',\n",
       "                      'uniform', 'uniform', 'uniform', 'uniform', 'uniform',\n",
       "                      'uniform', 'uniform', 'uniform', 'uniform', 'distance',\n",
       "                      'uniform', 'uniform', 'uniform', 'uniform', 'uniform',\n",
       "                      'uniform', 'distance', 'uniform', 'uniform', 'uniform',\n",
       "                      'uniform', 'uniform', 'uniform', 'uniform', 'uniform',\n",
       "                      'uniform', 'uniform', 'uniform', 'uniform', 'uniform',\n",
       "                      'uniform', 'uniform', 'uniform', 'uniform', 'uniform',\n",
       "                      'uniform', 'uniform', 'uniform', 'uniform', 'uniform',\n",
       "                      'uniform', 'uniform'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [OrderedDict([('algorithm', 'brute'),\n",
       "                 ('leaf_size', 71),\n",
       "                 ('n_neighbors', 32),\n",
       "                 ('p', 2),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'ball_tree'),\n",
       "                 ('leaf_size', 98),\n",
       "                 ('n_neighbors', 46),\n",
       "                 ('p', 2),\n",
       "                 ('weights', 'distance')]),\n",
       "    OrderedDict([('algorithm', 'brute'),\n",
       "                 ('leaf_size', 15),\n",
       "                 ('n_neighbors', 18),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'distance')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 80),\n",
       "                 ('n_neighbors', 25),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'ball_tree'),\n",
       "                 ('leaf_size', 32),\n",
       "                 ('n_neighbors', 37),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'distance')]),\n",
       "    OrderedDict([('algorithm', 'kd_tree'),\n",
       "                 ('leaf_size', 99),\n",
       "                 ('n_neighbors', 37),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'distance')]),\n",
       "    OrderedDict([('algorithm', 'kd_tree'),\n",
       "                 ('leaf_size', 78),\n",
       "                 ('n_neighbors', 22),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'distance')]),\n",
       "    OrderedDict([('algorithm', 'brute'),\n",
       "                 ('leaf_size', 57),\n",
       "                 ('n_neighbors', 37),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'distance')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 91),\n",
       "                 ('n_neighbors', 40),\n",
       "                 ('p', 2),\n",
       "                 ('weights', 'distance')]),\n",
       "    OrderedDict([('algorithm', 'ball_tree'),\n",
       "                 ('leaf_size', 50),\n",
       "                 ('n_neighbors', 15),\n",
       "                 ('p', 2),\n",
       "                 ('weights', 'distance')]),\n",
       "    OrderedDict([('algorithm', 'brute'),\n",
       "                 ('leaf_size', 17),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'kd_tree'),\n",
       "                 ('leaf_size', 11),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 2),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'ball_tree'),\n",
       "                 ('leaf_size', 99),\n",
       "                 ('n_neighbors', 6),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'distance')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 98),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'distance')]),\n",
       "    OrderedDict([('algorithm', 'kd_tree'),\n",
       "                 ('leaf_size', 100),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 89),\n",
       "                 ('n_neighbors', 50),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'kd_tree'),\n",
       "                 ('leaf_size', 14),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'distance')]),\n",
       "    OrderedDict([('algorithm', 'brute'),\n",
       "                 ('leaf_size', 67),\n",
       "                 ('n_neighbors', 7),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'distance')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'ball_tree'),\n",
       "                 ('leaf_size', 79),\n",
       "                 ('n_neighbors', 7),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'distance')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 100),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'kd_tree'),\n",
       "                 ('leaf_size', 32),\n",
       "                 ('n_neighbors', 8),\n",
       "                 ('p', 2),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'kd_tree'),\n",
       "                 ('leaf_size', 14),\n",
       "                 ('n_neighbors', 22),\n",
       "                 ('p', 2),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 100),\n",
       "                 ('n_neighbors', 12),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 97),\n",
       "                 ('n_neighbors', 27),\n",
       "                 ('p', 2),\n",
       "                 ('weights', 'distance')]),\n",
       "    OrderedDict([('algorithm', 'brute'),\n",
       "                 ('leaf_size', 70),\n",
       "                 ('n_neighbors', 35),\n",
       "                 ('p', 2),\n",
       "                 ('weights', 'distance')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 30),\n",
       "                 ('n_neighbors', 23),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'ball_tree'),\n",
       "                 ('leaf_size', 28),\n",
       "                 ('n_neighbors', 9),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'distance')]),\n",
       "    OrderedDict([('algorithm', 'kd_tree'),\n",
       "                 ('leaf_size', 82),\n",
       "                 ('n_neighbors', 21),\n",
       "                 ('p', 2),\n",
       "                 ('weights', 'distance')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 100),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 100),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'brute'),\n",
       "                 ('leaf_size', 13),\n",
       "                 ('n_neighbors', 15),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'distance')]),\n",
       "    OrderedDict([('algorithm', 'ball_tree'),\n",
       "                 ('leaf_size', 26),\n",
       "                 ('n_neighbors', 31),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 100),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'kd_tree'),\n",
       "                 ('leaf_size', 100),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'kd_tree'),\n",
       "                 ('leaf_size', 17),\n",
       "                 ('n_neighbors', 44),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 12),\n",
       "                 ('n_neighbors', 4),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 84),\n",
       "                 ('n_neighbors', 5),\n",
       "                 ('p', 2),\n",
       "                 ('weights', 'distance')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'brute'),\n",
       "                 ('leaf_size', 17),\n",
       "                 ('n_neighbors', 50),\n",
       "                 ('p', 2),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 79),\n",
       "                 ('n_neighbors', 11),\n",
       "                 ('p', 2),\n",
       "                 ('weights', 'distance')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 74),\n",
       "                 ('n_neighbors', 44),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 100),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 97),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'ball_tree'),\n",
       "                 ('leaf_size', 79),\n",
       "                 ('n_neighbors', 15),\n",
       "                 ('p', 2),\n",
       "                 ('weights', 'distance')]),\n",
       "    OrderedDict([('algorithm', 'ball_tree'),\n",
       "                 ('leaf_size', 81),\n",
       "                 ('n_neighbors', 30),\n",
       "                 ('p', 2),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'brute'),\n",
       "                 ('leaf_size', 80),\n",
       "                 ('n_neighbors', 24),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 100),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 100),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 100),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 71),\n",
       "                 ('n_neighbors', 50),\n",
       "                 ('p', 2),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 100),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'brute'),\n",
       "                 ('leaf_size', 33),\n",
       "                 ('n_neighbors', 35),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'distance')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 100),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 100),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 26),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 100),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 91),\n",
       "                 ('n_neighbors', 33),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'distance')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 100),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 100),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 24),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 100),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 98),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 99),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 100),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 100),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 100),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 100),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 10),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')]),\n",
       "    OrderedDict([('algorithm', 'auto'),\n",
       "                 ('leaf_size', 100),\n",
       "                 ('n_neighbors', 2),\n",
       "                 ('p', 1),\n",
       "                 ('weights', 'uniform')])],\n",
       "   'split0_test_score': array([-0.39540259, -0.41783548, -0.38431512, -0.39505121, -0.41448093,\n",
       "          -0.41437611, -0.38854112, -0.41435327, -0.40782774, -0.36296343,\n",
       "          -0.36731202, -0.34356391, -0.37117144, -0.36728568, -0.36863836,\n",
       "          -0.43985073, -0.36625308, -0.37184074, -0.36731202, -0.36731202,\n",
       "          -0.3714935 , -0.36731202, -0.35354265, -0.36731202, -0.378822  ,\n",
       "          -0.37705664, -0.36731202, -0.38600878, -0.39866651, -0.3902783 ,\n",
       "          -0.37413844, -0.37478769, -0.36731202, -0.36731202, -0.38077374,\n",
       "          -0.4067301 , -0.36731202, -0.36863836, -0.36731202, -0.43447304,\n",
       "          -0.36666031, -0.34713005, -0.36731202, -0.36731202, -0.41992009,\n",
       "          -0.36731202, -0.35740102, -0.36731202, -0.36731202, -0.43440959,\n",
       "          -0.36731202, -0.36731202, -0.36312077, -0.39223941, -0.39250777,\n",
       "          -0.36731202, -0.36731202, -0.36731202, -0.36731202, -0.36731202,\n",
       "          -0.36731202, -0.36731202, -0.36731202, -0.36731202, -0.41992009,\n",
       "          -0.36731202, -0.36731202, -0.41115941, -0.36731202, -0.36731202,\n",
       "          -0.36731202, -0.36731202, -0.36731202, -0.36731202, -0.40843224,\n",
       "          -0.36731202, -0.36731202, -0.36731202, -0.36731202, -0.36731202,\n",
       "          -0.36731202, -0.36731202, -0.36731202, -0.36731202, -0.36731202,\n",
       "          -0.36731202, -0.36731202, -0.36731202, -0.36731202, -0.36731202,\n",
       "          -0.36731202, -0.36731202, -0.36731202, -0.36731202, -0.36731202,\n",
       "          -0.36731202, -0.36731202, -0.36731202, -0.36731202, -0.36731202]),\n",
       "   'split1_test_score': array([-0.46940698, -0.48990025, -0.45722863, -0.46753778, -0.48555989,\n",
       "          -0.4854439 , -0.4628971 , -0.48533082, -0.48082729, -0.44555492,\n",
       "          -0.44725515, -0.44105993, -0.44671619, -0.44723057, -0.44756338,\n",
       "          -0.50108087, -0.44741861, -0.44842874, -0.44725515, -0.44725515,\n",
       "          -0.4483999 , -0.44725515, -0.4408771 , -0.44725515, -0.45396208,\n",
       "          -0.4523154 , -0.44725515, -0.46127171, -0.47407143, -0.46521251,\n",
       "          -0.44877401, -0.45302363, -0.44725515, -0.44725515, -0.4550224 ,\n",
       "          -0.47668635, -0.44725515, -0.44756338, -0.44725515, -0.4988921 ,\n",
       "          -0.44774849, -0.43904558, -0.44725515, -0.44725515, -0.4898063 ,\n",
       "          -0.44725515, -0.44330369, -0.44725515, -0.44725515, -0.49886086,\n",
       "          -0.44725515, -0.44725515, -0.44579317, -0.46622726, -0.4665181 ,\n",
       "          -0.44725515, -0.44725515, -0.44725515, -0.44725515, -0.44725515,\n",
       "          -0.44725515, -0.44725515, -0.44725515, -0.44725515, -0.4898063 ,\n",
       "          -0.44725515, -0.44725515, -0.48232411, -0.44725515, -0.44725515,\n",
       "          -0.44725515, -0.44725515, -0.44725515, -0.44725515, -0.47908252,\n",
       "          -0.44725515, -0.44725515, -0.44725515, -0.44725515, -0.44725515,\n",
       "          -0.44725515, -0.44725515, -0.44725515, -0.44725515, -0.44725515,\n",
       "          -0.44725515, -0.44725515, -0.44725515, -0.44725515, -0.44725515,\n",
       "          -0.44725515, -0.44725515, -0.44725515, -0.44725515, -0.44725515,\n",
       "          -0.44725515, -0.44725515, -0.44725515, -0.44725515, -0.44725515]),\n",
       "   'split2_test_score': array([-0.3939291 , -0.43355967, -0.35389881, -0.36687239, -0.39944647,\n",
       "          -0.39944639, -0.3598465 , -0.3992685 , -0.41588225, -0.35638091,\n",
       "          -0.32933908, -0.33687259, -0.33047307, -0.329289  , -0.32874293,\n",
       "          -0.43695763, -0.32984129, -0.33128708, -0.32933908, -0.32933908,\n",
       "          -0.33088512, -0.32933908, -0.34169378, -0.32933908, -0.36738649,\n",
       "          -0.33846065, -0.32933908, -0.37959249, -0.40282627, -0.36256118,\n",
       "          -0.33685038, -0.36413218, -0.32933908, -0.32933908, -0.34548194,\n",
       "          -0.38424079, -0.32933908, -0.32874293, -0.32933908, -0.42183094,\n",
       "          -0.3226178 , -0.33515128, -0.32933908, -0.32933908, -0.44309057,\n",
       "          -0.32933908, -0.34577579, -0.32933908, -0.32933908, -0.4219346 ,\n",
       "          -0.32933908, -0.32933908, -0.3555274 , -0.38786032, -0.36414374,\n",
       "          -0.32933908, -0.32933908, -0.32933908, -0.32933908, -0.32933908,\n",
       "          -0.32933908, -0.32933908, -0.32933908, -0.32933908, -0.44309057,\n",
       "          -0.32933908, -0.32933908, -0.3942985 , -0.32933908, -0.32933908,\n",
       "          -0.32933908, -0.32933908, -0.32933908, -0.32933908, -0.38918446,\n",
       "          -0.32933908, -0.32933908, -0.32933908, -0.32933908, -0.32933908,\n",
       "          -0.32933908, -0.32933908, -0.32933908, -0.32933908, -0.32933908,\n",
       "          -0.32933908, -0.32933908, -0.32933908, -0.32933908, -0.32933908,\n",
       "          -0.32933908, -0.32933908, -0.32933908, -0.32933908, -0.32933908,\n",
       "          -0.32933908, -0.32933908, -0.32933908, -0.32933908, -0.32933908]),\n",
       "   'split3_test_score': array([-0.38910508, -0.41121052, -0.34111352, -0.35279204, -0.37051557,\n",
       "          -0.37049582, -0.34802361, -0.37035272, -0.40157476, -0.36170051,\n",
       "          -0.3147963 , -0.3560316 , -0.3236032 , -0.31476998, -0.31563   ,\n",
       "          -0.39043011, -0.31683981, -0.32435912, -0.3147963 , -0.3147963 ,\n",
       "          -0.32476527, -0.3147963 , -0.357602  , -0.3147963 , -0.37420182,\n",
       "          -0.33182382, -0.3147963 , -0.38132313, -0.39579239, -0.34926949,\n",
       "          -0.32724919, -0.372592  , -0.3147963 , -0.3147963 , -0.33662754,\n",
       "          -0.36098458, -0.3147963 , -0.31563   , -0.3147963 , -0.38364075,\n",
       "          -0.31946989, -0.35700626, -0.3147963 , -0.3147963 , -0.41440565,\n",
       "          -0.3147963 , -0.35920129, -0.3147963 , -0.3147963 , -0.38340445,\n",
       "          -0.3147963 , -0.3147963 , -0.36224419, -0.38571665, -0.3511986 ,\n",
       "          -0.3147963 , -0.3147963 , -0.3147963 , -0.3147963 , -0.3147963 ,\n",
       "          -0.3147963 , -0.3147963 , -0.3147963 , -0.3147963 , -0.41440565,\n",
       "          -0.3147963 , -0.3147963 , -0.36788677, -0.3147963 , -0.3147963 ,\n",
       "          -0.3147963 , -0.3147963 , -0.3147963 , -0.3147963 , -0.36544041,\n",
       "          -0.3147963 , -0.3147963 , -0.3147963 , -0.3147963 , -0.3147963 ,\n",
       "          -0.3147963 , -0.3147963 , -0.3147963 , -0.3147963 , -0.3147963 ,\n",
       "          -0.3147963 , -0.3147963 , -0.3147963 , -0.3147963 , -0.3147963 ,\n",
       "          -0.3147963 , -0.3147963 , -0.3147963 , -0.3147963 , -0.3147963 ,\n",
       "          -0.3147963 , -0.3147963 , -0.3147963 , -0.3147963 , -0.3147963 ]),\n",
       "   'split4_test_score': array([-0.40160238, -0.42436013, -0.41927393, -0.42273239, -0.44443002,\n",
       "          -0.44411489, -0.42429427, -0.44396129, -0.41516308, -0.39763251,\n",
       "          -0.3762211 , -0.3558986 , -0.39180849, -0.37620067, -0.37589459,\n",
       "          -0.47664437, -0.37690108, -0.39424298, -0.3762211 , -0.3762211 ,\n",
       "          -0.3944061 , -0.3762211 , -0.37757618, -0.3762211 , -0.40196709,\n",
       "          -0.4068723 , -0.3762211 , -0.40194312, -0.40886956, -0.42112962,\n",
       "          -0.40257581, -0.40588959, -0.3762211 , -0.3762211 , -0.41408163,\n",
       "          -0.42883299, -0.3762211 , -0.37589459, -0.3762211 , -0.46080154,\n",
       "          -0.3836826 , -0.36584846, -0.3762211 , -0.3762211 , -0.43033032,\n",
       "          -0.3762211 , -0.38606796, -0.3762211 , -0.3762211 , -0.4606905 ,\n",
       "          -0.3762211 , -0.3762211 , -0.39853833, -0.40033993, -0.4219224 ,\n",
       "          -0.3762211 , -0.3762211 , -0.3762211 , -0.3762211 , -0.3762211 ,\n",
       "          -0.3762211 , -0.3762211 , -0.3762211 , -0.3762211 , -0.43033032,\n",
       "          -0.3762211 , -0.3762211 , -0.44008778, -0.3762211 , -0.3762211 ,\n",
       "          -0.3762211 , -0.3762211 , -0.3762211 , -0.3762211 , -0.4362769 ,\n",
       "          -0.3762211 , -0.3762211 , -0.3762211 , -0.3762211 , -0.3762211 ,\n",
       "          -0.3762211 , -0.3762211 , -0.3762211 , -0.3762211 , -0.3762211 ,\n",
       "          -0.3762211 , -0.3762211 , -0.3762211 , -0.3762211 , -0.3762211 ,\n",
       "          -0.3762211 , -0.3762211 , -0.3762211 , -0.3762211 , -0.3762211 ,\n",
       "          -0.3762211 , -0.3762211 , -0.3762211 , -0.3762211 , -0.3762211 ]),\n",
       "   'split5_test_score': array([-0.37109937, -0.41000535, -0.30087875, -0.31279721, -0.34688394,\n",
       "          -0.34725607, -0.30589074, -0.34707645, -0.39338985, -0.33514141,\n",
       "          -0.28191908, -0.31777861, -0.28641006, -0.28190017, -0.28225585,\n",
       "          -0.38384378, -0.28161312, -0.28553862, -0.28191908, -0.28191908,\n",
       "          -0.28521845, -0.28191908, -0.32312844, -0.28191908, -0.34756875,\n",
       "          -0.29293468, -0.28191908, -0.3580135 , -0.37892198, -0.30779919,\n",
       "          -0.29060032, -0.34596089, -0.28191908, -0.28191908, -0.29995822,\n",
       "          -0.32926412, -0.28191908, -0.28225585, -0.28191908, -0.3730829 ,\n",
       "          -0.28715158, -0.31975114, -0.28191908, -0.28191908, -0.41759509,\n",
       "          -0.28191908, -0.3291796 , -0.28191908, -0.28191908, -0.37320819,\n",
       "          -0.28191908, -0.28191908, -0.33504473, -0.36593682, -0.31077519,\n",
       "          -0.28191908, -0.28191908, -0.28191908, -0.28191908, -0.28191908,\n",
       "          -0.28191908, -0.28191908, -0.28191908, -0.28191908, -0.41759509,\n",
       "          -0.28191908, -0.28191908, -0.34115506, -0.28191908, -0.28191908,\n",
       "          -0.28191908, -0.28191908, -0.28191908, -0.28191908, -0.33503037,\n",
       "          -0.28191908, -0.28191908, -0.28191908, -0.28191908, -0.28191908,\n",
       "          -0.28191908, -0.28191908, -0.28191908, -0.28191908, -0.28191908,\n",
       "          -0.28191908, -0.28191908, -0.28191908, -0.28191908, -0.28191908,\n",
       "          -0.28191908, -0.28191908, -0.28191908, -0.28191908, -0.28191908,\n",
       "          -0.28191908, -0.28191908, -0.28191908, -0.28191908, -0.28191908]),\n",
       "   'split6_test_score': array([-0.46140432, -0.49105503, -0.52503478, -0.53009323, -0.54282221,\n",
       "          -0.54277392, -0.52767138, -0.54285586, -0.47634024, -0.45849998,\n",
       "          -0.51763607, -0.43706268, -0.52022296, -0.51764512, -0.5176777 ,\n",
       "          -0.55849642, -0.51779864, -0.51990205, -0.51763607, -0.51763607,\n",
       "          -0.51956041, -0.51763607, -0.44504353, -0.51763607, -0.46514979,\n",
       "          -0.52207814, -0.51763607, -0.46266204, -0.46501765, -0.52898253,\n",
       "          -0.52079946, -0.46442937, -0.51763607, -0.51763607, -0.52322605,\n",
       "          -0.53692016, -0.51763607, -0.5176777 , -0.51763607, -0.55103192,\n",
       "          -0.52336461, -0.43979567, -0.51763607, -0.51763607, -0.49962885,\n",
       "          -0.51763607, -0.45190854, -0.51763607, -0.51763607, -0.5512999 ,\n",
       "          -0.51763607, -0.51763607, -0.45921159, -0.46029756, -0.52983936,\n",
       "          -0.51763607, -0.51763607, -0.51763607, -0.51763607, -0.51763607,\n",
       "          -0.51763607, -0.51763607, -0.51763607, -0.51763607, -0.49962885,\n",
       "          -0.51763607, -0.51763607, -0.54057987, -0.51763607, -0.51763607,\n",
       "          -0.51763607, -0.51763607, -0.51763607, -0.51763607, -0.53862257,\n",
       "          -0.51763607, -0.51763607, -0.51763607, -0.51763607, -0.51763607,\n",
       "          -0.51763607, -0.51763607, -0.51763607, -0.51763607, -0.51763607,\n",
       "          -0.51763607, -0.51763607, -0.51763607, -0.51763607, -0.51763607,\n",
       "          -0.51763607, -0.51763607, -0.51763607, -0.51763607, -0.51763607,\n",
       "          -0.51763607, -0.51763607, -0.51763607, -0.51763607, -0.51763607]),\n",
       "   'split7_test_score': array([-0.40690507, -0.42941602, -0.39164745, -0.39813382, -0.40967631,\n",
       "          -0.40971495, -0.39653084, -0.40975522, -0.41944413, -0.3874588 ,\n",
       "          -0.36060171, -0.38702096, -0.37322667, -0.37154356, -0.3604501 ,\n",
       "          -0.42118875, -0.37036134, -0.37443783, -0.36060171, -0.36060171,\n",
       "          -0.37400863, -0.36060171, -0.37041311, -0.36060171, -0.3926803 ,\n",
       "          -0.38142774, -0.36060171, -0.40329909, -0.41192165, -0.39503142,\n",
       "          -0.3807028 , -0.39442228, -0.36060171, -0.36060171, -0.38687169,\n",
       "          -0.40339214, -0.36060171, -0.3604501 , -0.36060171, -0.41984359,\n",
       "          -0.36727294, -0.38503174, -0.36060171, -0.36060171, -0.42827699,\n",
       "          -0.36060171, -0.38521397, -0.36060171, -0.36060171, -0.41973173,\n",
       "          -0.36060171, -0.36060171, -0.38788991, -0.40397185, -0.39670346,\n",
       "          -0.36060171, -0.36060171, -0.36060171, -0.36060171, -0.36060171,\n",
       "          -0.36060171, -0.36060171, -0.36060171, -0.36060171, -0.42827699,\n",
       "          -0.36060171, -0.36060171, -0.40781681, -0.36060171, -0.36060171,\n",
       "          -0.36060171, -0.36060171, -0.36060171, -0.36060171, -0.40604543,\n",
       "          -0.36060171, -0.36060171, -0.36060171, -0.36060171, -0.36060171,\n",
       "          -0.36060171, -0.36060171, -0.36060171, -0.36060171, -0.36060171,\n",
       "          -0.36060171, -0.36060171, -0.36060171, -0.36060171, -0.36060171,\n",
       "          -0.36060171, -0.36060171, -0.36060171, -0.36060171, -0.36060171,\n",
       "          -0.36060171, -0.36060171, -0.36060171, -0.36060171, -0.36060171]),\n",
       "   'split8_test_score': array([-0.37827295, -0.39757073, -0.33514476, -0.34497762, -0.36439262,\n",
       "          -0.36424375, -0.34023963, -0.36441026, -0.38964847, -0.37249731,\n",
       "          -0.32520481, -0.3592126 , -0.33099961, -0.32520652, -0.32606357,\n",
       "          -0.38564316, -0.3272258 , -0.33168024, -0.32520481, -0.32520481,\n",
       "          -0.33159562, -0.32520481, -0.36862977, -0.32520481, -0.36900325,\n",
       "          -0.33536074, -0.32520481, -0.37062472, -0.38219672, -0.34236923,\n",
       "          -0.33376927, -0.36934772, -0.32520481, -0.32520481, -0.33408689,\n",
       "          -0.35457286, -0.32520481, -0.32606357, -0.32520481, -0.37996859,\n",
       "          -0.33005365, -0.36867612, -0.32520481, -0.32520481, -0.40029051,\n",
       "          -0.32520481, -0.37356365, -0.32520481, -0.32520481, -0.37987559,\n",
       "          -0.32520481, -0.32520481, -0.3723285 , -0.37471021, -0.3438076 ,\n",
       "          -0.32520481, -0.32520481, -0.32520481, -0.32520481, -0.32520481,\n",
       "          -0.32520481, -0.32520481, -0.32520481, -0.32520481, -0.40029051,\n",
       "          -0.32520481, -0.32520481, -0.36124624, -0.32520481, -0.32520481,\n",
       "          -0.32520481, -0.32520481, -0.32520481, -0.32520481, -0.35790639,\n",
       "          -0.32520481, -0.32520481, -0.32520481, -0.32520481, -0.32520481,\n",
       "          -0.32520481, -0.32520481, -0.32520481, -0.32520481, -0.32520481,\n",
       "          -0.32520481, -0.32520481, -0.32520481, -0.32520481, -0.32520481,\n",
       "          -0.32520481, -0.32520481, -0.32520481, -0.32520481, -0.32520481,\n",
       "          -0.32520481, -0.32520481, -0.32520481, -0.32520481, -0.32520481]),\n",
       "   'split9_test_score': array([-0.48546049, -0.49420003, -0.44022264, -0.44031199, -0.44454966,\n",
       "          -0.44469404, -0.44078269, -0.44482124, -0.485715  , -0.51946518,\n",
       "          -0.40524344, -0.4898028 , -0.41172844, -0.40522092, -0.40547456,\n",
       "          -0.47447404, -0.40525903, -0.41440339, -0.40524344, -0.40524344,\n",
       "          -0.41447077, -0.40524344, -0.50607988, -0.40524344, -0.50600554,\n",
       "          -0.42882493, -0.40524344, -0.49327836, -0.48427259, -0.44059031,\n",
       "          -0.4225349 , -0.50992504, -0.40524344, -0.40524344, -0.43509357,\n",
       "          -0.4402995 , -0.40524344, -0.40547456, -0.40524344, -0.45744365,\n",
       "          -0.41086481, -0.49168776, -0.40524344, -0.40524344, -0.50438144,\n",
       "          -0.40524344, -0.51196982, -0.40524344, -0.40524344, -0.45762729,\n",
       "          -0.40524344, -0.40524344, -0.51976582, -0.48638527, -0.44074441,\n",
       "          -0.40524344, -0.40524344, -0.40524344, -0.40524344, -0.40524344,\n",
       "          -0.40524344, -0.40524344, -0.40524344, -0.40524344, -0.50438144,\n",
       "          -0.40524344, -0.40524344, -0.44191942, -0.40524344, -0.40524344,\n",
       "          -0.40524344, -0.40524344, -0.40524344, -0.40524344, -0.44045757,\n",
       "          -0.40524344, -0.40524344, -0.40524344, -0.40524344, -0.40524344,\n",
       "          -0.40524344, -0.40524344, -0.40524344, -0.40524344, -0.40524344,\n",
       "          -0.40524344, -0.40524344, -0.40524344, -0.40524344, -0.40524344,\n",
       "          -0.40524344, -0.40524344, -0.40524344, -0.40524344, -0.40524344,\n",
       "          -0.40524344, -0.40524344, -0.40524344, -0.40524344, -0.40524344]),\n",
       "   'mean_test_score': array([-0.41525883, -0.43991132, -0.39487584, -0.40312997, -0.42227576,\n",
       "          -0.42225598, -0.39947179, -0.42221856, -0.42858128, -0.3997295 ,\n",
       "          -0.37255288, -0.38243043, -0.37863601, -0.37362922, -0.3728391 ,\n",
       "          -0.44686099, -0.37395118, -0.37961208, -0.37255288, -0.37255288,\n",
       "          -0.37948038, -0.37255288, -0.38845865, -0.37255288, -0.40567471,\n",
       "          -0.38671551, -0.37255288, -0.40980169, -0.42025567, -0.40032238,\n",
       "          -0.38379946, -0.40545104, -0.37255288, -0.37255288, -0.39112237,\n",
       "          -0.41219236, -0.37255288, -0.3728391 , -0.37255288, -0.4381009 ,\n",
       "          -0.37588867, -0.38491241, -0.37255288, -0.37255288, -0.44477258,\n",
       "          -0.37255288, -0.39435853, -0.37255288, -0.37255288, -0.43810427,\n",
       "          -0.37255288, -0.37255288, -0.39994644, -0.41236853, -0.40181606,\n",
       "          -0.37255288, -0.37255288, -0.37255288, -0.37255288, -0.37255288,\n",
       "          -0.37255288, -0.37255288, -0.37255288, -0.37255288, -0.44477258,\n",
       "          -0.37255288, -0.37255288, -0.4188474 , -0.37255288, -0.37255288,\n",
       "          -0.37255288, -0.37255288, -0.37255288, -0.37255288, -0.41564789,\n",
       "          -0.37255288, -0.37255288, -0.37255288, -0.37255288, -0.37255288,\n",
       "          -0.37255288, -0.37255288, -0.37255288, -0.37255288, -0.37255288,\n",
       "          -0.37255288, -0.37255288, -0.37255288, -0.37255288, -0.37255288,\n",
       "          -0.37255288, -0.37255288, -0.37255288, -0.37255288, -0.37255288,\n",
       "          -0.37255288, -0.37255288, -0.37255288, -0.37255288, -0.37255288]),\n",
       "   'std_test_score': array([0.03885517, 0.03528788, 0.06369893, 0.06124969, 0.05654861,\n",
       "          0.05648693, 0.06276282, 0.05651747, 0.03551604, 0.05443877,\n",
       "          0.06598603, 0.05260978, 0.06492959, 0.06587596, 0.06589242,\n",
       "          0.05362958, 0.06562588, 0.06516452, 0.06598603, 0.06598603,\n",
       "          0.0651511 , 0.06598603, 0.05408123, 0.06598603, 0.04900666,\n",
       "          0.06457625, 0.06598603, 0.04361462, 0.03704365, 0.06236899,\n",
       "          0.06444987, 0.05034677, 0.06598603, 0.06598603, 0.06382557,\n",
       "          0.05872932, 0.06598603, 0.06589242, 0.06598603, 0.05340624,\n",
       "          0.06659763, 0.05186428, 0.06598603, 0.06598603, 0.0365117 ,\n",
       "          0.06598603, 0.05416207, 0.06598603, 0.06598603, 0.0534815 ,\n",
       "          0.06598603, 0.06598603, 0.0546296 , 0.04022665, 0.06184136,\n",
       "          0.06598603, 0.06598603, 0.06598603, 0.06598603, 0.06598603,\n",
       "          0.06598603, 0.06598603, 0.06598603, 0.06598603, 0.0365117 ,\n",
       "          0.06598603, 0.06598603, 0.0570666 , 0.06598603, 0.06598603,\n",
       "          0.06598603, 0.06598603, 0.06598603, 0.06598603, 0.057781  ,\n",
       "          0.06598603, 0.06598603, 0.06598603, 0.06598603, 0.06598603,\n",
       "          0.06598603, 0.06598603, 0.06598603, 0.06598603, 0.06598603,\n",
       "          0.06598603, 0.06598603, 0.06598603, 0.06598603, 0.06598603,\n",
       "          0.06598603, 0.06598603, 0.06598603, 0.06598603, 0.06598603,\n",
       "          0.06598603, 0.06598603, 0.06598603, 0.06598603, 0.06598603]),\n",
       "   'rank_test_score': array([ 87,  97,  75,  81,  93,  92,  76,  91,  94,  77,   1,  68,  65,\n",
       "           62,  60, 100,  63,  67,   1,   1,  66,   1,  72,   1,  83,  71,\n",
       "            1,  84,  90,  79,  69,  82,   1,   1,  73,  85,   1,  60,   1,\n",
       "           95,  64,  70,   1,   1,  98,   1,  74,   1,   1,  96,   1,   1,\n",
       "           78,  86,  80,   1,   1,   1,   1,   1,   1,   1,   1,   1,  98,\n",
       "            1,   1,  89,   1,   1,   1,   1,   1,   1,  88,   1,   1,   1,\n",
       "            1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "            1,   1,   1,   1,   1,   1,   1,   1,   1], dtype=int32)}}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.722172192797577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.722172192797577\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9457936447726392, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9457936447726392\n",
      "[LightGBM] [Warning] feature_fraction is set=0.722172192797577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.722172192797577\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9457936447726392, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9457936447726392\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5251181027794909, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5251181027794909\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5251181027794909, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5251181027794909\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7467555456720641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7467555456720641\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7467555456720641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7467555456720641\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8795321843941388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8795321843941388\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8795321843941388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8795321843941388\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.515401886946663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.515401886946663\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.515401886946663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.515401886946663\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7634355677431282, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7634355677431282\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7702835112979058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7702835112979058\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7634355677431282, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7634355677431282\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7702835112979058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7702835112979058\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7213088905100546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213088905100546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7213088905100546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213088905100546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5097466354757849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5097466354757849\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7602844043654979, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7602844043654979\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5097466354757849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5097466354757849\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7602844043654979, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7602844043654979\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5020694803375102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5020694803375102\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5540885426228469, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5540885426228469\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5020694803375102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5020694803375102\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5540885426228469, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5540885426228469\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8350281884426594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8350281884426594\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8350281884426594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8350281884426594\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5140598674041665, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5140598674041665\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.629442121161646, subsample=1.0 will be ignored. Current value: bagging_fraction=0.629442121161646\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5140598674041665, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5140598674041665\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.629442121161646, subsample=1.0 will be ignored. Current value: bagging_fraction=0.629442121161646\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7392350355401398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7392350355401398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6938839605264809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6938839605264809\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6938839605264809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6938839605264809\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6587109527343454, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6587109527343454\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6587109527343454, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6587109527343454\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5588232543804782, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5588232543804782\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.530056102176457, subsample=1.0 will be ignored. Current value: bagging_fraction=0.530056102176457\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5588232543804782, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5588232543804782\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.530056102176457, subsample=1.0 will be ignored. Current value: bagging_fraction=0.530056102176457\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5879342643769147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5879342643769147\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5879342643769147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5879342643769147\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8941674821965382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8941674821965382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7213088905100546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213088905100546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7213088905100546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213088905100546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7634355677431282, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7634355677431282\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7702835112979058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7702835112979058\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7213088905100546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213088905100546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5097466354757849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5097466354757849\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7602844043654979, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7602844043654979\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5097466354757849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5097466354757849\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7602844043654979, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7602844043654979\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5020694803375102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5020694803375102\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5540885426228469, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5540885426228469\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5020694803375102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5020694803375102\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5540885426228469, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5540885426228469\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8350281884426594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8350281884426594\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8350281884426594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8350281884426594\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5140598674041665, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5140598674041665\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.629442121161646, subsample=1.0 will be ignored. Current value: bagging_fraction=0.629442121161646\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5140598674041665, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5140598674041665\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.629442121161646, subsample=1.0 will be ignored. Current value: bagging_fraction=0.629442121161646\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7392350355401398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7392350355401398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7392350355401398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7392350355401398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6938839605264809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6938839605264809\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6587109527343454, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6587109527343454\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5588232543804782, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5588232543804782\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.530056102176457, subsample=1.0 will be ignored. Current value: bagging_fraction=0.530056102176457\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5588232543804782, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5588232543804782\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.530056102176457, subsample=1.0 will be ignored. Current value: bagging_fraction=0.530056102176457\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5879342643769147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5879342643769147\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8941674821965382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8941674821965382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8941674821965382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8941674821965382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7213088905100546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213088905100546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8795321843941388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8795321843941388\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8795321843941388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8795321843941388\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.515401886946663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.515401886946663\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.515401886946663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.515401886946663\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7634355677431282, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7634355677431282\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7702835112979058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7702835112979058\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7634355677431282, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7634355677431282\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7702835112979058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7702835112979058\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7213088905100546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213088905100546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7213088905100546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213088905100546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5097466354757849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5097466354757849\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7602844043654979, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7602844043654979\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5020694803375102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5020694803375102\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5540885426228469, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5540885426228469\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8350281884426594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8350281884426594\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8350281884426594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8350281884426594\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5140598674041665, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5140598674041665\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.629442121161646, subsample=1.0 will be ignored. Current value: bagging_fraction=0.629442121161646\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7392350355401398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7392350355401398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6938839605264809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6938839605264809\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6587109527343454, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6587109527343454\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5588232543804782, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5588232543804782\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.530056102176457, subsample=1.0 will be ignored. Current value: bagging_fraction=0.530056102176457\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5588232543804782, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5588232543804782\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.530056102176457, subsample=1.0 will be ignored. Current value: bagging_fraction=0.530056102176457\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5879342643769147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5879342643769147\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5879342643769147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5879342643769147\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8941674821965382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8941674821965382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8941674821965382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8941674821965382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7213088905100546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213088905100546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829546076664571, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829546076664571\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829546076664571, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829546076664571\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.722172192797577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.722172192797577\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9457936447726392, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9457936447726392\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5251181027794909, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5251181027794909\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5251181027794909, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5251181027794909\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7467555456720641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7467555456720641\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7467555456720641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7467555456720641\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8795321843941388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8795321843941388\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8795321843941388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8795321843941388\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.515401886946663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.515401886946663\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.515401886946663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.515401886946663\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7634355677431282, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7634355677431282\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7702835112979058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7702835112979058\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7213088905100546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213088905100546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7213088905100546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213088905100546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5097466354757849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5097466354757849\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7602844043654979, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7602844043654979\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5020694803375102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5020694803375102\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5540885426228469, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5540885426228469\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5020694803375102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5020694803375102\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5540885426228469, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5540885426228469\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8350281884426594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8350281884426594\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5140598674041665, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5140598674041665\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.629442121161646, subsample=1.0 will be ignored. Current value: bagging_fraction=0.629442121161646\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5140598674041665, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5140598674041665\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.629442121161646, subsample=1.0 will be ignored. Current value: bagging_fraction=0.629442121161646\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7392350355401398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7392350355401398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7392350355401398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7392350355401398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6938839605264809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6938839605264809\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6938839605264809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6938839605264809\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6587109527343454, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6587109527343454\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6587109527343454, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6587109527343454\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5588232543804782, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5588232543804782\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.530056102176457, subsample=1.0 will be ignored. Current value: bagging_fraction=0.530056102176457\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5879342643769147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5879342643769147\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8941674821965382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8941674821965382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8941674821965382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8941674821965382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7213088905100546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213088905100546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7213088905100546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213088905100546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5276954526883374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5276954526883374\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5276954526883374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5276954526883374\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6189633097648055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6189633097648055\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6189633097648055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6189633097648055\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7327978832817351, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7327978832817351\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8778014457239963, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8778014457239963\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7327978832817351, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7327978832817351\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8778014457239963, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8778014457239963\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9756908253050366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9756908253050366\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9756908253050366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9756908253050366\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7272057454468276, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272057454468276\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5602471751326271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5602471751326271\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7272057454468276, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272057454468276\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5602471751326271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5602471751326271\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829546076664571, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829546076664571\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829546076664571, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829546076664571\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.722172192797577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.722172192797577\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9457936447726392, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9457936447726392\n",
      "[LightGBM] [Warning] feature_fraction is set=0.722172192797577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.722172192797577\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9457936447726392, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9457936447726392\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5251181027794909, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5251181027794909\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5251181027794909, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5251181027794909\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7467555456720641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7467555456720641\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7467555456720641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7467555456720641\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8795321843941388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8795321843941388\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8795321843941388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8795321843941388\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.515401886946663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.515401886946663\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7634355677431282, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7634355677431282\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7702835112979058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7702835112979058\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7634355677431282, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7634355677431282\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7702835112979058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7702835112979058\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7213088905100546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213088905100546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7213088905100546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213088905100546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5097466354757849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5097466354757849\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7602844043654979, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7602844043654979\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5097466354757849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5097466354757849\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7602844043654979, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7602844043654979\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5020694803375102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5020694803375102\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5540885426228469, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5540885426228469\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5020694803375102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5020694803375102\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5540885426228469, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5540885426228469\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8350281884426594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8350281884426594\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5140598674041665, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5140598674041665\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.629442121161646, subsample=1.0 will be ignored. Current value: bagging_fraction=0.629442121161646\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5140598674041665, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5140598674041665\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.629442121161646, subsample=1.0 will be ignored. Current value: bagging_fraction=0.629442121161646\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7392350355401398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7392350355401398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7392350355401398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7392350355401398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6938839605264809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6938839605264809\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6938839605264809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6938839605264809\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6587109527343454, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6587109527343454\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6587109527343454, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6587109527343454\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5588232543804782, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5588232543804782\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.530056102176457, subsample=1.0 will be ignored. Current value: bagging_fraction=0.530056102176457\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5588232543804782, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5588232543804782\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.530056102176457, subsample=1.0 will be ignored. Current value: bagging_fraction=0.530056102176457\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5879342643769147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5879342643769147\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5879342643769147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5879342643769147\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8941674821965382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8941674821965382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8941674821965382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8941674821965382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7213088905100546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213088905100546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7213088905100546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213088905100546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7272057454468276, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272057454468276\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5602471751326271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5602471751326271\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829546076664571, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829546076664571\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.722172192797577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.722172192797577\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9457936447726392, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9457936447726392\n",
      "[LightGBM] [Warning] feature_fraction is set=0.722172192797577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.722172192797577\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9457936447726392, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9457936447726392\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5251181027794909, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5251181027794909\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7467555456720641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7467555456720641\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8795321843941388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8795321843941388\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.515401886946663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.515401886946663\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.515401886946663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.515401886946663\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7634355677431282, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7634355677431282\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7702835112979058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7702835112979058\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7634355677431282, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7634355677431282\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7702835112979058, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7702835112979058\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7213088905100546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213088905100546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5097466354757849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5097466354757849\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7602844043654979, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7602844043654979\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5097466354757849, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5097466354757849\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7602844043654979, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7602844043654979\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5020694803375102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5020694803375102\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5540885426228469, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5540885426228469\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8350281884426594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8350281884426594\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8350281884426594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8350281884426594\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5140598674041665, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5140598674041665\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.629442121161646, subsample=1.0 will be ignored. Current value: bagging_fraction=0.629442121161646\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7392350355401398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7392350355401398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7392350355401398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7392350355401398\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6938839605264809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6938839605264809\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6938839605264809, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6938839605264809\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6587109527343454, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6587109527343454\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6587109527343454, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6587109527343454\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5588232543804782, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5588232543804782\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.530056102176457, subsample=1.0 will be ignored. Current value: bagging_fraction=0.530056102176457\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5879342643769147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5879342643769147\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5879342643769147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5879342643769147\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8941674821965382, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8941674821965382\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7213088905100546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213088905100546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7213088905100546, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7213088905100546\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n"
     ]
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "366df8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(pickle_file_path, 'rb') as handle:\n",
    "    results = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0ebf5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x1500 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 创建一个3x3的子图\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "\n",
    "# 循环遍历每个模型名称，并在相应的子图中绘制\n",
    "for idx, model_name in enumerate(model_names):\n",
    "    optimization_history = results[model_name]['optimization_history']\n",
    "\n",
    "    scores = optimization_history['mean_test_score']\n",
    "    iterations = range(1, len(scores) + 1)\n",
    "\n",
    "    best_scores = np.maximum.accumulate(scores)\n",
    "\n",
    "    ax = axs[idx // 3, idx % 3]  # 确定当前子图位置\n",
    "    ax.plot(iterations, scores, marker='o', label='Iteration Scores')\n",
    "    ax.plot(iterations, best_scores, marker='x', linestyle='--', label='Best Scores')\n",
    "    ax.set_xlabel('HP Optimization Iteration')\n",
    "    ax.set_ylabel('Negative Mean Absolute Error')\n",
    "    ax.set_title(model_name)\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "# 调整子图之间的间距\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "fig.savefig('Optimization_history' + data_for + '.png', dpi=300, format='png', transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1a9483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_HP_df = pd.DataFrame([(model, best_params) for model, best_params in results.items()], columns=['Model', 'Best Hyperparameter'])\n",
    "optimized_HP_df.to_excel('Table_SI_optimized_HP' + data_for + '.xlsx', index = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8b18ae",
   "metadata": {},
   "source": [
    "# Model evaluation using the literature test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "405866ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/tree/_classes.py:306: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "  warnings.warn(\n",
      "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0'`.\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/shichenma/opt/anaconda3/envs/Solubility/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:416: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7276147634418255, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7276147634418255\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7382668290280634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7382668290280634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9398644747208972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9398644747208972\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9398644747208972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9398644747208972\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5345692040165404, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5345692040165404\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9698399160129514, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9698399160129514\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9698399160129514, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9698399160129514\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9856124647994302, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9856124647994302\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6389064676271512, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6389064676271512\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6389064676271512, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6389064676271512\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118929555283037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118929555283037\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8118929555283037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8118929555283037\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7082843226968932, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7082843226968932\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7082843226968932, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7082843226968932\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9426618146192435, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9426618146192435\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7065451482709622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7065451482709622\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9426618146192435, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9426618146192435\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7065451482709622, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7065451482709622\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7388928029926499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7388928029926499\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5276954526883374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5276954526883374\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5276954526883374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5276954526883374\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6189633097648055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6189633097648055\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7327978832817351, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7327978832817351\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8778014457239963, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8778014457239963\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9756908253050366, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9756908253050366\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7272057454468276, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272057454468276\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5602471751326271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5602471751326271\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7272057454468276, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7272057454468276\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5602471751326271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5602471751326271\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829546076664571, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829546076664571\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9829546076664571, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9829546076664571\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.722172192797577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.722172192797577\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9457936447726392, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9457936447726392\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5251181027794909, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5251181027794909\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7467555456720641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7467555456720641\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7467555456720641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7467555456720641\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8795321843941388, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8795321843941388\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.515401886946663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.515401886946663\n"
     ]
    }
   ],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "metrics = ['MAE', 'MedAE', 'RMSE', 'MSE', 'PCC', 'SCC']\n",
    "train_summary = pd.DataFrame(index=metrics, columns=model_names)\n",
    "test_summary = pd.DataFrame(index=metrics, columns=model_names)\n",
    "predictions = pd.DataFrame(columns=model_names)\n",
    "\n",
    "for model_name in model_names:\n",
    "    model = results[model_name]['best_estimator']\n",
    "\n",
    "    cv = GroupKFold(n_splits=10)\n",
    "    Y_pred_train = cross_val_predict(model, X_train, Y_train, cv=cv, groups=G_train, n_jobs=6)\n",
    "    \n",
    "    train_summary[model_name]['MAE'] = mean_absolute_error(Y_train, Y_pred_train)\n",
    "    train_summary[model_name]['MedAE'] = np.median(abs(Y_train.values - Y_pred_train))\n",
    "    train_summary[model_name]['RMSE'] = rmse(Y_train, Y_pred_train)\n",
    "    train_summary[model_name]['MSE'] = mean_squared_error(Y_train, Y_pred_train)\n",
    "    train_summary[model_name]['PCC'] = pearsonr(Y_train, Y_pred_train)[0]\n",
    "    train_summary[model_name]['SCC'] = spearmanr(Y_train, Y_pred_train)[0]\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    test_summary[model_name]['MAE'] = mean_absolute_error(Y_test, Y_pred_test)\n",
    "    test_summary[model_name]['MedAE'] = np.median(abs(Y_test.values - Y_pred_test))\n",
    "    test_summary[model_name]['RMSE'] = rmse(Y_test, Y_pred_test)\n",
    "    test_summary[model_name]['MSE'] = mean_squared_error(Y_test, Y_pred_test)\n",
    "    test_summary[model_name]['PCC'] = pearsonr(Y_test, Y_pred_test)[0]\n",
    "    test_summary[model_name]['SCC'] = spearmanr(Y_test, Y_pred_test)[0]\n",
    "    \n",
    "    predictions[model_name] = Y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47196b2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT</th>\n",
       "      <th>RF</th>\n",
       "      <th>XGB</th>\n",
       "      <th>NN</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>MLR</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>PLS</th>\n",
       "      <th>kNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.466604</td>\n",
       "      <td>0.419224</td>\n",
       "      <td>0.313857</td>\n",
       "      <td>0.355612</td>\n",
       "      <td>0.304708</td>\n",
       "      <td>15805513690.182011</td>\n",
       "      <td>0.42075</td>\n",
       "      <td>0.517055</td>\n",
       "      <td>0.372601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedAE</th>\n",
       "      <td>0.326391</td>\n",
       "      <td>0.299936</td>\n",
       "      <td>0.218969</td>\n",
       "      <td>0.244456</td>\n",
       "      <td>0.206032</td>\n",
       "      <td>0.51082</td>\n",
       "      <td>0.332001</td>\n",
       "      <td>0.911558</td>\n",
       "      <td>0.217619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.653108</td>\n",
       "      <td>0.575666</td>\n",
       "      <td>0.445129</td>\n",
       "      <td>0.519619</td>\n",
       "      <td>0.441142</td>\n",
       "      <td>164085493934.91684</td>\n",
       "      <td>0.556553</td>\n",
       "      <td>0.676728</td>\n",
       "      <td>0.589886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.42655</td>\n",
       "      <td>0.331392</td>\n",
       "      <td>0.19814</td>\n",
       "      <td>0.270004</td>\n",
       "      <td>0.194606</td>\n",
       "      <td>26924049319865631113216.0</td>\n",
       "      <td>0.309751</td>\n",
       "      <td>0.457961</td>\n",
       "      <td>0.347965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCC</th>\n",
       "      <td>0.789436</td>\n",
       "      <td>0.827981</td>\n",
       "      <td>0.90053</td>\n",
       "      <td>0.867011</td>\n",
       "      <td>0.902438</td>\n",
       "      <td>-0.007601</td>\n",
       "      <td>0.841386</td>\n",
       "      <td>[0.7608982099732914]</td>\n",
       "      <td>0.835883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCC</th>\n",
       "      <td>0.75902</td>\n",
       "      <td>0.791287</td>\n",
       "      <td>0.88463</td>\n",
       "      <td>0.85134</td>\n",
       "      <td>0.888681</td>\n",
       "      <td>0.542158</td>\n",
       "      <td>0.819654</td>\n",
       "      <td>0.733371</td>\n",
       "      <td>0.81378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DT        RF       XGB        NN  LightGBM  \\\n",
       "MAE    0.466604  0.419224  0.313857  0.355612  0.304708   \n",
       "MedAE  0.326391  0.299936  0.218969  0.244456  0.206032   \n",
       "RMSE   0.653108  0.575666  0.445129  0.519619  0.441142   \n",
       "MSE     0.42655  0.331392   0.19814  0.270004  0.194606   \n",
       "PCC    0.789436  0.827981   0.90053  0.867011  0.902438   \n",
       "SCC     0.75902  0.791287   0.88463   0.85134  0.888681   \n",
       "\n",
       "                             MLR     Lasso                   PLS       kNN  \n",
       "MAE           15805513690.182011   0.42075              0.517055  0.372601  \n",
       "MedAE                    0.51082  0.332001              0.911558  0.217619  \n",
       "RMSE          164085493934.91684  0.556553              0.676728  0.589886  \n",
       "MSE    26924049319865631113216.0  0.309751              0.457961  0.347965  \n",
       "PCC                    -0.007601  0.841386  [0.7608982099732914]  0.835883  \n",
       "SCC                     0.542158  0.819654              0.733371   0.81378  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05dd54c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT</th>\n",
       "      <th>RF</th>\n",
       "      <th>XGB</th>\n",
       "      <th>NN</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>MLR</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>PLS</th>\n",
       "      <th>kNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.493109</td>\n",
       "      <td>0.432282</td>\n",
       "      <td>0.310961</td>\n",
       "      <td>0.354327</td>\n",
       "      <td>0.301628</td>\n",
       "      <td>3632783918.718997</td>\n",
       "      <td>0.534682</td>\n",
       "      <td>0.50342</td>\n",
       "      <td>0.35328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedAE</th>\n",
       "      <td>0.332722</td>\n",
       "      <td>0.275598</td>\n",
       "      <td>0.169482</td>\n",
       "      <td>0.238689</td>\n",
       "      <td>0.190974</td>\n",
       "      <td>0.491904</td>\n",
       "      <td>0.341277</td>\n",
       "      <td>0.922107</td>\n",
       "      <td>0.223003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.712609</td>\n",
       "      <td>0.656919</td>\n",
       "      <td>0.484724</td>\n",
       "      <td>0.558513</td>\n",
       "      <td>0.462983</td>\n",
       "      <td>25057178586.497921</td>\n",
       "      <td>1.034779</td>\n",
       "      <td>0.698993</td>\n",
       "      <td>0.532319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.431542</td>\n",
       "      <td>0.234957</td>\n",
       "      <td>0.311937</td>\n",
       "      <td>0.214353</td>\n",
       "      <td>627862198715649884160.0</td>\n",
       "      <td>1.070767</td>\n",
       "      <td>0.488591</td>\n",
       "      <td>0.283363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCC</th>\n",
       "      <td>0.767986</td>\n",
       "      <td>0.810882</td>\n",
       "      <td>0.905084</td>\n",
       "      <td>0.867883</td>\n",
       "      <td>0.911951</td>\n",
       "      <td>-0.050615</td>\n",
       "      <td>0.608138</td>\n",
       "      <td>[0.7784872107561801]</td>\n",
       "      <td>0.878558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCC</th>\n",
       "      <td>0.77205</td>\n",
       "      <td>0.827561</td>\n",
       "      <td>0.908206</td>\n",
       "      <td>0.880334</td>\n",
       "      <td>0.912881</td>\n",
       "      <td>0.685666</td>\n",
       "      <td>0.806404</td>\n",
       "      <td>0.791676</td>\n",
       "      <td>0.866065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DT        RF       XGB        NN  LightGBM  \\\n",
       "MAE    0.493109  0.432282  0.310961  0.354327  0.301628   \n",
       "MedAE  0.332722  0.275598  0.169482  0.238689  0.190974   \n",
       "RMSE   0.712609  0.656919  0.484724  0.558513  0.462983   \n",
       "MSE    0.507812  0.431542  0.234957  0.311937  0.214353   \n",
       "PCC    0.767986  0.810882  0.905084  0.867883  0.911951   \n",
       "SCC     0.77205  0.827561  0.908206  0.880334  0.912881   \n",
       "\n",
       "                           MLR     Lasso                   PLS       kNN  \n",
       "MAE          3632783918.718997  0.534682               0.50342   0.35328  \n",
       "MedAE                 0.491904  0.341277              0.922107  0.223003  \n",
       "RMSE        25057178586.497921  1.034779              0.698993  0.532319  \n",
       "MSE    627862198715649884160.0  1.070767              0.488591  0.283363  \n",
       "PCC                  -0.050615  0.608138  [0.7784872107561801]  0.878558  \n",
       "SCC                   0.685666  0.806404              0.791676  0.866065  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e48d9e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT</th>\n",
       "      <th>RF</th>\n",
       "      <th>XGB</th>\n",
       "      <th>NN</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>MLR</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>PLS</th>\n",
       "      <th>kNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.493639</td>\n",
       "      <td>0.123010</td>\n",
       "      <td>0.090379</td>\n",
       "      <td>0.048439</td>\n",
       "      <td>0.145469</td>\n",
       "      <td>0.511013</td>\n",
       "      <td>0.212471</td>\n",
       "      <td>0.269927</td>\n",
       "      <td>0.130301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.393487</td>\n",
       "      <td>0.022858</td>\n",
       "      <td>0.006974</td>\n",
       "      <td>0.119783</td>\n",
       "      <td>0.020668</td>\n",
       "      <td>0.303957</td>\n",
       "      <td>0.007025</td>\n",
       "      <td>0.461491</td>\n",
       "      <td>0.383835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.347997</td>\n",
       "      <td>0.520759</td>\n",
       "      <td>0.389370</td>\n",
       "      <td>0.379648</td>\n",
       "      <td>0.362066</td>\n",
       "      <td>0.064391</td>\n",
       "      <td>0.370642</td>\n",
       "      <td>0.924756</td>\n",
       "      <td>0.564785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.269406</td>\n",
       "      <td>0.049914</td>\n",
       "      <td>0.082744</td>\n",
       "      <td>0.130718</td>\n",
       "      <td>0.207453</td>\n",
       "      <td>0.556341</td>\n",
       "      <td>0.254460</td>\n",
       "      <td>0.262204</td>\n",
       "      <td>0.354590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.559507</td>\n",
       "      <td>0.179512</td>\n",
       "      <td>0.121404</td>\n",
       "      <td>0.083469</td>\n",
       "      <td>0.253092</td>\n",
       "      <td>0.650886</td>\n",
       "      <td>0.351965</td>\n",
       "      <td>0.139307</td>\n",
       "      <td>0.136240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6561</th>\n",
       "      <td>0.423969</td>\n",
       "      <td>0.210884</td>\n",
       "      <td>0.152290</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.276320</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.096445</td>\n",
       "      <td>0.163685</td>\n",
       "      <td>0.300149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6562</th>\n",
       "      <td>0.334045</td>\n",
       "      <td>0.120961</td>\n",
       "      <td>0.084644</td>\n",
       "      <td>0.130098</td>\n",
       "      <td>0.245387</td>\n",
       "      <td>0.410275</td>\n",
       "      <td>0.124719</td>\n",
       "      <td>0.150995</td>\n",
       "      <td>0.233798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6563</th>\n",
       "      <td>0.264479</td>\n",
       "      <td>0.051395</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.206465</td>\n",
       "      <td>0.216567</td>\n",
       "      <td>0.359816</td>\n",
       "      <td>0.173351</td>\n",
       "      <td>0.117947</td>\n",
       "      <td>0.177779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6564</th>\n",
       "      <td>0.056915</td>\n",
       "      <td>0.306661</td>\n",
       "      <td>0.145904</td>\n",
       "      <td>0.098061</td>\n",
       "      <td>0.285338</td>\n",
       "      <td>0.584591</td>\n",
       "      <td>0.044175</td>\n",
       "      <td>0.273137</td>\n",
       "      <td>0.228076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>0.329513</td>\n",
       "      <td>0.116429</td>\n",
       "      <td>0.009541</td>\n",
       "      <td>0.151796</td>\n",
       "      <td>0.157137</td>\n",
       "      <td>0.174756</td>\n",
       "      <td>0.356583</td>\n",
       "      <td>0.049702</td>\n",
       "      <td>0.062872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6566 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DT        RF       XGB        NN  LightGBM       MLR     Lasso  \\\n",
       "0     0.493639  0.123010  0.090379  0.048439  0.145469  0.511013  0.212471   \n",
       "1     0.393487  0.022858  0.006974  0.119783  0.020668  0.303957  0.007025   \n",
       "2     0.347997  0.520759  0.389370  0.379648  0.362066  0.064391  0.370642   \n",
       "3     0.269406  0.049914  0.082744  0.130718  0.207453  0.556341  0.254460   \n",
       "4     0.559507  0.179512  0.121404  0.083469  0.253092  0.650886  0.351965   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6561  0.423969  0.210884  0.152290  0.031242  0.276320  0.440347  0.096445   \n",
       "6562  0.334045  0.120961  0.084644  0.130098  0.245387  0.410275  0.124719   \n",
       "6563  0.264479  0.051395  0.000961  0.206465  0.216567  0.359816  0.173351   \n",
       "6564  0.056915  0.306661  0.145904  0.098061  0.285338  0.584591  0.044175   \n",
       "6565  0.329513  0.116429  0.009541  0.151796  0.157137  0.174756  0.356583   \n",
       "\n",
       "           PLS       kNN  \n",
       "0     0.269927  0.130301  \n",
       "1     0.461491  0.383835  \n",
       "2     0.924756  0.564785  \n",
       "3     0.262204  0.354590  \n",
       "4     0.139307  0.136240  \n",
       "...        ...       ...  \n",
       "6561  0.163685  0.300149  \n",
       "6562  0.150995  0.233798  \n",
       "6563  0.117947  0.177779  \n",
       "6564  0.273137  0.228076  \n",
       "6565  0.049702  0.062872  \n",
       "\n",
       "[6566 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_AE = predictions.copy()\n",
    "\n",
    "test_AE['Y'] = Y_test.values\n",
    "\n",
    "for model_name in model_names:\n",
    "    test_AE[model_name] = abs(test_AE[model_name] - test_AE['Y'])\n",
    "    \n",
    "test_AE = test_AE.drop(['Y'], axis = 1)    \n",
    "test_AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7985e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in train_summary.columns:\n",
    "    train_summary[column] = train_summary[column].astype(float)\n",
    "    test_summary[column] = test_summary[column].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6855680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_summary_round = train_summary.round(3)\n",
    "test_summary_round = test_summary.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2859080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT</th>\n",
       "      <th>RF</th>\n",
       "      <th>XGB</th>\n",
       "      <th>NN</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>MLR</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>PLS</th>\n",
       "      <th>kNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.467</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.305</td>\n",
       "      <td>1.580551e+10</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedAE</th>\n",
       "      <td>0.326</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.206</td>\n",
       "      <td>5.110000e-01</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.653</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.441</td>\n",
       "      <td>1.640855e+11</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.427</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.195</td>\n",
       "      <td>2.692405e+22</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCC</th>\n",
       "      <td>0.789</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.902</td>\n",
       "      <td>-8.000000e-03</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCC</th>\n",
       "      <td>0.759</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.889</td>\n",
       "      <td>5.420000e-01</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DT     RF    XGB     NN  LightGBM           MLR  Lasso    PLS    kNN\n",
       "MAE    0.467  0.419  0.314  0.356     0.305  1.580551e+10  0.421  0.517  0.373\n",
       "MedAE  0.326  0.300  0.219  0.244     0.206  5.110000e-01  0.332  0.912  0.218\n",
       "RMSE   0.653  0.576  0.445  0.520     0.441  1.640855e+11  0.557  0.677  0.590\n",
       "MSE    0.427  0.331  0.198  0.270     0.195  2.692405e+22  0.310  0.458  0.348\n",
       "PCC    0.789  0.828  0.901  0.867     0.902 -8.000000e-03  0.841  0.761  0.836\n",
       "SCC    0.759  0.791  0.885  0.851     0.889  5.420000e-01  0.820  0.733  0.814"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_summary_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b21a4786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT</th>\n",
       "      <th>RF</th>\n",
       "      <th>XGB</th>\n",
       "      <th>NN</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>MLR</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>PLS</th>\n",
       "      <th>kNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.493</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.302</td>\n",
       "      <td>3.632784e+09</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedAE</th>\n",
       "      <td>0.333</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.191</td>\n",
       "      <td>4.920000e-01</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.713</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.463</td>\n",
       "      <td>2.505718e+10</td>\n",
       "      <td>1.035</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.508</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.214</td>\n",
       "      <td>6.278622e+20</td>\n",
       "      <td>1.071</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCC</th>\n",
       "      <td>0.768</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.912</td>\n",
       "      <td>-5.100000e-02</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCC</th>\n",
       "      <td>0.772</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.913</td>\n",
       "      <td>6.860000e-01</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DT     RF    XGB     NN  LightGBM           MLR  Lasso    PLS    kNN\n",
       "MAE    0.493  0.432  0.311  0.354     0.302  3.632784e+09  0.535  0.503  0.353\n",
       "MedAE  0.333  0.276  0.169  0.239     0.191  4.920000e-01  0.341  0.922  0.223\n",
       "RMSE   0.713  0.657  0.485  0.559     0.463  2.505718e+10  1.035  0.699  0.532\n",
       "MSE    0.508  0.432  0.235  0.312     0.214  6.278622e+20  1.071  0.489  0.283\n",
       "PCC    0.768  0.811  0.905  0.868     0.912 -5.100000e-02  0.608  0.778  0.879\n",
       "SCC    0.772  0.828  0.908  0.880     0.913  6.860000e-01  0.806  0.792  0.866"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_summary_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef30d18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MedAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>PCC</th>\n",
       "      <th>SCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>4.930000e-01</td>\n",
       "      <td>0.333</td>\n",
       "      <td>7.130000e-01</td>\n",
       "      <td>5.080000e-01</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>4.320000e-01</td>\n",
       "      <td>0.276</td>\n",
       "      <td>6.570000e-01</td>\n",
       "      <td>4.320000e-01</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>3.110000e-01</td>\n",
       "      <td>0.169</td>\n",
       "      <td>4.850000e-01</td>\n",
       "      <td>2.350000e-01</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>3.540000e-01</td>\n",
       "      <td>0.239</td>\n",
       "      <td>5.590000e-01</td>\n",
       "      <td>3.120000e-01</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>3.020000e-01</td>\n",
       "      <td>0.191</td>\n",
       "      <td>4.630000e-01</td>\n",
       "      <td>2.140000e-01</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLR</th>\n",
       "      <td>3.632784e+09</td>\n",
       "      <td>0.492</td>\n",
       "      <td>2.505718e+10</td>\n",
       "      <td>6.278622e+20</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>5.350000e-01</td>\n",
       "      <td>0.341</td>\n",
       "      <td>1.035000e+00</td>\n",
       "      <td>1.071000e+00</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLS</th>\n",
       "      <td>5.030000e-01</td>\n",
       "      <td>0.922</td>\n",
       "      <td>6.990000e-01</td>\n",
       "      <td>4.890000e-01</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kNN</th>\n",
       "      <td>3.530000e-01</td>\n",
       "      <td>0.223</td>\n",
       "      <td>5.320000e-01</td>\n",
       "      <td>2.830000e-01</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   MAE  MedAE          RMSE           MSE    PCC    SCC\n",
       "DT        4.930000e-01  0.333  7.130000e-01  5.080000e-01  0.768  0.772\n",
       "RF        4.320000e-01  0.276  6.570000e-01  4.320000e-01  0.811  0.828\n",
       "XGB       3.110000e-01  0.169  4.850000e-01  2.350000e-01  0.905  0.908\n",
       "NN        3.540000e-01  0.239  5.590000e-01  3.120000e-01  0.868  0.880\n",
       "LightGBM  3.020000e-01  0.191  4.630000e-01  2.140000e-01  0.912  0.913\n",
       "MLR       3.632784e+09  0.492  2.505718e+10  6.278622e+20 -0.051  0.686\n",
       "Lasso     5.350000e-01  0.341  1.035000e+00  1.071000e+00  0.608  0.806\n",
       "PLS       5.030000e-01  0.922  6.990000e-01  4.890000e-01  0.778  0.792\n",
       "kNN       3.530000e-01  0.223  5.320000e-01  2.830000e-01  0.879  0.866"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_summary_round_T = test_summary_round.T\n",
    "test_summary_round_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4e40a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MedAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>PCC</th>\n",
       "      <th>SCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>3.020000e-01</td>\n",
       "      <td>0.191</td>\n",
       "      <td>4.630000e-01</td>\n",
       "      <td>2.140000e-01</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>3.110000e-01</td>\n",
       "      <td>0.169</td>\n",
       "      <td>4.850000e-01</td>\n",
       "      <td>2.350000e-01</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kNN</th>\n",
       "      <td>3.530000e-01</td>\n",
       "      <td>0.223</td>\n",
       "      <td>5.320000e-01</td>\n",
       "      <td>2.830000e-01</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>3.540000e-01</td>\n",
       "      <td>0.239</td>\n",
       "      <td>5.590000e-01</td>\n",
       "      <td>3.120000e-01</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>4.320000e-01</td>\n",
       "      <td>0.276</td>\n",
       "      <td>6.570000e-01</td>\n",
       "      <td>4.320000e-01</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>4.930000e-01</td>\n",
       "      <td>0.333</td>\n",
       "      <td>7.130000e-01</td>\n",
       "      <td>5.080000e-01</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLS</th>\n",
       "      <td>5.030000e-01</td>\n",
       "      <td>0.922</td>\n",
       "      <td>6.990000e-01</td>\n",
       "      <td>4.890000e-01</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>5.350000e-01</td>\n",
       "      <td>0.341</td>\n",
       "      <td>1.035000e+00</td>\n",
       "      <td>1.071000e+00</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLR</th>\n",
       "      <td>3.632784e+09</td>\n",
       "      <td>0.492</td>\n",
       "      <td>2.505718e+10</td>\n",
       "      <td>6.278622e+20</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   MAE  MedAE          RMSE           MSE    PCC    SCC\n",
       "LightGBM  3.020000e-01  0.191  4.630000e-01  2.140000e-01  0.912  0.913\n",
       "XGB       3.110000e-01  0.169  4.850000e-01  2.350000e-01  0.905  0.908\n",
       "kNN       3.530000e-01  0.223  5.320000e-01  2.830000e-01  0.879  0.866\n",
       "NN        3.540000e-01  0.239  5.590000e-01  3.120000e-01  0.868  0.880\n",
       "RF        4.320000e-01  0.276  6.570000e-01  4.320000e-01  0.811  0.828\n",
       "DT        4.930000e-01  0.333  7.130000e-01  5.080000e-01  0.768  0.772\n",
       "PLS       5.030000e-01  0.922  6.990000e-01  4.890000e-01  0.778  0.792\n",
       "Lasso     5.350000e-01  0.341  1.035000e+00  1.071000e+00  0.608  0.806\n",
       "MLR       3.632784e+09  0.492  2.505718e+10  6.278622e+20 -0.051  0.686"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_models_ind = test_summary_round_T.sort_values(by=\"MAE\", ascending=True).index\n",
    "sorted_models = test_summary_round_T.loc[sorted_models_ind]\n",
    "sorted_models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b9ec316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>XGB</th>\n",
       "      <th>kNN</th>\n",
       "      <th>NN</th>\n",
       "      <th>RF</th>\n",
       "      <th>DT</th>\n",
       "      <th>PLS</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>MLR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.145469</td>\n",
       "      <td>0.090379</td>\n",
       "      <td>0.130301</td>\n",
       "      <td>0.048439</td>\n",
       "      <td>0.123010</td>\n",
       "      <td>0.493639</td>\n",
       "      <td>0.269927</td>\n",
       "      <td>0.212471</td>\n",
       "      <td>0.511013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020668</td>\n",
       "      <td>0.006974</td>\n",
       "      <td>0.383835</td>\n",
       "      <td>0.119783</td>\n",
       "      <td>0.022858</td>\n",
       "      <td>0.393487</td>\n",
       "      <td>0.461491</td>\n",
       "      <td>0.007025</td>\n",
       "      <td>0.303957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.362066</td>\n",
       "      <td>0.389370</td>\n",
       "      <td>0.564785</td>\n",
       "      <td>0.379648</td>\n",
       "      <td>0.520759</td>\n",
       "      <td>0.347997</td>\n",
       "      <td>0.924756</td>\n",
       "      <td>0.370642</td>\n",
       "      <td>0.064391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.207453</td>\n",
       "      <td>0.082744</td>\n",
       "      <td>0.354590</td>\n",
       "      <td>0.130718</td>\n",
       "      <td>0.049914</td>\n",
       "      <td>0.269406</td>\n",
       "      <td>0.262204</td>\n",
       "      <td>0.254460</td>\n",
       "      <td>0.556341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.253092</td>\n",
       "      <td>0.121404</td>\n",
       "      <td>0.136240</td>\n",
       "      <td>0.083469</td>\n",
       "      <td>0.179512</td>\n",
       "      <td>0.559507</td>\n",
       "      <td>0.139307</td>\n",
       "      <td>0.351965</td>\n",
       "      <td>0.650886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6561</th>\n",
       "      <td>0.276320</td>\n",
       "      <td>0.152290</td>\n",
       "      <td>0.300149</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.210884</td>\n",
       "      <td>0.423969</td>\n",
       "      <td>0.163685</td>\n",
       "      <td>0.096445</td>\n",
       "      <td>0.440347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6562</th>\n",
       "      <td>0.245387</td>\n",
       "      <td>0.084644</td>\n",
       "      <td>0.233798</td>\n",
       "      <td>0.130098</td>\n",
       "      <td>0.120961</td>\n",
       "      <td>0.334045</td>\n",
       "      <td>0.150995</td>\n",
       "      <td>0.124719</td>\n",
       "      <td>0.410275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6563</th>\n",
       "      <td>0.216567</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.177779</td>\n",
       "      <td>0.206465</td>\n",
       "      <td>0.051395</td>\n",
       "      <td>0.264479</td>\n",
       "      <td>0.117947</td>\n",
       "      <td>0.173351</td>\n",
       "      <td>0.359816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6564</th>\n",
       "      <td>0.285338</td>\n",
       "      <td>0.145904</td>\n",
       "      <td>0.228076</td>\n",
       "      <td>0.098061</td>\n",
       "      <td>0.306661</td>\n",
       "      <td>0.056915</td>\n",
       "      <td>0.273137</td>\n",
       "      <td>0.044175</td>\n",
       "      <td>0.584591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6565</th>\n",
       "      <td>0.157137</td>\n",
       "      <td>0.009541</td>\n",
       "      <td>0.062872</td>\n",
       "      <td>0.151796</td>\n",
       "      <td>0.116429</td>\n",
       "      <td>0.329513</td>\n",
       "      <td>0.049702</td>\n",
       "      <td>0.356583</td>\n",
       "      <td>0.174756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6566 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LightGBM       XGB       kNN        NN        RF        DT       PLS  \\\n",
       "0     0.145469  0.090379  0.130301  0.048439  0.123010  0.493639  0.269927   \n",
       "1     0.020668  0.006974  0.383835  0.119783  0.022858  0.393487  0.461491   \n",
       "2     0.362066  0.389370  0.564785  0.379648  0.520759  0.347997  0.924756   \n",
       "3     0.207453  0.082744  0.354590  0.130718  0.049914  0.269406  0.262204   \n",
       "4     0.253092  0.121404  0.136240  0.083469  0.179512  0.559507  0.139307   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6561  0.276320  0.152290  0.300149  0.031242  0.210884  0.423969  0.163685   \n",
       "6562  0.245387  0.084644  0.233798  0.130098  0.120961  0.334045  0.150995   \n",
       "6563  0.216567  0.000961  0.177779  0.206465  0.051395  0.264479  0.117947   \n",
       "6564  0.285338  0.145904  0.228076  0.098061  0.306661  0.056915  0.273137   \n",
       "6565  0.157137  0.009541  0.062872  0.151796  0.116429  0.329513  0.049702   \n",
       "\n",
       "         Lasso       MLR  \n",
       "0     0.212471  0.511013  \n",
       "1     0.007025  0.303957  \n",
       "2     0.370642  0.064391  \n",
       "3     0.254460  0.556341  \n",
       "4     0.351965  0.650886  \n",
       "...        ...       ...  \n",
       "6561  0.096445  0.440347  \n",
       "6562  0.124719  0.410275  \n",
       "6563  0.173351  0.359816  \n",
       "6564  0.044175  0.584591  \n",
       "6565  0.356583  0.174756  \n",
       "\n",
       "[6566 rows x 9 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_AE = test_AE[sorted_models_ind]\n",
    "test_AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f8e05a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>XGB</th>\n",
       "      <th>kNN</th>\n",
       "      <th>NN</th>\n",
       "      <th>RF</th>\n",
       "      <th>DT</th>\n",
       "      <th>PLS</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>MLR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.302</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.535</td>\n",
       "      <td>3.632784e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedAE</th>\n",
       "      <td>0.191</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.341</td>\n",
       "      <td>4.920000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.463</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.699</td>\n",
       "      <td>1.035</td>\n",
       "      <td>2.505718e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.214</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.489</td>\n",
       "      <td>1.071</td>\n",
       "      <td>6.278622e+20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCC</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.608</td>\n",
       "      <td>-5.100000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCC</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.806</td>\n",
       "      <td>6.860000e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LightGBM    XGB    kNN     NN     RF     DT    PLS  Lasso           MLR\n",
       "MAE       0.302  0.311  0.353  0.354  0.432  0.493  0.503  0.535  3.632784e+09\n",
       "MedAE     0.191  0.169  0.223  0.239  0.276  0.333  0.922  0.341  4.920000e-01\n",
       "RMSE      0.463  0.485  0.532  0.559  0.657  0.713  0.699  1.035  2.505718e+10\n",
       "MSE       0.214  0.235  0.283  0.312  0.432  0.508  0.489  1.071  6.278622e+20\n",
       "PCC       0.912  0.905  0.879  0.868  0.811  0.768  0.778  0.608 -5.100000e-02\n",
       "SCC       0.913  0.908  0.866  0.880  0.828  0.772  0.792  0.806  6.860000e-01"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_summary_round = test_summary_round[sorted_models_ind]\n",
    "test_summary_round.to_excel('Figure_3b' + data_for + '.xlsx', index = True)\n",
    "test_summary_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "516c2f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>XGB</th>\n",
       "      <th>kNN</th>\n",
       "      <th>NN</th>\n",
       "      <th>RF</th>\n",
       "      <th>DT</th>\n",
       "      <th>PLS</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>MLR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.305</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.421</td>\n",
       "      <td>1.580551e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedAE</th>\n",
       "      <td>0.206</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.332</td>\n",
       "      <td>5.110000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.441</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.557</td>\n",
       "      <td>1.640855e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.195</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.310</td>\n",
       "      <td>2.692405e+22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCC</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.841</td>\n",
       "      <td>-8.000000e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCC</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.820</td>\n",
       "      <td>5.420000e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LightGBM    XGB    kNN     NN     RF     DT    PLS  Lasso           MLR\n",
       "MAE       0.305  0.314  0.373  0.356  0.419  0.467  0.517  0.421  1.580551e+10\n",
       "MedAE     0.206  0.219  0.218  0.244  0.300  0.326  0.912  0.332  5.110000e-01\n",
       "RMSE      0.441  0.445  0.590  0.520  0.576  0.653  0.677  0.557  1.640855e+11\n",
       "MSE       0.195  0.198  0.348  0.270  0.331  0.427  0.458  0.310  2.692405e+22\n",
       "PCC       0.902  0.901  0.836  0.867  0.828  0.789  0.761  0.841 -8.000000e-03\n",
       "SCC       0.889  0.885  0.814  0.851  0.791  0.759  0.733  0.820  5.420000e-01"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_summary_round = train_summary_round[sorted_models_ind]\n",
    "train_summary_round.to_excel('Figure_SI_training_results' + data_for + '.xlsx', index = True)\n",
    "train_summary_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37396695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "\n",
    "palette = [red] + [blue] * (len(test_AE.columns) - 1)\n",
    "\n",
    "\n",
    "sns.boxplot(data=test_AE, palette=palette, showfliers=False, showmeans=True,linewidth = 1.0, \n",
    "            meanprops={\"marker\":\"o\", \"markerfacecolor\":\"white\", \"markeredgecolor\":\"white\", \"markersize\": 7, \"markeredgewidth\": 0.5, \"markeredgecolor\": \"black\"})\n",
    "\n",
    "        \n",
    "plt.title('')\n",
    "plt.ylabel('Model Absolute Error')\n",
    "\n",
    "plt.annotate('a)', xy=(0, 1.06), xycoords=\"axes fraction\", va=\"top\", ha=\"left\", fontsize=12)\n",
    "plt.savefig('Figure_3a_Model_test_boxplots' + data_for + '.png', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3e106f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "\n",
    "palette = [red] + [blue] * (len(test_AE.columns) - 1)\n",
    "\n",
    "\n",
    "sns.boxplot(data=test_AE, palette=palette, showfliers=True, showmeans=True,linewidth = 1.0, \n",
    "            meanprops={\"marker\":\"o\", \"markerfacecolor\":\"white\", \"markeredgecolor\":\"white\", \"markersize\": 7, \"markeredgewidth\": 0.5, \"markeredgecolor\": \"black\"})\n",
    "\n",
    "\n",
    "        \n",
    "plt.title('')\n",
    "plt.ylabel('Model Absolute Error')\n",
    "\n",
    "plt.annotate('a)', xy=(0, 1.06), xycoords=\"axes fraction\", va=\"top\", ha=\"left\", fontsize=12)\n",
    "plt.savefig('Figure_SI_model_test_boxplots_with_outliers' + data_for + '.png', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2628bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5e9168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
